# -*- coding: utf-8 -*-

import google.generativeai as genai
import os
import json
import re
import time
from typing import Optional, Dict, Any, List
import logging
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ProSummaryConfig:
    """Proçµ±åˆè¦ç´„ã®è¨­å®šã‚¯ãƒ©ã‚¹"""
    enabled: bool = True
    min_articles_threshold: int = 10
    max_daily_executions: int = 3
    execution_hours: List[int] = None  # [9, 15, 21] # JST
    cost_limit_monthly: float = 50.0  # USD
    timeout_seconds: int = 180
    model_name: str = "gemini-2.5-pro"
    
    def __post_init__(self):
        if self.execution_hours is None:
            self.execution_hours = list(range(24))  # 24æ™‚é–“ã„ã¤ã§ã‚‚å®Ÿè¡Œå¯èƒ½


class ProSummarizer:
    """Gemini 2.5 Proã«ã‚ˆã‚‹çµ±åˆè¦ç´„æ©Ÿèƒ½"""
    
    def __init__(self, api_key: str, config: ProSummaryConfig = None):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key (str): Google Gemini APIã‚­ãƒ¼
            config (ProSummaryConfig): è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        self.api_key = api_key
        self.config = config or ProSummaryConfig()
        self.logger = logging.getLogger(__name__)
        
        if not api_key:
            raise ValueError("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        if len(api_key) < 20:  # åŸºæœ¬çš„ãªé•·ã•ãƒã‚§ãƒƒã‚¯
            raise ValueError("Gemini APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ï¼ˆé•·ã•ãŒçŸ­ã™ãã¾ã™ï¼‰")
        
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(self.config.model_name)
            self.logger.info(f"Gemini APIãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ (ãƒ¢ãƒ‡ãƒ«: {self.config.model_name})")
        except Exception as e:
            self.logger.error(f"Gemini APIåˆæœŸåŒ–å¤±æ•—: {e}")
            raise
    
    def generate_unified_summary(self, grouped_articles: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """
        ä¸€æ‹¬çµ±åˆè¦ç´„ã‚’ç”Ÿæˆï¼ˆåœ°åŸŸé–¢é€£æ€§ã‚’è€ƒæ…®ï¼‰
        
        Args:
            grouped_articles (Dict[str, List[Dict]]): åœ°åŸŸåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸè¨˜äº‹ç¾¤
                ä¾‹: {"japan": [{"summary": "...", "title": "...", "category": "..."}], ...}
        
        Returns:
            Dict[str, Any]: çµ±åˆè¦ç´„çµæœï¼ˆåœ°åŸŸåˆ¥+å…¨ä½“+é–¢é€£æ€§åˆ†æï¼‰
        """
        start_time = time.time()
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        self.logger.info(f"ä¸€æ‹¬çµ±åˆè¦ç´„ç”Ÿæˆé–‹å§‹ (ç·è¨˜äº‹æ•°: {total_articles}, åœ°åŸŸæ•°: {len(grouped_articles)})")
        
        # è¨˜äº‹æ•°åˆ¶é™ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾ç­–ï¼‰
        max_total_articles = 50
        limited_articles = {}
        
        for region, articles in grouped_articles.items():
            if len(articles) == 0:
                continue
            # å„åœ°åŸŸæœ€å¤§15è¨˜äº‹ã«åˆ¶é™
            max_per_region = min(15, max_total_articles // len(grouped_articles))
            if len(articles) > max_per_region:
                self.logger.warning(f"åœ°åŸŸ {region}: {len(articles)}ä»¶ â†’ {max_per_region}ä»¶ã«åˆ¶é™")
                articles = articles[:max_per_region]
            limited_articles[region] = articles
        
        try:
            prompt = self._build_unified_prompt(limited_articles)
            self.logger.info(f"çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(prompt)}æ–‡å­—")
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=4096,  # ä¸€æ‹¬å‡¦ç†ãªã®ã§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—åŠ 
                    temperature=0.3,
                ),
                request_options={"timeout": 120}  # 120ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            if not response:
                raise Exception("Gemini APIã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            if not hasattr(response, 'text') or not response.text:
                raise Exception(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {response}")
            
            self.logger.info(f"çµ±åˆè¦ç´„APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {len(response.text)}æ–‡å­—")
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            parsed_result = self._parse_unified_response(response.text)
            
            if parsed_result:
                result = {
                    "unified_summary": parsed_result,
                    "total_articles": total_articles,
                    "processing_time_ms": processing_time_ms,
                    "model_version": self.config.model_name
                }
                self.logger.info(f"ä¸€æ‹¬çµ±åˆè¦ç´„å®Œäº† ({processing_time_ms}ms)")
                return result
            else:
                self.logger.error("çµ±åˆè¦ç´„ã®è§£æã«å¤±æ•—")
                return None
                
        except Exception as e:
            self.logger.error(f"ğŸš¨ ä¸€æ‹¬çµ±åˆè¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ğŸš¨ UNIFIED SUMMARY FAILED: {e}")
            return None
    
    def generate_global_summary(self, all_articles: List[Dict[str, Any]], 
                              regional_summaries: Dict[str, Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """
        å…¨ä½“å¸‚æ³è¦ç´„ã‚’ç”Ÿæˆ
        
        Args:
            all_articles (List[Dict]): å…¨è¨˜äº‹ã®ãƒªã‚¹ãƒˆ
            regional_summaries (Dict): åœ°åŸŸåˆ¥è¦ç´„ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            Optional[Dict[str, Any]]: å…¨ä½“è¦ç´„çµæœã€å¤±æ•—æ™‚ã¯None
        """
        start_time = time.time()
        self.logger.info(f"å…¨ä½“è¦ç´„ç”Ÿæˆé–‹å§‹ (è¨˜äº‹æ•°: {len(all_articles)}, åœ°åŸŸæ•°: {len(regional_summaries)})")
        
        try:
            prompt = self._build_global_prompt(all_articles, regional_summaries)
            self.logger.info(f"å…¨ä½“è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(prompt)}æ–‡å­—")
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=3072,
                    temperature=0.3,
                ),
                request_options={"timeout": 90}  # 90ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            if not response:
                raise Exception("Gemini APIã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            if not hasattr(response, 'text') or not response.text:
                raise Exception(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {response}")
            
            self.logger.info(f"å…¨ä½“è¦ç´„Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {len(response.text)}æ–‡å­—")
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            summary_text = self._extract_summary_text(response.text)
            
            if summary_text:
                result = {
                    "summary_text": summary_text,
                    "articles_count": len(all_articles),
                    "processing_time_ms": processing_time_ms,
                    "model_version": self.config.model_name
                }
                self.logger.info(f"å…¨ä½“è¦ç´„å®Œäº† ({len(summary_text)}å­—, {processing_time_ms}ms)")
                return result
            else:
                self.logger.error("å…¨ä½“è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡ºã«å¤±æ•—")
                return None
                
        except Exception as e:
            self.logger.error(f"å…¨ä½“è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _build_regional_prompt(self, region: str, articles: List[Dict[str, Any]]) -> str:
        """åœ°åŸŸåˆ¥è¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        region_names = {
            "japan": "æ—¥æœ¬",
            "usa": "ç±³å›½", 
            "china": "ä¸­å›½",
            "europe": "æ¬§å·",
            "other": "ãã®ä»–åœ°åŸŸ"
        }
        
        region_ja = region_names.get(region, region)
        
        # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
        article_summaries = []
        for i, article in enumerate(articles, 1):
            summary = article.get("summary", "").strip()
            title = article.get("title", "").strip()
            category = article.get("category", "ãã®ä»–")
            
            article_summaries.append(f"{i}. ã€{category}ã€‘{title}\n   è¦ç´„: {summary}")
        
        articles_text = "\n\n".join(article_summaries)
        
        prompt = f"""
ä»¥ä¸‹ã®{region_ja}ã«é–¢ã™ã‚‹{len(articles)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åˆ†æã—ã€åœ°åŸŸåˆ¥ã®çµ±åˆè¦ç´„ã‚’400-600å­—ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

## è¦ç´„ä½œæˆã®æŒ‡é‡
1. **ä¸»è¦ãƒˆãƒ¬ãƒ³ãƒ‰**: {region_ja}å¸‚å ´ã®ä¸»è¦ãªå‹•å‘ã¨ç‰¹å¾´
2. **é‡è¦ãªç™ºè¡¨**: çµŒæ¸ˆæŒ‡æ¨™ã€æ”¿ç­–ç™ºè¡¨ã€ä¼æ¥­æ¥­ç¸¾ç­‰ã®é‡è¦ãªç™ºè¡¨
3. **å¸‚å ´ã¸ã®å½±éŸ¿**: æ ªä¾¡ã€ç‚ºæ›¿ã€é‡‘åˆ©ç­‰ã¸ã®å…·ä½“çš„ãªå½±éŸ¿
4. **åœ°åŸŸç‰¹æœ‰ã®èª²é¡Œ**: {region_ja}ç‰¹æœ‰ã®çµŒæ¸ˆèª²é¡Œã‚„æ©Ÿä¼š

## è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
{articles_text}

## å‡ºåŠ›å½¢å¼
400-600å­—ã®çµ±åˆè¦ç´„æ–‡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯é©åº¦ã«ä½¿ç”¨ã—ã€å¸‚å ´é–¢ä¿‚è€…ã«ã¨ã£ã¦æœ‰ç”¨ã§èª­ã¿ã‚„ã™ã„å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def _build_global_prompt(self, all_articles: List[Dict[str, Any]], 
                           regional_summaries: Dict[str, Dict[str, Any]]) -> str:
        """å…¨ä½“è¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        
        # åœ°åŸŸåˆ¥è¦ç´„ã‚’ã¾ã¨ã‚ã‚‹
        regional_text = []
        for region, summary_data in regional_summaries.items():
            region_names = {
                "japan": "æ—¥æœ¬",
                "usa": "ç±³å›½",
                "china": "ä¸­å›½", 
                "europe": "æ¬§å·",
                "other": "ãã®ä»–åœ°åŸŸ"
            }
            region_ja = region_names.get(region, region)
            summary = summary_data.get("summary_text", "")
            article_count = summary_data.get("articles_count", 0)
            
            regional_text.append(f"### {region_ja}å¸‚æ³ ({article_count}è¨˜äº‹)\n{summary}")
        
        regional_summaries_text = "\n\n".join(regional_text)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        category_counts = {}
        for article in all_articles:
            category = article.get("category", "ãã®ä»–")
            category_counts[category] = category_counts.get(category, 0) + 1
        
        category_stats = ", ".join([f"{cat}: {count}ä»¶" for cat, count in category_counts.items()])
        
        prompt = f"""
ä»¥ä¸‹ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚æ³ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€å…¨ä½“å¸‚æ³ã®çµ±åˆè¦ç´„ã‚’800-1000å­—ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

## åˆ†æãƒ‡ãƒ¼ã‚¿
- **ç·è¨˜äº‹æ•°**: {len(all_articles)}ä»¶
- **ã‚«ãƒ†ã‚´ãƒªåˆ¥**: {category_stats}
- **åˆ†æå¯¾è±¡åœ°åŸŸ**: {', '.join(regional_summaries.keys())}

## åœ°åŸŸåˆ¥è¦ç´„
{regional_summaries_text}

## è¦ç´„ä½œæˆã®æŒ‡é‡
1. **ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒˆãƒ¬ãƒ³ãƒ‰**: ä¸–ç•Œå¸‚å ´å…¨ä½“ã®ä¸»è¦ãªå‹•å‘ã¨æ–¹å‘æ€§
2. **åœ°åŸŸé–“ç›¸äº’ä½œç”¨**: å„åœ°åŸŸå¸‚å ´é–“ã®ç›¸äº’å½±éŸ¿ã¨æ³¢åŠåŠ¹æœ
3. **ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æ**: æ¥­ç•Œãƒ»åˆ†é‡åˆ¥ã®æ³¨ç›®ã™ã¹ãå‹•å‘
4. **ãƒªã‚¹ã‚¯ã¨æ©Ÿä¼š**: å¸‚å ´å‚åŠ è€…ãŒæ³¨æ„ã™ã¹ããƒªã‚¹ã‚¯ã¨æŠ•è³‡æ©Ÿä¼š
5. **ä»Šå¾Œã®è¦‹é€šã—**: çŸ­æœŸçš„ãªå¸‚å ´äºˆæ¸¬ã¨æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ

## å‡ºåŠ›å½¢å¼
800-1000å­—ã®ç·åˆå¸‚æ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æŠ•è³‡å®¶ãƒ»å¸‚å ´é–¢ä¿‚è€…ã«ã¨ã£ã¦å®Ÿç”¨çš„ã§æ´å¯Ÿã«å¯Œã‚“ã å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def _build_unified_prompt(self, grouped_articles: Dict[str, List[Dict[str, Any]]]) -> str:
        """ä¸€æ‹¬çµ±åˆè¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆè¨˜äº‹é–¢é€£æ€§ã‚’è€ƒæ…®ï¼‰"""
        
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        
        prompt = f"""ã‚ãªãŸã¯é‡‘èãƒ»çµŒæ¸ˆåˆ†é‡ã®å°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã® {total_articles} ä»¶ã®è¨˜äº‹ã‚’åˆ†æã—ã€åœ°åŸŸé–“ã®é–¢é€£æ€§ã‚„ç›¸äº’å½±éŸ¿ã‚’è€ƒæ…®ã—ãŸåŒ…æ‹¬çš„ãªå¸‚å ´åˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æå¯¾è±¡è¨˜äº‹ï¼ˆåœ°åŸŸåˆ¥ï¼‰ã€‘
"""
        
        # åœ°åŸŸåˆ¥è¨˜äº‹ã‚’æ•´ç†
        for region, articles in grouped_articles.items():
            region_names = {
                "japan": "æ—¥æœ¬", "usa": "ç±³å›½", "china": "ä¸­å›½", 
                "europe": "æ¬§å·", "asia": "ã‚¢ã‚¸ã‚¢", "global": "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "other": "ãã®ä»–"
            }
            region_ja = region_names.get(region, region)
            
            prompt += f"\nâ–  {region_ja}åœ°åŸŸ ({len(articles)}ä»¶)\n"
            
            for i, article in enumerate(articles, 1):
                title = article.get("title", "").strip()
                summary = article.get("summary", "").strip()
                category = article.get("category", "ãã®ä»–")
                
                prompt += f"{i}. ã€{category}ã€‘{title}\n   {summary}\n"
        
        prompt += f"""

ã€åˆ†æè¦æ±‚ã€‘
ä»¥ä¸‹ã®æ§‹é€ ã§åŒ…æ‹¬çš„ãªåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š

## åœ°åŸŸåˆ¥è¦ç´„
å„åœ°åŸŸã®ä¸»è¦å‹•å‘ã¨é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’ç°¡æ½”ã«è¦ç´„

## ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´æ¦‚æ³
å…¨ä½“çš„ãªå¸‚å ´å‹•å‘ã¨ä¸»è¦ãƒ†ãƒ¼ãƒã®ç·æ‹¬

## åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ
å„åœ°åŸŸã®å‹•å‘ãŒä»–åœ°åŸŸã«ä¸ãˆã‚‹å½±éŸ¿ã‚„é–¢é€£æ€§

## æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰
è¨˜äº‹å…¨ä½“ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹é‡è¦ãªå¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„å°†æ¥ã®å±•æœ›

## ãƒªã‚¹ã‚¯è¦å› 
å¸‚å ´ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ãƒªã‚¹ã‚¯è¦å› ã®ç‰¹å®š

å›ç­”ã¯æ—¥æœ¬èªã§ã€å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³300æ–‡å­—ç¨‹åº¦ã§ç°¡æ½”ã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãè¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
å°‚é–€ç”¨èªã¯é©åº¦ã«ä½¿ç”¨ã—ã€ä¸€èˆ¬æŠ•è³‡å®¶ã«ã‚‚ç†è§£ã—ã‚„ã™ã„è¡¨ç¾ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""

        return prompt
    
    def _parse_unified_response(self, response_text: str) -> Optional[Dict[str, str]]:
        """çµ±åˆè¦ç´„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æã—ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã«åˆ†å‰²"""
        if not response_text:
            return None
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²
        sections = {}
        current_section = None
        current_content = []
        
        lines = response_text.split('\n')
        
        section_headers = {
            'åœ°åŸŸåˆ¥è¦ç´„': 'regional_summaries',
            'ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´æ¦‚æ³': 'global_overview', 
            'åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ': 'cross_regional_analysis',
            'æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰': 'key_trends',
            'ãƒªã‚¹ã‚¯è¦å› ': 'risk_factors'
        }
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œå‡º
            header_found = False
            for header, key in section_headers.items():
                if header in line and ('##' in line or 'â– ' in line or 'â—' in line):
                    # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                    if current_section and current_content:
                        sections[current_section] = '\n'.join(current_content).strip()
                    
                    current_section = key
                    current_content = []
                    header_found = True
                    break
            
            if not header_found and current_section:
                current_content.append(line)
        
        # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content).strip()
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…¨ä½“ã‚’global_overviewã¨ã—ã¦æ‰±ã†
        if not sections:
            sections['global_overview'] = response_text.strip()
        
        return sections if sections else None
    
    def _extract_summary_text(self, response_text: str) -> Optional[str]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¦ç´„éƒ¨åˆ†ã‚’æŠ½å‡º"""
        if not response_text:
            return None
        
        # ä¸è¦ãªå‰å¾Œã®è£…é£¾ã‚’é™¤å»
        text = response_text.strip()
        
        # ```markdown ãªã©ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯é™¤å»
        text = re.sub(r"```[a-zA-Z]*\n(.*?)\n```", r"\1", text, flags=re.DOTALL)
        
        # æœ€çµ‚çš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
        return text.strip() if text.strip() else None


def create_integrated_summaries(api_key: str, grouped_articles: Dict[str, List[Dict[str, Any]]], 
                               config: ProSummaryConfig = None) -> Optional[Dict[str, Any]]:
    """
    çµ±åˆè¦ç´„ã‚’ä½œæˆã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    Args:
        api_key (str): Gemini APIã‚­ãƒ¼
        grouped_articles (Dict): åœ°åŸŸåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸè¨˜äº‹
        config (ProSummaryConfig): è¨­å®š
    
    Returns:
        Optional[Dict[str, Any]]: çµ±åˆè¦ç´„çµæœã€å¤±æ•—æ™‚ã¯None
    """
    logger = logging.getLogger(__name__)
    
    try:
        # è¨˜äº‹æ•°ãƒã‚§ãƒƒã‚¯
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        if config and total_articles < config.min_articles_threshold:
            logger.warning(f"è¨˜äº‹æ•°ãŒé–¾å€¤æœªæº€ã§ã™ ({total_articles} < {config.min_articles_threshold})")
            return None
        
        # Pro Summarizerã‚’åˆæœŸåŒ–
        summarizer = ProSummarizer(api_key, config)
        
        # åœ°åŸŸåˆ¥è¦ç´„ç”Ÿæˆ
        regional_summaries = summarizer.generate_regional_summaries(grouped_articles)
        
        if not regional_summaries:
            logger.error("åœ°åŸŸåˆ¥è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
        
        # å…¨è¨˜äº‹ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–
        all_articles = []
        for articles in grouped_articles.values():
            all_articles.extend(articles)
        
        # å…¨ä½“è¦ç´„ç”Ÿæˆ
        global_summary = summarizer.generate_global_summary(all_articles, regional_summaries)
        
        if not global_summary:
            logger.error("å…¨ä½“è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
        
        # çµ±è¨ˆæƒ…å ±ã‚’æ•´ç†
        articles_by_region = {region: len(articles) for region, articles in grouped_articles.items()}
        
        result = {
            "global_summary": global_summary,
            "regional_summaries": regional_summaries,
            "metadata": {
                "total_articles": total_articles,
                "articles_by_region": articles_by_region,
                "processing_timestamp": datetime.utcnow().isoformat()
            }
        }
        
        logger.info(f"çµ±åˆè¦ç´„ç”Ÿæˆå®Œäº†: å…¨ä½“1ä»¶, åœ°åŸŸåˆ¥{len(regional_summaries)}ä»¶")
        return result
        
    except Exception as e:
        logger.error(f"çµ±åˆè¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return None


if __name__ == '__main__':
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    from dotenv import load_dotenv
    load_dotenv()
    
    test_api_key = os.getenv("GEMINI_API_KEY")
    if not test_api_key:
        raise ValueError("ç’°å¢ƒå¤‰æ•° 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
    test_grouped_articles = {
        "japan": [
            {
                "title": "æ—¥éŠ€ã€æ”¿ç­–é‡‘åˆ©æ®ãˆç½®ãæ±ºå®š",
                "summary": "æ—¥æœ¬éŠ€è¡Œã¯é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã§æ”¿ç­–é‡‘åˆ©ã‚’æ®ãˆç½®ãã€ç·©å’Œçš„ãªé‡‘èæ”¿ç­–ã‚’ç¶™ç¶šã™ã‚‹ã“ã¨ã‚’æ±ºå®šã—ãŸã€‚",
                "category": "é‡‘èæ”¿ç­–"
            },
            {
                "title": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã€å¢—ç›Šã‚’ç™ºè¡¨",
                "summary": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã¯å››åŠæœŸæ±ºç®—ã§å‰å¹´åŒæœŸæ¯”å¢—ç›Šã‚’ç™ºè¡¨ã€æµ·å¤–è²©å£²ãŒå¥½èª¿ã ã£ãŸã€‚",
                "category": "ä¼æ¥­æ¥­ç¸¾"
            }
        ],
        "usa": [
            {
                "title": "FRBã€åˆ©ä¸Šã’ã‚’æ¤œè¨",
                "summary": "ç±³é€£é‚¦æº–å‚™åˆ¶åº¦ç†äº‹ä¼šã¯æ¬¡å›ä¼šåˆã§ã®åˆ©ä¸Šã’å®Ÿæ–½ã‚’ç¤ºå”†ã€ã‚¤ãƒ³ãƒ•ãƒ¬æŠ‘åˆ¶ã‚’å„ªå…ˆã™ã‚‹å§¿å‹¢ã€‚",
                "category": "é‡‘èæ”¿ç­–"
            }
        ]
    }
    
    print("--- Proçµ±åˆè¦ç´„ãƒ†ã‚¹ãƒˆ ---")
    config = ProSummaryConfig(min_articles_threshold=2)
    result = create_integrated_summaries(test_api_key, test_grouped_articles, config)
    
    if result:
        print(f"\n=== å…¨ä½“è¦ç´„ ===")
        print(f"æ–‡å­—æ•°: {len(result['global_summary']['summary_text'])}å­—")
        print(f"å†…å®¹: {result['global_summary']['summary_text'][:100]}...")
        
        print(f"\n=== åœ°åŸŸåˆ¥è¦ç´„ ===")
        for region, summary_data in result['regional_summaries'].items():
            print(f"{region}: {len(summary_data['summary_text'])}å­—")
            print(f"  {summary_data['summary_text'][:50]}...")
        
        print(f"\n=== ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ ===")
        print(f"ç·è¨˜äº‹æ•°: {result['metadata']['total_articles']}")
        print(f"åœ°åŸŸåˆ¥: {result['metadata']['articles_by_region']}")
    else:
        print("ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")