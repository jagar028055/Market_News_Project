# -*- coding: utf-8 -*-

import google.generativeai as genai
import os
import json
import re
import time
from typing import Optional, Dict, Any, List
import logging
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ProSummaryConfig:
    """Proçµ±åˆè¦ç´„ã®è¨­å®šã‚¯ãƒ©ã‚¹"""
    enabled: bool = True
    min_articles_threshold: int = 10
    max_daily_executions: int = 3
    execution_hours: List[int] = None  # [9, 15, 21] # JST
    cost_limit_monthly: float = 50.0  # USD
    timeout_seconds: int = 180
    model_name: str = "gemini-2.5-pro"
    
    def __post_init__(self):
        if self.execution_hours is None:
            self.execution_hours = list(range(24))  # 24æ™‚é–“ã„ã¤ã§ã‚‚å®Ÿè¡Œå¯èƒ½


class ProSummarizer:
    """Gemini 2.5 Proã«ã‚ˆã‚‹çµ±åˆè¦ç´„æ©Ÿèƒ½"""
    
    def __init__(self, api_key: str, config: ProSummaryConfig = None):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key (str): Google Gemini APIã‚­ãƒ¼
            config (ProSummaryConfig): è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        self.api_key = api_key
        self.config = config or ProSummaryConfig()
        self.logger = logging.getLogger(__name__)
        
        if not api_key:
            raise ValueError("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        if len(api_key) < 20:  # åŸºæœ¬çš„ãªé•·ã•ãƒã‚§ãƒƒã‚¯
            raise ValueError("Gemini APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ï¼ˆé•·ã•ãŒçŸ­ã™ãã¾ã™ï¼‰")
        
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(self.config.model_name)
            self.logger.info(f"Gemini APIãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ (ãƒ¢ãƒ‡ãƒ«: {self.config.model_name})")
        except Exception as e:
            self.logger.error(f"Gemini APIåˆæœŸåŒ–å¤±æ•—: {e}")
            raise
    
    
    def generate_unified_summary(self, grouped_articles: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """
        ä¸€æ‹¬çµ±åˆè¦ç´„ã‚’ç”Ÿæˆï¼ˆåœ°åŸŸé–¢é€£æ€§ã‚’è€ƒæ…®ï¼‰
        
        Args:
            grouped_articles (Dict[str, List[Dict]]): åœ°åŸŸåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸè¨˜äº‹ç¾¤
                ä¾‹: {"japan": [{"summary": "...", "title": "...", "category": "..."}], ...}
        
        Returns:
            Dict[str, Any]: çµ±åˆè¦ç´„çµæœï¼ˆåœ°åŸŸåˆ¥+å…¨ä½“+é–¢é€£æ€§åˆ†æï¼‰
        """
        start_time = time.time()
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        self.logger.info(f"ä¸€æ‹¬çµ±åˆè¦ç´„ç”Ÿæˆé–‹å§‹ (ç·è¨˜äº‹æ•°: {total_articles}, åœ°åŸŸæ•°: {len(grouped_articles)})")
        
        # è¨˜äº‹æ•°åˆ¶é™ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾ç­–ï¼‰
        max_total_articles = 50
        limited_articles = {}
        
        for region, articles in grouped_articles.items():
            if len(articles) == 0:
                continue
            # å„åœ°åŸŸæœ€å¤§15è¨˜äº‹ã«åˆ¶é™
            max_per_region = min(15, max_total_articles // len(grouped_articles))
            if len(articles) > max_per_region:
                self.logger.warning(f"åœ°åŸŸ {region}: {len(articles)}ä»¶ â†’ {max_per_region}ä»¶ã«åˆ¶é™")
                articles = articles[:max_per_region]
            limited_articles[region] = articles
        
        try:
            prompt = self._build_unified_prompt(limited_articles)
            self.logger.info(f"çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(prompt)}æ–‡å­—")
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=4096,  # ä¸€æ‹¬å‡¦ç†ãªã®ã§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—åŠ 
                    temperature=0.3,
                ),
                request_options={"timeout": 600}  # 600ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ10åˆ†ï¼‰
            )
            
            if not response:
                raise Exception("Gemini APIã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            if not hasattr(response, 'text') or not response.text:
                raise Exception(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {response}")
            
            self.logger.info(f"çµ±åˆè¦ç´„APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {len(response.text)}æ–‡å­—")
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            parsed_result = self._parse_unified_response(response.text)
            
            if parsed_result:
                result = {
                    "unified_summary": parsed_result,
                    "total_articles": total_articles,
                    "processing_time_ms": processing_time_ms,
                    "model_version": self.config.model_name
                }
                self.logger.info(f"ä¸€æ‹¬çµ±åˆè¦ç´„å®Œäº† ({processing_time_ms}ms)")
                return result
            else:
                self.logger.error("çµ±åˆè¦ç´„ã®è§£æã«å¤±æ•—")
                return None
                
        except Exception as e:
            self.logger.error(f"ğŸš¨ ä¸€æ‹¬çµ±åˆè¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ğŸš¨ UNIFIED SUMMARY FAILED: {e}")
            return None
    
    
    
    
    def _build_unified_prompt(self, grouped_articles: Dict[str, List[Dict[str, Any]]]) -> str:
        """çµ±åˆè¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆåœ°åŸŸé–“é–¢é€£æ€§åˆ†æã‚’é‡è¦–ï¼‰"""
        
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        
        prompt = f"""ã‚ãªãŸã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡‘èå¸‚å ´ã®ä¸“é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®{total_articles}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åˆ†æã—ã€åœ°åŸŸé–“ã®ç›¸äº’é–¢é€£æ€§ã¨å½±éŸ¿ã‚’æ·±ãè€ƒæ…®ã—ãŸåŒ…æ‹¬çš„ãªå¸‚å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æå¯¾è±¡ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘"""
        
        # åœ°åŸŸåˆ¥è¨˜äº‹ã‚’æ•´ç†
        for region, articles in grouped_articles.items():
            region_names = {
                "japan": "æ—¥æœ¬", "usa": "ç±³å›½", "china": "ä¸­å›½", 
                "europe": "æ¬§å·", "asia": "ã‚¢ã‚¸ã‚¢", "global": "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "other": "ãã®ä»–"
            }
            region_ja = region_names.get(region, region)
            
            prompt += f"\n\nâ– â–  {region_ja}å¸‚å ´ ({len(articles)}ä»¶)\n"
            
            for i, article in enumerate(articles, 1):
                title = article.get("title", "").strip()
                summary = article.get("summary", "").strip()
                category = article.get("category", "ãã®ä»–")
                
                prompt += f"{i}. ã€{category}ã€‘{title}\n   è¦ç´„: {summary}\n"
        
        prompt += f"""

ã€åˆ†æãƒ¬ãƒãƒ¼ãƒˆæ§‹æˆã€‘
ä»¥ä¸‹ã®æ§‹é€ ã§ã€åœ°åŸŸé–“ã®ç›¸äº’ä½œç”¨ã¨æ³¢åŠåŠ¹æœã‚’é‡è¦–ã—ãŸç·åˆåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š

## åœ°åŸŸåˆ¥å¸‚å ´æ¦‚æ³
å„åœ°åŸŸã®ä¸»è¦å‹•å‘ã€é‡è¦æŒ‡æ¨™ã€æ”¿ç­–ç™ºè¡¨ã€ä¼æ¥­æ¥­ç¸¾ãªã©ã‚’ç°¡æ½”ã«æ•´ç†
(åœ°åŸŸã”ã¨ã«250-300æ–‡å­—ç¨‹åº¦)

## ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ç·æ‹¬
ä¸–ç•Œå…¨ä½“ã®å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã€ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥å‹•å‘ã€ä¸»è¦ãƒ†ãƒ¼ãƒã‚’ç·åˆçš„ã«åˆ†æ
(400-500æ–‡å­—ç¨‹åº¦)

## åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ
**ã“ã“ãŒæœ€é‡è¦**: å„åœ°åŸŸã®å‹•å‘ãŒä»–åœ°åŸŸã«ä¸ãˆã‚‹å½±éŸ¿ã€ç›¸äº’é–¢é€£æ€§ã€æ³¢åŠåŠ¹æœã‚’å…·ä½“ä¾‹ã§è©³ç´°åˆ†æ
- ç±³å›½é‡‘èæ”¿ç­–ãŒä»–åœ°åŸŸã«ä¸ãˆã‚‹å½±éŸ¿
- ä¸­å›½çµŒæ¸ˆå‹•å‘ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æ³¢åŠ
- æ—¥æœ¬ã®æ”¿ç­–å¤‰æ›´ãŒã‚¢ã‚¸ã‚¢åœ°åŸŸã«ä¸ãˆã‚‹å½±éŸ¿
- æ¬§å·æƒ…å‹¢ã®ä»–åœ°åŸŸã¸ã®æ³¢åŠ
(400-500æ–‡å­—ç¨‹åº¦)

## æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å°†æ¥å±•æœ›
è¨˜äº‹å…¨ä½“ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹é‡è¦ãªå¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã€æŠ€è¡“é€²æ­©ã€æ”¿ç­–æ–¹å‘æ€§ã€ä»Šå¾Œã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ
(300-400æ–‡å­—ç¨‹åº¦)

## ãƒªã‚¹ã‚¯è¦å› ãƒ»æŠ•è³‡æ©Ÿä¼š
çŸ­æœŸãƒ»ä¸­æœŸçš„ãªãƒªã‚¹ã‚¯è¦å› ã€åœ°æ”¿å­¦çš„ãƒªã‚¹ã‚¯ã€æŠ•è³‡æ©Ÿä¼šã®ç‰¹å®š
(250-300æ–‡å­—ç¨‹åº¦)

ã€å‡ºåŠ›æŒ‡å®šã€‘
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯å¿…ãš "##" ã§é–‹å§‹ã—ã€æ˜ç¢ºã«åŒºåˆ†ã™ã‚‹
- åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æã‚’ç‰¹ã«è©³ç´°ã«è¨˜è¿°ã™ã‚‹
- æŠ•è³‡å®¶ãƒ»å¸‚å ´é–¢ä¿‚è€…ã«ã¨ã£ã¦å®Ÿç”¨çš„ãªæƒ…å ±ã‚’æä¾›
- æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚„å…·ä½“ä¾‹ã‚’ç©æ¥µçš„ã«å«ã‚ã‚‹
- æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãè¨˜è¿°ã™ã‚‹"""

        return prompt
    
    def _parse_unified_response(self, response_text: str) -> Optional[Dict[str, str]]:
        """çµ±åˆè¦ç´„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æã—ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã«åˆ†å‰²"""
        if not response_text:
            return None
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²
        sections = {}
        current_section = None
        current_content = []
        
        lines = response_text.split('\n')
        
        section_headers = {
            'åœ°åŸŸåˆ¥å¸‚å ´æ¦‚æ³': 'regional_summaries',
            'ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ç·æ‹¬': 'global_overview', 
            'åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ': 'cross_regional_analysis',
            'æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰': 'key_trends',
            'ãƒªã‚¹ã‚¯è¦å› ': 'risk_factors',
            'å°†æ¥å±•æœ›': 'future_outlook',
            'æŠ•è³‡æ©Ÿä¼š': 'investment_opportunities'
        }
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œå‡º
            header_found = False
            for header, key in section_headers.items():
                if header in line and ('##' in line or 'â– ' in line or 'â—' in line):
                    # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                    if current_section and current_content:
                        sections[current_section] = '\n'.join(current_content).strip()
                    
                    current_section = key
                    current_content = []
                    header_found = True
                    break
            
            if not header_found and current_section:
                current_content.append(line)
        
        # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content).strip()
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…¨ä½“ã‚’global_overviewã¨ã—ã¦æ‰±ã†
        if not sections:
            sections['global_overview'] = response_text.strip()
            # åŸºæœ¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¢ºä¿
            sections['regional_summaries'] = 'åœ°åŸŸåˆ¥æƒ…å ±ãŒä¸ååˆ†ã§ã™'
            sections['cross_regional_analysis'] = 'åœ°åŸŸé–“é–¢é€£æ€§ã®åˆ†æãŒä¸ååˆ†ã§ã™'
        
        return sections if sections else None
    
    def _extract_summary_text(self, response_text: str) -> Optional[str]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¦ç´„éƒ¨åˆ†ã‚’æŠ½å‡º"""
        if not response_text:
            return None
        
        # ä¸è¦ãªå‰å¾Œã®è£…é£¾ã‚’é™¤å»
        text = response_text.strip()
        
        # ```markdown ãªã©ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯é™¤å»
        text = re.sub(r"```[a-zA-Z]*\n(.*?)\n```", r"\1", text, flags=re.DOTALL)
        
        # æœ€çµ‚çš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
        return text.strip() if text.strip() else None


def create_integrated_summaries(api_key: str, grouped_articles: Dict[str, List[Dict[str, Any]]], 
                               config: ProSummaryConfig = None) -> Optional[Dict[str, Any]]:
    """
    1å›ã®APIå‘¼ã³å‡ºã—ã§çµ±åˆè¦ç´„ã‚’ä½œæˆã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆåœ°åŸŸé–“é–¢é€£æ€§åˆ†æé‡è¦–ï¼‰
    
    Args:
        api_key (str): Gemini APIã‚­ãƒ¼
        grouped_articles (Dict): åœ°åŸŸåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸè¨˜äº‹
        config (ProSummaryConfig): è¨­å®š
    
    Returns:
        Optional[Dict[str, Any]]: çµ±åˆè¦ç´„çµæœï¼ˆåœ°åŸŸåˆ¥+ã‚°ãƒ­ãƒ¼ãƒãƒ«+é–¢é€£æ€§åˆ†æï¼‰ã€å¤±æ•—æ™‚ã¯None
    """
    logger = logging.getLogger(__name__)
    
    try:
        # è¨˜äº‹æ•°ãƒã‚§ãƒƒã‚¯
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        if config and total_articles < config.min_articles_threshold:
            logger.warning(f"è¨˜äº‹æ•°ãŒé–¾å€¤æœªæº€ã§ã™ ({total_articles} < {config.min_articles_threshold})")
            return None
        
        # Pro Summarizerã‚’åˆæœŸåŒ–
        summarizer = ProSummarizer(api_key, config)
        
        # 1å›APIå‘¼ã³å‡ºã—ã§çµ±åˆè¦ç´„ç”Ÿæˆ
        unified_result = summarizer.generate_unified_summary(grouped_articles)
        
        if not unified_result:
            logger.error("çµ±åˆè¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
        
        # çµæœã‚’æ•´ç†
        articles_by_region = {region: len(articles) for region, articles in grouped_articles.items()}
        
        result = {
            "unified_summary": unified_result["unified_summary"],
            "metadata": {
                "total_articles": total_articles,
                "articles_by_region": articles_by_region,
                "processing_timestamp": datetime.utcnow().isoformat(),
                "processing_time_ms": unified_result.get("processing_time_ms", 0),
                "model_version": unified_result.get("model_version", "gemini-2.5-pro")
            }
        }
        
        logger.info(f"1å›APIå‘¼ã³å‡ºã—çµ±åˆè¦ç´„ç”Ÿæˆå®Œäº†: {total_articles}ä»¶ã®è¨˜äº‹ã‚’å‡¦ç†")
        return result
        
    except Exception as e:
        logger.error(f"çµ±åˆè¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return None


if __name__ == '__main__':
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    from dotenv import load_dotenv
    load_dotenv()
    
    test_api_key = os.getenv("GEMINI_API_KEY")
    if not test_api_key:
        raise ValueError("ç’°å¢ƒå¤‰æ•° 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
    test_grouped_articles = {
        "japan": [
            {
                "title": "æ—¥éŠ€ã€æ”¿ç­–é‡‘åˆ©æ®ãˆç½®ãæ±ºå®š",
                "summary": "æ—¥æœ¬éŠ€è¡Œã¯é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã§æ”¿ç­–é‡‘åˆ©ã‚’æ®ãˆç½®ãã€ç·©å’Œçš„ãªé‡‘èæ”¿ç­–ã‚’ç¶™ç¶šã™ã‚‹ã“ã¨ã‚’æ±ºå®šã—ãŸã€‚",
                "category": "é‡‘èæ”¿ç­–"
            },
            {
                "title": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã€å¢—ç›Šã‚’ç™ºè¡¨",
                "summary": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã¯å››åŠæœŸæ±ºç®—ã§å‰å¹´åŒæœŸæ¯”å¢—ç›Šã‚’ç™ºè¡¨ã€æµ·å¤–è²©å£²ãŒå¥½èª¿ã ã£ãŸã€‚",
                "category": "ä¼æ¥­æ¥­ç¸¾"
            }
        ],
        "usa": [
            {
                "title": "FRBã€åˆ©ä¸Šã’ã‚’æ¤œè¨",
                "summary": "ç±³é€£é‚¦æº–å‚™åˆ¶åº¦ç†äº‹ä¼šã¯æ¬¡å›ä¼šåˆã§ã®åˆ©ä¸Šã’å®Ÿæ–½ã‚’ç¤ºå”†ã€ã‚¤ãƒ³ãƒ•ãƒ¬æŠ‘åˆ¶ã‚’å„ªå…ˆã™ã‚‹å§¿å‹¢ã€‚",
                "category": "é‡‘èæ”¿ç­–"
            }
        ]
    }
    
    print("--- Proçµ±åˆè¦ç´„ãƒ†ã‚¹ãƒˆ ---")
    config = ProSummaryConfig(min_articles_threshold=2)
    result = create_integrated_summaries(test_api_key, test_grouped_articles, config)
    
    if result:
        print(f"\n=== çµ±åˆè¦ç´„çµæœ ===")
        unified_summary = result['unified_summary']
        
        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º
        for section_name, content in unified_summary.items():
            section_names = {
                'regional_summaries': 'åœ°åŸŸåˆ¥å¸‚å ´æ¦‚æ³',
                'global_overview': 'ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ç·æ‹¬',
                'cross_regional_analysis': 'åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ',
                'key_trends': 'æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å°†æ¥å±•æœ›',
                'risk_factors': 'ãƒªã‚¹ã‚¯è¦å› ãƒ»æŠ•è³‡æ©Ÿä¼š'
            }
            display_name = section_names.get(section_name, section_name)
            print(f"\n--- {display_name} ---")
            print(f"æ–‡å­—æ•°: {len(content)}å­—")
            print(f"å†…å®¹: {content[:100]}...")
        
        print(f"\n=== ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ ===")
        print(f"ç·è¨˜äº‹æ•°: {result['metadata']['total_articles']}")
        print(f"åœ°åŸŸåˆ¥: {result['metadata']['articles_by_region']}")
        print(f"å‡¦ç†æ™‚é–“: {result['metadata']['processing_time_ms']}ms")
        print(f"ãƒ¢ãƒ‡ãƒ«: {result['metadata']['model_version']}")
    else:
        print("ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")