# -*- coding: utf-8 -*-

import google.generativeai as genai
import os
import json
import re
import time
from typing import Optional, Dict, Any, List
import logging
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ProSummaryConfig:
    """Proçµ±åˆè¦ç´„ã®è¨­å®šã‚¯ãƒ©ã‚¹"""
    enabled: bool = True
    min_articles_threshold: int = 10
    max_daily_executions: int = 3
    execution_hours: List[int] = None  # [9, 15, 21] # JST
    cost_limit_monthly: float = 50.0  # USD
    timeout_seconds: int = 180
    model_name: str = "gemini-2.5-pro"
    
    def __post_init__(self):
        if self.execution_hours is None:
            self.execution_hours = list(range(24))  # 24æ™‚é–“ã„ã¤ã§ã‚‚å®Ÿè¡Œå¯èƒ½


class ProSummarizer:
    """Gemini 2.5 Proã«ã‚ˆã‚‹çµ±åˆè¦ç´„æ©Ÿèƒ½"""
    
    def __init__(self, api_key: str, config: ProSummaryConfig = None):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key (str): Google Gemini APIã‚­ãƒ¼
            config (ProSummaryConfig): è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        self.api_key = api_key
        self.config = config or ProSummaryConfig()
        self.logger = logging.getLogger(__name__)
        
        if not api_key:
            raise ValueError("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        if len(api_key) < 20:  # åŸºæœ¬çš„ãªé•·ã•ãƒã‚§ãƒƒã‚¯
            raise ValueError("Gemini APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ï¼ˆé•·ã•ãŒçŸ­ã™ãã¾ã™ï¼‰")
        
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(self.config.model_name)
            self.logger.info(f"Gemini APIãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ (ãƒ¢ãƒ‡ãƒ«: {self.config.model_name})")
        except Exception as e:
            self.logger.error(f"Gemini APIåˆæœŸåŒ–å¤±æ•—: {e}")
            raise
    
    def generate_regional_summaries(self, grouped_articles: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Dict[str, Any]]:
        """
        åœ°åŸŸåˆ¥çµ±åˆè¦ç´„ã‚’ç”Ÿæˆ
        
        Args:
            grouped_articles (Dict[str, List[Dict]]): åœ°åŸŸåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸè¨˜äº‹ç¾¤
                ä¾‹: {"japan": [{"summary": "...", "title": "...", "category": "..."}], ...}
        
        Returns:
            Dict[str, Dict[str, Any]]: åœ°åŸŸåˆ¥è¦ç´„çµæœ
        """
        regional_summaries = {}
        
        for region, articles in grouped_articles.items():
            if len(articles) == 0:
                continue
                
            start_time = time.time()
            self.logger.info(f"åœ°åŸŸåˆ¥è¦ç´„ç”Ÿæˆé–‹å§‹: {region} ({len(articles)}è¨˜äº‹)")
            
            try:
                prompt = self._build_regional_prompt(region, articles)
                self.logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(prompt)}æ–‡å­—")
                
                response = self.model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=2048,
                        temperature=0.3,
                    )
                )
                
                if not response:
                    raise Exception("Gemini APIã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                
                if not hasattr(response, 'text') or not response.text:
                    raise Exception(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {response}")
                
                self.logger.info(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {len(response.text)}æ–‡å­—")
                
                processing_time_ms = int((time.time() - start_time) * 1000)
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                summary_text = self._extract_summary_text(response.text)
                
                if summary_text:
                    regional_summaries[region] = {
                        "summary_text": summary_text,
                        "articles_count": len(articles),
                        "processing_time_ms": processing_time_ms,
                        "model_version": self.config.model_name
                    }
                    self.logger.info(f"åœ°åŸŸåˆ¥è¦ç´„å®Œäº†: {region} ({len(summary_text)}å­—, {processing_time_ms}ms)")
                else:
                    self.logger.error(f"åœ°åŸŸåˆ¥è¦ç´„ç”Ÿæˆå¤±æ•—: {region}")
                    
            except Exception as e:
                self.logger.error(f"ğŸš¨ åœ°åŸŸåˆ¥è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({region}): {e}")
                print(f"ğŸš¨ FAILED REGION: {region} - Error: {e}")
                # å¤±æ•—ã—ãŸåœ°åŸŸã§ã‚‚å‡¦ç†ã‚’ç¶šè¡Œ
                regional_summaries[region] = {
                    "error": str(e),
                    "articles_count": len(articles),
                    "processing_time_ms": int((time.time() - start_time) * 1000)
                }
                
        return regional_summaries
    
    def generate_global_summary(self, all_articles: List[Dict[str, Any]], 
                              regional_summaries: Dict[str, Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """
        å…¨ä½“å¸‚æ³è¦ç´„ã‚’ç”Ÿæˆ
        
        Args:
            all_articles (List[Dict]): å…¨è¨˜äº‹ã®ãƒªã‚¹ãƒˆ
            regional_summaries (Dict): åœ°åŸŸåˆ¥è¦ç´„ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            Optional[Dict[str, Any]]: å…¨ä½“è¦ç´„çµæœã€å¤±æ•—æ™‚ã¯None
        """
        start_time = time.time()
        self.logger.info(f"å…¨ä½“è¦ç´„ç”Ÿæˆé–‹å§‹ (è¨˜äº‹æ•°: {len(all_articles)}, åœ°åŸŸæ•°: {len(regional_summaries)})")
        
        try:
            prompt = self._build_global_prompt(all_articles, regional_summaries)
            self.logger.info(f"å…¨ä½“è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(prompt)}æ–‡å­—")
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=3072,
                    temperature=0.3,
                )
            )
            
            if not response:
                raise Exception("Gemini APIã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            if not hasattr(response, 'text') or not response.text:
                raise Exception(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {response}")
            
            self.logger.info(f"å…¨ä½“è¦ç´„Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {len(response.text)}æ–‡å­—")
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            summary_text = self._extract_summary_text(response.text)
            
            if summary_text:
                result = {
                    "summary_text": summary_text,
                    "articles_count": len(all_articles),
                    "processing_time_ms": processing_time_ms,
                    "model_version": self.config.model_name
                }
                self.logger.info(f"å…¨ä½“è¦ç´„å®Œäº† ({len(summary_text)}å­—, {processing_time_ms}ms)")
                return result
            else:
                self.logger.error("å…¨ä½“è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡ºã«å¤±æ•—")
                return None
                
        except Exception as e:
            self.logger.error(f"å…¨ä½“è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _build_regional_prompt(self, region: str, articles: List[Dict[str, Any]]) -> str:
        """åœ°åŸŸåˆ¥è¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        region_names = {
            "japan": "æ—¥æœ¬",
            "usa": "ç±³å›½", 
            "china": "ä¸­å›½",
            "europe": "æ¬§å·",
            "other": "ãã®ä»–åœ°åŸŸ"
        }
        
        region_ja = region_names.get(region, region)
        
        # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
        article_summaries = []
        for i, article in enumerate(articles, 1):
            summary = article.get("summary", "").strip()
            title = article.get("title", "").strip()
            category = article.get("category", "ãã®ä»–")
            
            article_summaries.append(f"{i}. ã€{category}ã€‘{title}\n   è¦ç´„: {summary}")
        
        articles_text = "\n\n".join(article_summaries)
        
        prompt = f"""
ä»¥ä¸‹ã®{region_ja}ã«é–¢ã™ã‚‹{len(articles)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åˆ†æã—ã€åœ°åŸŸåˆ¥ã®çµ±åˆè¦ç´„ã‚’400-600å­—ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

## è¦ç´„ä½œæˆã®æŒ‡é‡
1. **ä¸»è¦ãƒˆãƒ¬ãƒ³ãƒ‰**: {region_ja}å¸‚å ´ã®ä¸»è¦ãªå‹•å‘ã¨ç‰¹å¾´
2. **é‡è¦ãªç™ºè¡¨**: çµŒæ¸ˆæŒ‡æ¨™ã€æ”¿ç­–ç™ºè¡¨ã€ä¼æ¥­æ¥­ç¸¾ç­‰ã®é‡è¦ãªç™ºè¡¨
3. **å¸‚å ´ã¸ã®å½±éŸ¿**: æ ªä¾¡ã€ç‚ºæ›¿ã€é‡‘åˆ©ç­‰ã¸ã®å…·ä½“çš„ãªå½±éŸ¿
4. **åœ°åŸŸç‰¹æœ‰ã®èª²é¡Œ**: {region_ja}ç‰¹æœ‰ã®çµŒæ¸ˆèª²é¡Œã‚„æ©Ÿä¼š

## è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
{articles_text}

## å‡ºåŠ›å½¢å¼
400-600å­—ã®çµ±åˆè¦ç´„æ–‡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯é©åº¦ã«ä½¿ç”¨ã—ã€å¸‚å ´é–¢ä¿‚è€…ã«ã¨ã£ã¦æœ‰ç”¨ã§èª­ã¿ã‚„ã™ã„å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def _build_global_prompt(self, all_articles: List[Dict[str, Any]], 
                           regional_summaries: Dict[str, Dict[str, Any]]) -> str:
        """å…¨ä½“è¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        
        # åœ°åŸŸåˆ¥è¦ç´„ã‚’ã¾ã¨ã‚ã‚‹
        regional_text = []
        for region, summary_data in regional_summaries.items():
            region_names = {
                "japan": "æ—¥æœ¬",
                "usa": "ç±³å›½",
                "china": "ä¸­å›½", 
                "europe": "æ¬§å·",
                "other": "ãã®ä»–åœ°åŸŸ"
            }
            region_ja = region_names.get(region, region)
            summary = summary_data.get("summary_text", "")
            article_count = summary_data.get("articles_count", 0)
            
            regional_text.append(f"### {region_ja}å¸‚æ³ ({article_count}è¨˜äº‹)\n{summary}")
        
        regional_summaries_text = "\n\n".join(regional_text)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        category_counts = {}
        for article in all_articles:
            category = article.get("category", "ãã®ä»–")
            category_counts[category] = category_counts.get(category, 0) + 1
        
        category_stats = ", ".join([f"{cat}: {count}ä»¶" for cat, count in category_counts.items()])
        
        prompt = f"""
ä»¥ä¸‹ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚æ³ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€å…¨ä½“å¸‚æ³ã®çµ±åˆè¦ç´„ã‚’800-1000å­—ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

## åˆ†æãƒ‡ãƒ¼ã‚¿
- **ç·è¨˜äº‹æ•°**: {len(all_articles)}ä»¶
- **ã‚«ãƒ†ã‚´ãƒªåˆ¥**: {category_stats}
- **åˆ†æå¯¾è±¡åœ°åŸŸ**: {', '.join(regional_summaries.keys())}

## åœ°åŸŸåˆ¥è¦ç´„
{regional_summaries_text}

## è¦ç´„ä½œæˆã®æŒ‡é‡
1. **ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒˆãƒ¬ãƒ³ãƒ‰**: ä¸–ç•Œå¸‚å ´å…¨ä½“ã®ä¸»è¦ãªå‹•å‘ã¨æ–¹å‘æ€§
2. **åœ°åŸŸé–“ç›¸äº’ä½œç”¨**: å„åœ°åŸŸå¸‚å ´é–“ã®ç›¸äº’å½±éŸ¿ã¨æ³¢åŠåŠ¹æœ
3. **ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æ**: æ¥­ç•Œãƒ»åˆ†é‡åˆ¥ã®æ³¨ç›®ã™ã¹ãå‹•å‘
4. **ãƒªã‚¹ã‚¯ã¨æ©Ÿä¼š**: å¸‚å ´å‚åŠ è€…ãŒæ³¨æ„ã™ã¹ããƒªã‚¹ã‚¯ã¨æŠ•è³‡æ©Ÿä¼š
5. **ä»Šå¾Œã®è¦‹é€šã—**: çŸ­æœŸçš„ãªå¸‚å ´äºˆæ¸¬ã¨æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ

## å‡ºåŠ›å½¢å¼
800-1000å­—ã®ç·åˆå¸‚æ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æŠ•è³‡å®¶ãƒ»å¸‚å ´é–¢ä¿‚è€…ã«ã¨ã£ã¦å®Ÿç”¨çš„ã§æ´å¯Ÿã«å¯Œã‚“ã å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def _extract_summary_text(self, response_text: str) -> Optional[str]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¦ç´„éƒ¨åˆ†ã‚’æŠ½å‡º"""
        if not response_text:
            return None
        
        # ä¸è¦ãªå‰å¾Œã®è£…é£¾ã‚’é™¤å»
        text = response_text.strip()
        
        # ```markdown ãªã©ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯é™¤å»
        text = re.sub(r"```[a-zA-Z]*\n(.*?)\n```", r"\1", text, flags=re.DOTALL)
        
        # æœ€çµ‚çš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
        return text.strip() if text.strip() else None


def create_integrated_summaries(api_key: str, grouped_articles: Dict[str, List[Dict[str, Any]]], 
                               config: ProSummaryConfig = None) -> Optional[Dict[str, Any]]:
    """
    çµ±åˆè¦ç´„ã‚’ä½œæˆã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    Args:
        api_key (str): Gemini APIã‚­ãƒ¼
        grouped_articles (Dict): åœ°åŸŸåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸè¨˜äº‹
        config (ProSummaryConfig): è¨­å®š
    
    Returns:
        Optional[Dict[str, Any]]: çµ±åˆè¦ç´„çµæœã€å¤±æ•—æ™‚ã¯None
    """
    logger = logging.getLogger(__name__)
    
    try:
        # è¨˜äº‹æ•°ãƒã‚§ãƒƒã‚¯
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        if config and total_articles < config.min_articles_threshold:
            logger.warning(f"è¨˜äº‹æ•°ãŒé–¾å€¤æœªæº€ã§ã™ ({total_articles} < {config.min_articles_threshold})")
            return None
        
        # Pro Summarizerã‚’åˆæœŸåŒ–
        summarizer = ProSummarizer(api_key, config)
        
        # åœ°åŸŸåˆ¥è¦ç´„ç”Ÿæˆ
        regional_summaries = summarizer.generate_regional_summaries(grouped_articles)
        
        if not regional_summaries:
            logger.error("åœ°åŸŸåˆ¥è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
        
        # å…¨è¨˜äº‹ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–
        all_articles = []
        for articles in grouped_articles.values():
            all_articles.extend(articles)
        
        # å…¨ä½“è¦ç´„ç”Ÿæˆ
        global_summary = summarizer.generate_global_summary(all_articles, regional_summaries)
        
        if not global_summary:
            logger.error("å…¨ä½“è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
        
        # çµ±è¨ˆæƒ…å ±ã‚’æ•´ç†
        articles_by_region = {region: len(articles) for region, articles in grouped_articles.items()}
        
        result = {
            "global_summary": global_summary,
            "regional_summaries": regional_summaries,
            "metadata": {
                "total_articles": total_articles,
                "articles_by_region": articles_by_region,
                "processing_timestamp": datetime.utcnow().isoformat()
            }
        }
        
        logger.info(f"çµ±åˆè¦ç´„ç”Ÿæˆå®Œäº†: å…¨ä½“1ä»¶, åœ°åŸŸåˆ¥{len(regional_summaries)}ä»¶")
        return result
        
    except Exception as e:
        logger.error(f"çµ±åˆè¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return None


if __name__ == '__main__':
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    from dotenv import load_dotenv
    load_dotenv()
    
    test_api_key = os.getenv("GEMINI_API_KEY")
    if not test_api_key:
        raise ValueError("ç’°å¢ƒå¤‰æ•° 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
    test_grouped_articles = {
        "japan": [
            {
                "title": "æ—¥éŠ€ã€æ”¿ç­–é‡‘åˆ©æ®ãˆç½®ãæ±ºå®š",
                "summary": "æ—¥æœ¬éŠ€è¡Œã¯é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã§æ”¿ç­–é‡‘åˆ©ã‚’æ®ãˆç½®ãã€ç·©å’Œçš„ãªé‡‘èæ”¿ç­–ã‚’ç¶™ç¶šã™ã‚‹ã“ã¨ã‚’æ±ºå®šã—ãŸã€‚",
                "category": "é‡‘èæ”¿ç­–"
            },
            {
                "title": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã€å¢—ç›Šã‚’ç™ºè¡¨",
                "summary": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã¯å››åŠæœŸæ±ºç®—ã§å‰å¹´åŒæœŸæ¯”å¢—ç›Šã‚’ç™ºè¡¨ã€æµ·å¤–è²©å£²ãŒå¥½èª¿ã ã£ãŸã€‚",
                "category": "ä¼æ¥­æ¥­ç¸¾"
            }
        ],
        "usa": [
            {
                "title": "FRBã€åˆ©ä¸Šã’ã‚’æ¤œè¨",
                "summary": "ç±³é€£é‚¦æº–å‚™åˆ¶åº¦ç†äº‹ä¼šã¯æ¬¡å›ä¼šåˆã§ã®åˆ©ä¸Šã’å®Ÿæ–½ã‚’ç¤ºå”†ã€ã‚¤ãƒ³ãƒ•ãƒ¬æŠ‘åˆ¶ã‚’å„ªå…ˆã™ã‚‹å§¿å‹¢ã€‚",
                "category": "é‡‘èæ”¿ç­–"
            }
        ]
    }
    
    print("--- Proçµ±åˆè¦ç´„ãƒ†ã‚¹ãƒˆ ---")
    config = ProSummaryConfig(min_articles_threshold=2)
    result = create_integrated_summaries(test_api_key, test_grouped_articles, config)
    
    if result:
        print(f"\n=== å…¨ä½“è¦ç´„ ===")
        print(f"æ–‡å­—æ•°: {len(result['global_summary']['summary_text'])}å­—")
        print(f"å†…å®¹: {result['global_summary']['summary_text'][:100]}...")
        
        print(f"\n=== åœ°åŸŸåˆ¥è¦ç´„ ===")
        for region, summary_data in result['regional_summaries'].items():
            print(f"{region}: {len(summary_data['summary_text'])}å­—")
            print(f"  {summary_data['summary_text'][:50]}...")
        
        print(f"\n=== ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ ===")
        print(f"ç·è¨˜äº‹æ•°: {result['metadata']['total_articles']}")
        print(f"åœ°åŸŸåˆ¥: {result['metadata']['articles_by_region']}")
    else:
        print("ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")