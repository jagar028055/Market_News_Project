# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è©³ç´°

RAGã‚·ã‚¹ãƒ†ãƒ å†…éƒ¨ã§ã®ãƒ‡ãƒ¼ã‚¿ã®æµã‚Œã¨å‡¦ç†ãƒ—ãƒ­ã‚»ã‚¹ã‚’è©³ç´°ã«è§£èª¬ã—ã¾ã™ã€‚

## ğŸ“‹ å‡¦ç†ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥è©³ç´°

### ãƒ•ã‚§ãƒ¼ã‚º1: ãƒ‡ãƒ¼ã‚¿å—ã‘å–ã‚Šãƒ»å‰å‡¦ç†

```mermaid
graph LR
    A[Market News System] --> B{ãƒ‡ãƒ¼ã‚¿å½¢å¼ç¢ºèª}
    B -->|æ—¥æ¬¡ã‚µãƒãƒªãƒ¼| C[ã‚µãƒãƒªãƒ¼å‰å‡¦ç†]
    B -->|è¨˜äº‹ãƒ‡ãƒ¼ã‚¿| D[è¨˜äº‹å‰å‡¦ç†]
    
    C --> E[ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º]
    D --> E
    
    E --> F[ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼]
    F --> G[RAG Manager ã¸]
    
    subgraph "å‰å‡¦ç†å†…å®¹"
        H[é‡è¤‡ãƒã‚§ãƒƒã‚¯]
        I[æ–‡å­—æ•°ã‚«ã‚¦ãƒ³ãƒˆ]
        J[ã‚«ãƒ†ã‚´ãƒªåˆ†é¡]
        K[æ—¥ä»˜æ­£è¦åŒ–]
    end
```

#### å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿å¤‰æ›ä¾‹
```python
# å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ä¾‹
input_article = {
    "title": "AIæŠ€è¡“ã®æœ€æ–°å‹•å‘ã«ã¤ã„ã¦",
    "content": "æœ¬æ—¥ã€å¤§æ‰‹ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ãŒ...",
    "published_at": "2024-08-24T10:30:00Z",
    "category": "tech"
}

# å‰å‡¦ç†å¾Œ
processed_data = {
    "id": "uuid-generated",
    "title": "AIæŠ€è¡“ã®æœ€æ–°å‹•å‘ã«ã¤ã„ã¦",
    "content": "æœ¬æ—¥ã€å¤§æ‰‹ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ãŒ...",
    "doc_type": "article",
    "metadata": {
        "category": "technology",
        "source": "market_news",
        "published_date": "2024-08-24",
        "word_count": 1250,
        "language": "ja"
    },
    "created_at": "2024-08-24T10:30:00Z"
}
```

### ãƒ•ã‚§ãƒ¼ã‚º2: ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°

```mermaid
graph TD
    A[é•·æ–‡ãƒ†ã‚­ã‚¹ãƒˆ] --> B[æ–‡ç« å¢ƒç•Œæ¤œå‡º]
    B --> C[600æ–‡å­—å˜ä½ã§åˆ†å‰²]
    C --> D[100æ–‡å­—ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—]
    
    D --> E{ãƒãƒ£ãƒ³ã‚¯å“è³ªãƒã‚§ãƒƒã‚¯}
    E -->|OK| F[ãƒãƒ£ãƒ³ã‚¯é…åˆ—ç”Ÿæˆ]
    E -->|NG| G[å†åˆ†å‰²èª¿æ•´]
    G --> D
    
    F --> H[ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸]
    H --> I[Embedding Generator ã¸]
    
    subgraph "ãƒãƒ£ãƒ³ã‚¯ä¾‹"
        J["ãƒãƒ£ãƒ³ã‚¯1: æœ¬æ—¥ã€å¤§æ‰‹ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ãŒæ–°ã—ã„AIæŠ€è¡“ã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚ã“ã®æŠ€è¡“ã¯è‡ªç„¶è¨€èªå‡¦ç†ã®åˆ†é‡ã§é©æ–°çš„ãªé€²æ­©ã‚’ã‚‚ãŸã‚‰ã™ã¨æœŸå¾…ã•ã‚Œã¦ãŠã‚Š...ï¼ˆ600æ–‡å­—ï¼‰"]
        K["ãƒãƒ£ãƒ³ã‚¯2: ...æœŸå¾…ã•ã‚Œã¦ãŠã‚Šã€é–¢é€£éŠ˜æŸ„ã®æ ªä¾¡ãŒå¤§å¹…ã«ä¸Šæ˜‡ã—ã¦ã„ã¾ã™ã€‚å¸‚å ´ã‚¢ãƒŠãƒªã‚¹ãƒˆã¯ã€ã“ã®æŠ€è¡“ãŒä»Šå¾Œ5å¹´é–“ã§æ¥­ç•Œå…¨ä½“ã«å¤§ããªå¤‰é©ã‚’...ï¼ˆ600æ–‡å­—ï¼‰"]
    end
```

#### ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®è©³ç´°ãƒ­ã‚¸ãƒƒã‚¯
```python
def create_chunks(text, chunk_size=600, overlap=100):
    chunks = []
    start = 0
    
    while start < len(text):
        # ãƒãƒ£ãƒ³ã‚¯çµ‚äº†ä½ç½®ã‚’è¨ˆç®—
        end = start + chunk_size
        
        # æ–‡ç« å¢ƒç•Œã§èª¿æ•´ï¼ˆå¥èª­ç‚¹ã§åˆ‡ã‚‹ï¼‰
        if end < len(text):
            # æœ€å¾Œã®å¥ç‚¹ã¾ãŸã¯æ”¹è¡Œã‚’æ¢ã™
            for i in range(end, start + chunk_size//2, -1):
                if text[i] in ['ã€‚', 'ï¼', 'ï¼Ÿ', '\n']:
                    end = i + 1
                    break
        
        chunk = text[start:end]
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        chunk_data = {
            "content": chunk,
            "chunk_index": len(chunks),
            "start_pos": start,
            "end_pos": end,
            "word_count": len(chunk)
        }
        
        chunks.append(chunk_data)
        
        # æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã®é–‹å§‹ä½ç½®ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚ã‚Šï¼‰
        start = end - overlap
        
    return chunks
```

### ãƒ•ã‚§ãƒ¼ã‚º3: åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ

```mermaid
graph LR
    A[ãƒãƒ£ãƒ³ã‚¯é…åˆ—] --> B[Embedding Generator]
    
    subgraph "ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹"
        C[ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–]
        D[ãƒˆãƒ¼ã‚¯ãƒ³åŒ–]
        E[sentence-transformers]
        F[384æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«]
    end
    
    B --> C
    C --> D
    D --> E
    E --> F
    
    F --> G[ãƒ™ã‚¯ãƒˆãƒ«æ­£è¦åŒ–]
    G --> H[ãƒãƒƒãƒå‡¦ç†]
    H --> I[Supabaseä¿å­˜æº–å‚™]
    
    subgraph "æŠ€è¡“è©³ç´°"
        J[ãƒ¢ãƒ‡ãƒ«: all-MiniLM-L6-v2]
        K[æ¬¡å…ƒ: 384]
        L[æ­£è¦åŒ–: L2 norm]
        M[ãƒãƒƒãƒã‚µã‚¤ã‚º: 32]
    end
```

#### åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã®å®Ÿè£…ä¾‹
```python
def generate_embeddings(chunks):
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿æŠ½å‡º
    texts = [chunk['content'] for chunk in chunks]
    
    # ãƒãƒƒãƒå‡¦ç†ã§é«˜é€ŸåŒ–
    embeddings = model.encode(
        texts,
        batch_size=32,
        normalize_embeddings=True,  # L2æ­£è¦åŒ–
        show_progress_bar=True
    )
    
    # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã«åŸ‹ã‚è¾¼ã¿ã‚’è¿½åŠ 
    for chunk, embedding in zip(chunks, embeddings):
        chunk['embedding'] = embedding.tolist()
    
    return chunks
```

### ãƒ•ã‚§ãƒ¼ã‚º4: Supabaseãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜

```mermaid
graph TD
    A[å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿] --> B{ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹}
    
    B --> C[documentsãƒ†ãƒ¼ãƒ–ãƒ«æŠ•å…¥]
    C --> D[document_idå–å¾—]
    
    D --> E[chunksãƒ†ãƒ¼ãƒ–ãƒ«ä¸€æ‹¬æŠ•å…¥]
    E --> F[Storageãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜]
    
    F --> G{ä¿å­˜æˆåŠŸï¼Ÿ}
    G -->|Yes| H[ã‚³ãƒŸãƒƒãƒˆ]
    G -->|No| I[ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯]
    
    H --> J[ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°]
    J --> K[ä¿å­˜å®Œäº†é€šçŸ¥]
    
    I --> L[ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²]
    L --> M[ãƒªãƒˆãƒ©ã‚¤ã¾ãŸã¯ä¸­æ–­]
    
    subgraph "ä¸¦åˆ—å‡¦ç†"
        N[documentsä¿å­˜]
        O[chunksä¿å­˜]
        P[Storageä¿å­˜]
    end
```

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã®å®Ÿè£…
```python
async def save_to_supabase(document_data, chunks_data):
    async with supabase_client.transaction():
        try:
            # 1. documentsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
            doc_result = await supabase_client.table('documents').insert({
                'title': document_data['title'],
                'content': document_data['content'],
                'doc_type': document_data['doc_type'],
                'metadata': document_data['metadata']
            }).execute()
            
            document_id = doc_result.data[0]['id']
            
            # 2. chunksãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¸€æ‹¬ä¿å­˜
            chunks_to_insert = []
            for chunk in chunks_data:
                chunks_to_insert.append({
                    'document_id': document_id,
                    'content': chunk['content'],
                    'embedding': chunk['embedding'],
                    'chunk_index': chunk['chunk_index'],
                    'metadata': chunk.get('metadata', {})
                })
            
            await supabase_client.table('chunks').insert(chunks_to_insert).execute()
            
            # 3. Storageã«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆä¸¦åˆ—ï¼‰
            await save_to_storage(document_data, document_id)
            
            return {'success': True, 'document_id': document_id}
            
        except Exception as e:
            # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯è‡ªå‹•çš„ã«å®Ÿè¡Œã•ã‚Œã‚‹
            return {'success': False, 'error': str(e)}
```

### ãƒ•ã‚§ãƒ¼ã‚º5: æ¤œç´¢å‡¦ç†

```mermaid
graph LR
    A[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª] --> B[ã‚¯ã‚¨ãƒªå‰å‡¦ç†]
    B --> C[åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ]
    C --> D[ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼æ¤œç´¢]
    
    subgraph "é¡ä¼¼æ¤œç´¢è©³ç´°"
        E[cosineé¡ä¼¼åº¦è¨ˆç®—]
        F[Top-Kå–å¾—]
        G[ã—ãã„å€¤ãƒ•ã‚£ãƒ«ã‚¿]
        H[ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿]
    end
    
    D --> E
    E --> F
    F --> G
    G --> H
    
    H --> I[çµæœã®é‡è¤‡é™¤å»]
    I --> J[ã‚¹ã‚³ã‚¢èª¿æ•´]
    J --> K[ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ•´å½¢]
    K --> L[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¿”å´]
```

#### æ¤œç´¢SQLã®è©³ç´°
```sql
-- ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼æ¤œç´¢ã‚¯ã‚¨ãƒª
SELECT 
    c.id as chunk_id,
    d.id as document_id,
    d.title,
    c.content,
    (c.embedding <=> $1::vector) as similarity,
    c.metadata,
    d.metadata as doc_metadata,
    d.created_at
FROM chunks c
JOIN documents d ON c.document_id = d.id
WHERE 
    -- é¡ä¼¼åº¦ã—ãã„å€¤ãƒ•ã‚£ãƒ«ã‚¿
    (c.embedding <=> $1::vector) < $2
    -- æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
    AND d.created_at >= $3
    -- ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    AND ($4::text IS NULL OR d.metadata->>'category' = $4)
ORDER BY 
    c.embedding <=> $1::vector
LIMIT $5;
```

## ğŸ” ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥
```sql
-- ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆIVF-Flatï¼‰
CREATE INDEX idx_chunks_embedding_ivfflat 
ON chunks 
USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);

-- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_chunks_metadata_category 
ON chunks USING GIN ((metadata->>'category'));

-- æ—¥ä»˜ç¯„å›²æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_documents_created_at 
ON documents (created_at DESC);
```

### ãƒãƒƒãƒå‡¦ç†æœ€é©åŒ–
```python
class BatchProcessor:
    def __init__(self, batch_size=100):
        self.batch_size = batch_size
        
    async def process_documents(self, documents):
        batches = [
            documents[i:i+self.batch_size] 
            for i in range(0, len(documents), self.batch_size)
        ]
        
        tasks = []
        for batch in batches:
            task = asyncio.create_task(self.process_batch(batch))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return sum(results, [])  # ãƒ•ãƒ©ãƒƒãƒˆåŒ–
```

## ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### ç›£è¦–å¯¾è±¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
```python
class SystemMetrics:
    def collect_metrics(self):
        return {
            "database_metrics": {
                "total_documents": self.count_documents(),
                "total_chunks": self.count_chunks(),
                "average_similarity_score": self.avg_similarity(),
                "storage_usage_mb": self.storage_usage()
            },
            "performance_metrics": {
                "search_latency_ms": self.search_latency(),
                "indexing_time_s": self.indexing_time(),
                "embedding_generation_time_s": self.embedding_time()
            },
            "error_metrics": {
                "failed_searches": self.failed_searches(),
                "timeout_errors": self.timeout_errors(),
                "connection_errors": self.connection_errors()
            }
        }
```

<function_calls>
<invoke name="mcp__market-news-server__TodoWrite">
<parameter name="todos">[{"content": "RAG\u30b7\u30b9\u30c6\u30e0\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u6574\u7406", "status": "in_progress", "activeForm": "RAG\u30b7\u30b9\u30c6\u30e0\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u6574\u7406\u4e2d"}, {"content": "\u30c7\u30fc\u30bf\u30d5\u30ed\u30fc\u8a73\u7d30\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u4f5c\u6210", "status": "completed", "activeForm": "\u30c7\u30fc\u30bf\u30d5\u30ed\u30fc\u8a73\u7d30\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u4f5c\u6210"}, {"content": "\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8\u30ac\u30a4\u30c9\u4f5c\u6210", "status": "in_progress", "activeForm": "\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8\u30ac\u30a4\u30c9\u4f5c\u6210"}]