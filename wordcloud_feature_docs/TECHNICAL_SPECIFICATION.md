# æ—¥æ¬¡ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰æ©Ÿèƒ½ - æŠ€è¡“ä»•æ§˜æ›¸

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦
```
Market News Project
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ wordcloud/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ generator.py          # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â”‚   â”œâ”€â”€ processor.py          # ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
â”‚   â”‚   â”œâ”€â”€ visualizer.py         # è¦–è¦šåŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
â”‚   â”‚   â””â”€â”€ config.py             # è¨­å®šç®¡ç†
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ models.py             # WordCloudDataãƒ¢ãƒ‡ãƒ«è¿½åŠ 
â”‚   â””â”€â”€ html/
â”‚       â””â”€â”€ html_generator.py     # HTMLçµ±åˆæ©Ÿèƒ½æ‹¡å¼µ
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ wordcloud.css         # å°‚ç”¨ã‚¹ã‚¿ã‚¤ãƒ«
â”‚   â””â”€â”€ fonts/
â”‚       â””â”€â”€ NotoSansCJK-Regular.ttf  # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ
â””â”€â”€ wordcloud_feature_docs/       # æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
```

---

## ğŸ”§ ã‚³ã‚¢æŠ€è¡“ä»•æ§˜

### 1. ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³

#### 1.1 `WordCloudGenerator`ã‚¯ãƒ©ã‚¹
```python
class WordCloudGenerator:
    """
    ãƒ¡ã‚¤ãƒ³ã®ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, config: WordCloudConfig):
        self.config = config
        self.processor = TextProcessor(config)
        self.visualizer = WordCloudVisualizer(config)
        
    def generate_daily_wordcloud(self, articles: List[Dict]) -> WordCloudResult:
        """
        æ—¥æ¬¡ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            articles: è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
            
        Returns:
            WordCloudResult: ç”Ÿæˆçµæœ
        """
        
    def _extract_text_content(self, articles: List[Dict]) -> str:
        """è¨˜äº‹ã‹ã‚‰æœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        
    def _calculate_word_frequencies(self, text: str) -> Dict[str, int]:
        """å˜èªé »åº¦è¨ˆç®—"""
        
    def _apply_financial_weights(self, frequencies: Dict[str, int]) -> Dict[str, int]:
        """é‡‘èé‡è¦èªå¥ã®é‡ã¿ä»˜ã‘é©ç”¨"""
```

#### 1.2 è¨­å®šä»•æ§˜
```python
@dataclass
class WordCloudConfig:
    # ç”»åƒè¨­å®š
    width: int = 800
    height: int = 400
    background_color: str = "rgba(0,0,0,0)"
    
    # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    font_path: str = "assets/fonts/NotoSansCJK-Regular.ttf"
    max_font_size: int = 100
    min_font_size: int = 20
    
    # è‰²å½©è¨­å®š
    color_scheme: List[str] = field(default_factory=lambda: [
        "#2E8B57", "#32CD32", "#4682B4", 
        "#6495ED", "#DC143C", "#FF6347"
    ])
    
    # å‡¦ç†è¨­å®š
    max_words: int = 100
    relative_scaling: float = 0.5
    min_word_frequency: int = 2
    
    # æ—¥æœ¬èªå‡¦ç†è¨­å®š
    mecab_dicdir: Optional[str] = None
    stopwords_file: str = "assets/config/stopwords_japanese.txt"
    
    # é‡‘èé‡è¦èªå¥é‡ã¿
    financial_weights: Dict[str, float] = field(default_factory=lambda: {
        "é‡‘åˆ©": 3.0, "GDP": 2.5, "ã‚¤ãƒ³ãƒ•ãƒ¬": 2.8,
        "æ—¥éŠ€": 3.2, "FRB": 3.0, "ECB": 2.5,
        "æ ªä¾¡": 2.8, "å††å®‰": 2.5, "ãƒ‰ãƒ«": 2.3,
        "æ±ºç®—": 2.2, "æ¥­ç¸¾": 2.0, "æŠ•è³‡": 2.4
    })
```

### 2. ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 

#### 2.1 `TextProcessor`ã‚¯ãƒ©ã‚¹
```python
class TextProcessor:
    """
    ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†å°‚ç”¨ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, config: WordCloudConfig):
        self.config = config
        self.mecab = MeCab.Tagger(f"-d {config.mecab_dicdir}" if config.mecab_dicdir else "")
        self.stopwords = self._load_stopwords()
        
    def process_articles_text(self, articles: List[Dict]) -> str:
        """è¨˜äº‹ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†"""
        
    def _extract_meaningful_words(self, text: str) -> List[str]:
        """å½¢æ…‹ç´ è§£æã§æ„å‘³ã®ã‚ã‚‹å˜èªã‚’æŠ½å‡º"""
        
    def _filter_words(self, words: List[str]) -> List[str]:
        """ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å»ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        
    def _normalize_financial_terms(self, words: List[str]) -> List[str]:
        """é‡‘èç”¨èªã®æ­£è¦åŒ–"""
```

#### 2.2 æ—¥æœ¬èªå‡¦ç†è©³ç´°
```python
# å½¢æ…‹ç´ è§£æè¨­å®š
MECAB_POS_FILTERS = [
    "åè©,ä¸€èˆ¬",      # ä¸€èˆ¬åè©
    "åè©,å›ºæœ‰åè©",  # å›ºæœ‰åè©
    "åè©,ã‚µå¤‰æ¥ç¶š",  # ã‚µå¤‰å‹•è©èªå¹¹
    "å‹•è©,è‡ªç«‹",      # è‡ªç«‹å‹•è©
    "å½¢å®¹è©,è‡ªç«‹",    # è‡ªç«‹å½¢å®¹è©
]

# é™¤å¤–ã™ã‚‹å“è©
EXCLUDE_POS = [
    "åŠ©è©", "åŠ©å‹•è©", "æ¥ç¶šè©", "æ„Ÿå‹•è©", "è¨˜å·", "ãƒ•ã‚£ãƒ©ãƒ¼"
]

# æœ€å°æ–‡å­—æ•°
MIN_WORD_LENGTH = 2

# æ•°å­—ãƒ»è¨˜å·ãƒ‘ã‚¿ãƒ¼ãƒ³
EXCLUDE_PATTERNS = [
    r'^\d+$',           # æ•°å­—ã®ã¿
    r'^[a-zA-Z]$',      # 1æ–‡å­—ã®è‹±å­—
    r'^[ã€‚ã€]$',        # å¥èª­ç‚¹
]
```

### 3. è¦–è¦šåŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

#### 3.1 `WordCloudVisualizer`ã‚¯ãƒ©ã‚¹
```python
class WordCloudVisualizer:
    """
    ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰è¦–è¦šåŒ–å°‚ç”¨ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, config: WordCloudConfig):
        self.config = config
        
    def create_wordcloud_image(self, word_frequencies: Dict[str, int]) -> str:
        """
        ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”»åƒç”Ÿæˆ
        
        Returns:
            str: base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
        """
        
    def _color_function(self, word: str, font_size: int, 
                       position: Tuple[int, int], orientation: int, 
                       font_path: str, random_state: int) -> str:
        """ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼é–¢æ•°"""
        
    def _generate_base64_image(self, wordcloud_obj) -> str:
        """WordCloudã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰base64ç”»åƒç”Ÿæˆ"""
```

#### 3.2 è‰²å½©è¨­è¨ˆ
```python
# é‡‘èãƒ†ãƒ¼ãƒé…è‰²ãƒ‘ãƒ¬ãƒƒãƒˆ
COLOR_PALETTES = {
    "professional": {
        "primary": ["#1E3A8A", "#3B82F6", "#60A5FA"],     # é’ç³»
        "positive": ["#059669", "#10B981", "#34D399"],    # ç·‘ç³»ï¼ˆä¸Šæ˜‡ï¼‰
        "negative": ["#DC2626", "#EF4444", "#F87171"],    # èµ¤ç³»ï¼ˆä¸‹é™ï¼‰
        "neutral": ["#6B7280", "#9CA3AF", "#D1D5DB"]     # ã‚°ãƒ¬ãƒ¼ç³»
    }
}

# é‡è¦åº¦ã«ã‚ˆã‚‹è‰²åˆ†ã‘
def get_word_color(word: str, frequency: int, max_frequency: int) -> str:
    """
    å˜èªã®é‡è¦åº¦ã«åŸºã¥ãè‰²é¸æŠ
    
    Args:
        word: å¯¾è±¡å˜èª
        frequency: å‡ºç¾é »åº¦
        max_frequency: æœ€å¤§å‡ºç¾é »åº¦
    
    Returns:
        str: HEXã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰
    """
```

---

## ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

### 1. æ–°è¦ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ 

#### 1.1 `wordcloud_data`ãƒ†ãƒ¼ãƒ–ãƒ«
```sql
CREATE TABLE wordcloud_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id INTEGER NOT NULL,
    generated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- ç”»åƒãƒ‡ãƒ¼ã‚¿
    image_base64 TEXT NOT NULL,
    image_size_bytes INTEGER,
    
    -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    total_articles INTEGER NOT NULL,
    total_words INTEGER NOT NULL,
    unique_words INTEGER NOT NULL,
    
    -- å‡¦ç†çµ±è¨ˆ
    generation_time_ms INTEGER,
    memory_usage_mb REAL,
    
    -- è¨­å®šæƒ…å ±
    config_version VARCHAR(20),
    
    -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    FOREIGN KEY (session_id) REFERENCES scraping_sessions(id),
    INDEX idx_wordcloud_generated (generated_at),
    INDEX idx_wordcloud_session (session_id)
);
```

#### 1.2 `wordcloud_frequencies`ãƒ†ãƒ¼ãƒ–ãƒ«
```sql
CREATE TABLE wordcloud_frequencies (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    wordcloud_data_id INTEGER NOT NULL,
    word VARCHAR(100) NOT NULL,
    frequency INTEGER NOT NULL,
    weight_applied REAL DEFAULT 1.0,
    
    -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    FOREIGN KEY (wordcloud_data_id) REFERENCES wordcloud_data(id),
    INDEX idx_word_frequency (word, frequency),
    INDEX idx_wordcloud_word (wordcloud_data_id, word)
);
```

### 2. æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«æ‹¡å¼µ

#### 2.1 `scraping_sessions`ãƒ†ãƒ¼ãƒ–ãƒ«æ‹¡å¼µ
```sql
-- æ–°è¦ã‚«ãƒ©ãƒ è¿½åŠ 
ALTER TABLE scraping_sessions 
ADD COLUMN wordcloud_generated BOOLEAN DEFAULT FALSE;

ALTER TABLE scraping_sessions 
ADD COLUMN wordcloud_generation_time_ms INTEGER;
```

---

## ğŸŒ HTMLçµ±åˆä»•æ§˜

### 1. HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ‹¡å¼µ

#### 1.1 ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
```html
<!-- wordcloud-section.html -->
<section class="wordcloud-section" id="daily-wordcloud">
    <div class="wordcloud-header">
        <h2 class="section-title">
            <span class="icon">ğŸ“Š</span>
            ä»Šæ—¥ã®å¸‚å ´ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        </h2>
        <div class="wordcloud-meta">
            <span class="update-time">æ›´æ–°æ™‚åˆ»: {{update_timestamp}}</span>
            <span class="article-count">å¯¾è±¡è¨˜äº‹: {{article_count}}ä»¶</span>
        </div>
    </div>
    
    <div class="wordcloud-container">
        <div class="wordcloud-loading" id="wordcloud-loading">
            <div class="spinner"></div>
            <p>ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆä¸­...</p>
        </div>
        
        <div class="wordcloud-image-container" id="wordcloud-image">
            <img src="data:image/png;base64,{{wordcloud_base64}}" 
                 alt="å¸‚å ´ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ - {{word_count}}å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"
                 class="wordcloud-img">
        </div>
        
        <div class="wordcloud-stats">
            <div class="stat-item">
                <span class="stat-label">ç·å˜èªæ•°</span>
                <span class="stat-value">{{total_words}}</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èª</span>
                <span class="stat-value">{{unique_words}}</span>
            </div>
        </div>
    </div>
</section>
```

#### 1.2 CSSä»•æ§˜
```css
/* wordcloud.css */
.wordcloud-section {
    background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
    border: 1px solid #cbd5e1;
    border-radius: 12px;
    padding: 2rem;
    margin: 2rem 0;
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
}

.wordcloud-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 1.5rem;
    border-bottom: 2px solid #e2e8f0;
    padding-bottom: 1rem;
}

.section-title {
    font-size: 1.5rem;
    font-weight: 700;
    color: #1e293b;
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.wordcloud-container {
    position: relative;
    min-height: 400px;
    display: flex;
    flex-direction: column;
    align-items: center;
}

.wordcloud-img {
    max-width: 100%;
    height: auto;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

/* ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œ */
@media (max-width: 768px) {
    .wordcloud-header {
        flex-direction: column;
        align-items: flex-start;
        gap: 1rem;
    }
    
    .wordcloud-section {
        padding: 1rem;
    }
}
```

### 2. JavaScriptçµ±åˆ

#### 2.1 å‹•çš„ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
```javascript
// wordcloud-loader.js
class WordCloudLoader {
    constructor() {
        this.loadingElement = document.getElementById('wordcloud-loading');
        this.imageElement = document.getElementById('wordcloud-image');
    }
    
    async loadWordCloud() {
        try {
            this.showLoading();
            
            // ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰æœ€æ–°ã®ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            const response = await fetch('/api/wordcloud/latest');
            const data = await response.json();
            
            if (data.success) {
                this.displayWordCloud(data.wordcloud);
            } else {
                this.showError(data.error);
            }
            
        } catch (error) {
            this.showError(error.message);
        }
    }
    
    showLoading() {
        this.loadingElement.style.display = 'flex';
        this.imageElement.style.display = 'none';
    }
    
    displayWordCloud(wordcloudData) {
        // ç”»åƒã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        this.loadingElement.style.display = 'none';
        this.imageElement.style.display = 'block';
    }
}
```

---

## ğŸ”„ å‡¦ç†ãƒ•ãƒ­ãƒ¼è©³ç´°

### 1. ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼
```python
def generate_daily_wordcloud_workflow(session_id: int, articles: List[Dict]) -> bool:
    """
    æ—¥æ¬¡ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã®å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
    """
    
    try:
        # 1. åˆæœŸåŒ–
        generator = WordCloudGenerator(get_wordcloud_config())
        start_time = time.time()
        
        # 2. ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
        processed_text = generator.processor.process_articles_text(articles)
        
        # 3. å˜èªé »åº¦è¨ˆç®—
        frequencies = generator._calculate_word_frequencies(processed_text)
        
        # 4. é‡‘èé‡è¦èªå¥é‡ã¿ä»˜ã‘
        weighted_frequencies = generator._apply_financial_weights(frequencies)
        
        # 5. ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”»åƒç”Ÿæˆ
        image_base64 = generator.visualizer.create_wordcloud_image(weighted_frequencies)
        
        # 6. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        save_result = save_wordcloud_to_db(session_id, {
            'image_base64': image_base64,
            'word_frequencies': weighted_frequencies,
            'generation_time_ms': int((time.time() - start_time) * 1000),
            'total_articles': len(articles)
        })
        
        # 7. HTMLæ›´æ–°
        update_html_with_wordcloud(image_base64, get_wordcloud_metadata())
        
        return True
        
    except Exception as e:
        logger.error(f"ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return False
```

### 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
```python
class WordCloudError(Exception):
    """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰é–¢é€£ã®ä¾‹å¤–"""
    pass

class TextProcessingError(WordCloudError):
    """ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼"""
    pass

class ImageGenerationError(WordCloudError):
    """ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼"""
    pass

def handle_wordcloud_error(error: Exception, fallback_action: str = "display_default"):
    """
    ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¨ãƒ©ãƒ¼ã®çµ±ä¸€ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    """
    
    if isinstance(error, TextProcessingError):
        # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼ã®å ´åˆ: ç°¡æ˜“ç‰ˆã§å†è©¦è¡Œ
        logger.warning("ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼ - ç°¡æ˜“ç‰ˆã§å†å®Ÿè¡Œ")
        return generate_simple_wordcloud()
        
    elif isinstance(error, ImageGenerationError):
        # ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼ã®å ´åˆ: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒè¡¨ç¤º
        logger.error("ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒã‚’è¡¨ç¤º")
        return get_default_wordcloud_image()
        
    else:
        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {error}")
        return execute_fallback_action(fallback_action)
```

---

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ãƒ¡ãƒ¢ãƒªç®¡ç†
```python
# å¤§é‡è¨˜äº‹å‡¦ç†æ™‚ã®ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
def process_articles_batch(articles: List[Dict], batch_size: int = 100):
    """
    è¨˜äº‹ã‚’åˆ†å‰²å‡¦ç†ã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶é™
    """
    
    for i in range(0, len(articles), batch_size):
        batch = articles[i:i + batch_size]
        yield process_article_batch(batch)
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
        if psutil.virtual_memory().percent > 80:
            gc.collect()  # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
```

### 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥
```python
from functools import lru_cache

@lru_cache(maxsize=10)
def get_stopwords_cache(lang: str = 'japanese') -> Set[str]:
    """ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    return load_stopwords_file(f"assets/config/stopwords_{lang}.txt")

@lru_cache(maxsize=5)
def get_mecab_instance(dicdir: Optional[str] = None) -> MeCab.Tagger:
    """MeCabã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    return MeCab.Tagger(f"-d {dicdir}" if dicdir else "")
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆä»•æ§˜

### 1. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
```python
# tests/test_wordcloud_generator.py
class TestWordCloudGenerator:
    
    def test_generate_daily_wordcloud_success(self):
        """æ­£å¸¸ãªãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        
    def test_japanese_text_processing(self):
        """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        
    def test_financial_weights_application(self):
        """é‡‘èé‡è¦èªå¥é‡ã¿ä»˜ã‘ãƒ†ã‚¹ãƒˆ"""
        
    def test_image_generation_base64(self):
        """base64ç”»åƒç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        
    def test_error_handling(self):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
```

### 2. çµ±åˆãƒ†ã‚¹ãƒˆ
```python
# tests/test_wordcloud_integration.py
class TestWordCloudIntegration:
    
    def test_end_to_end_generation(self):
        """è¨˜äº‹æŠ•å…¥ã‹ã‚‰HTMLè¡¨ç¤ºã¾ã§ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        
    def test_database_integration(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é€£æºãƒ†ã‚¹ãƒˆ"""
        
    def test_html_integration(self):
        """HTMLçµ±åˆãƒ†ã‚¹ãƒˆ"""
```

---

## ğŸ“¦ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆä»•æ§˜

### 1. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
# requirements.txt è¿½åŠ åˆ†
pip install wordcloud>=1.9.2
pip install mecab-python3>=1.0.6
pip install pillow>=10.0.0
```

### 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«é…ç½®
```bash
# ãƒ•ã‚©ãƒ³ãƒˆé…ç½®
mkdir -p assets/fonts/
# NotoSansCJK-Regular.ttf ã‚’é…ç½®

# ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é…ç½®  
mkdir -p assets/config/
# stopwords_japanese.txt ã‚’é…ç½®
```

### 3. ç’°å¢ƒå¤‰æ•°è¨­å®š
```bash
# .env è¿½åŠ è¨­å®š
WORDCLOUD_ENABLED=true
WORDCLOUD_FONT_PATH=assets/fonts/NotoSansCJK-Regular.ttf
MECAB_DICDIR=/usr/local/lib/mecab/dic/mecab-ipadic-neologd
```