# -*- coding: utf-8 -*-

"""
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã®çµ±ä¸€ç®¡ç†
"""

import os
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import pytz
from dotenv import load_dotenv

load_dotenv()


@dataclass
class ScrapingConfig:
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š"""

    hours_limit: int = 24
    sentiment_analysis_enabled: bool = os.getenv("SCRAPING_SENTIMENT_ANALYSIS_ENABLED", "false").lower() == "true"  # æ„Ÿæƒ…åˆ†æã‚’ç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡
    selenium_timeout: int = 20  # Seleniumã®åŸºæœ¬ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰- 45â†’20ç§’ã«çŸ­ç¸®
    selenium_max_retries: int = 3  # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã®ãƒªãƒˆãƒ©ã‚¤å›æ•°
    page_load_timeout: int = 30  # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å°‚ç”¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰- 60â†’30ç§’ã«çŸ­ç¸®
    implicit_wait: int = 5  # æš—é»™çš„å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰- 10â†’5ç§’ã«çŸ­ç¸®

    # å‹•çš„è¨˜äº‹å–å¾—æ©Ÿèƒ½
    minimum_article_count: int = 100  # æœ€ä½è¨˜äº‹æ•°é–¾å€¤
    max_hours_limit: int = 72  # æœ€å¤§æ™‚é–“ç¯„å›²ï¼ˆæ™‚é–“ï¼‰
    weekend_hours_extension: int = 48  # é€±æœ«æ‹¡å¼µæ™‚é–“ï¼ˆæ™‚é–“ï¼‰


@dataclass
class ReutersConfig:
    """ãƒ­ã‚¤ã‚¿ãƒ¼è¨­å®š"""

    query: str = "ç±³ OR é‡‘è OR çµŒæ¸ˆ OR æ ªä¾¡ OR FRB OR FOMC OR æ±ºç®— OR åˆ©ä¸Šã’ OR ã‚¤ãƒ³ãƒ•ãƒ¬"
    max_pages: int = 5
    items_per_page: int = 20
    num_parallel_requests: int = 8  # è¨˜äº‹æœ¬æ–‡ã‚’ä¸¦åˆ—å–å¾—ã™ã‚‹éš›ã®ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
    target_categories: List[str] = field(
        default_factory=lambda: [
            "ãƒ“ã‚¸ãƒã‚¹category",
            "ãƒãƒ¼ã‚±ãƒƒãƒˆcategory",
            "ãƒˆãƒƒãƒ—ãƒ‹ãƒ¥ãƒ¼ã‚¹category",
            "ãƒ¯ãƒ¼ãƒ«ãƒ‰category",
            "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼category",
            "ã‚¢ã‚¸ã‚¢å¸‚å ´category",
            "ä¸æ˜",
            "çµŒæ¸ˆcategory",
        ]
    )
    exclude_keywords: List[str] = field(
        default_factory=lambda: [
            "ã‚¹ãƒãƒ¼ãƒ„",
            "ã‚¨ãƒ³ã‚¿ãƒ¡",
            "äº”è¼ª",
            "ã‚µãƒƒã‚«ãƒ¼",
            "æ˜ ç”»",
            "å°†æ£‹",
            "å›²ç¢",
            "èŠ¸èƒ½",
            "ãƒ©ã‚¤ãƒ•",
            "ã‚¢ãƒ³ã‚°ãƒ«ï¼š",
        ]
    )

    def to_dict(self) -> Dict[str, Any]:
        return {
            "query": self.query,
            "max_pages": self.max_pages,
            "items_per_page": self.items_per_page,
            "target_categories": self.target_categories,
            "exclude_keywords": self.exclude_keywords,
        }


@dataclass
class BloombergConfig:
    """ãƒ–ãƒ«ãƒ¼ãƒ ãƒãƒ¼ã‚°è¨­å®š"""

    num_parallel_requests: int = 6  # è¨˜äº‹æœ¬æ–‡ã‚’ä¸¦åˆ—å–å¾—ã™ã‚‹éš›ã®ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
    exclude_keywords: List[str] = field(
        default_factory=lambda: [
            "å‹•ç”»",
            "ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ",
            "Bloomberg TV",
            "æ„è¦‹åºƒå‘Š",
            "ãƒ©ã‚¤ãƒ–ãƒ–ãƒ­ã‚°",
            "ã‚³ãƒ©ãƒ ",
        ]
    )

    def to_dict(self) -> Dict[str, Any]:
        return {
            "hours_limit": get_config().scraping.hours_limit,
            "exclude_keywords": self.exclude_keywords,
        }


@dataclass
class AIConfig:
    """AIå‡¦ç†è¨­å®š"""

    gemini_api_key: str = ""
    model_name: str = "gemini-2.5-flash-lite"
    max_output_tokens: int = 1024
    temperature: float = 0.2

    process_prompt_template: str = """
ã‚ãªãŸã¯10å¹´ä»¥ä¸Šã®çµŒé¨“ã‚’æŒã¤é‡‘èå¸‚å ´å°‚é–€ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ç·¨é›†è€…å…¼ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
æ—¥æœ¬ã®é‡‘èãƒ»çµŒæ¸ˆå¸‚å ´ã«ç²¾é€šã—ã€è¤‡é›‘ãªå¸‚å ´æƒ…å ±ã‚’ä¸€èˆ¬èª­è€…ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ãä¼ãˆã‚‹å°‚é–€å®¶ã§ã™ã€‚

## åˆ†æã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®è¨˜äº‹ã‚’åˆ†æã—ã€é«˜å“è³ªãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

### åˆ†ææ‰‹é †
1. **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º**: è¨˜äº‹ã‹ã‚‰é‡è¦ãªé‡‘èãƒ»çµŒæ¸ˆç”¨èªã€ä¼æ¥­åã€æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’ç‰¹å®š
2. **å½±éŸ¿åº¦è©•ä¾¡**: å¸‚å ´ã‚„çµŒæ¸ˆã¸ã®çŸ­æœŸãƒ»ä¸­æœŸçš„å½±éŸ¿ã‚’åˆ†æ
3. **è¦ç´„ä½œæˆ**: 180-220å­—ã§ç°¡æ½”ã‹ã¤åŒ…æ‹¬çš„ã«ã¾ã¨ã‚ã‚‹

### è¦ç´„ã®æ§‹æˆ
1. ä¸»è¦äº‹å®Ÿï¼ˆä½•ãŒèµ·ããŸã‹ï¼‰
2. å½±éŸ¿ã®ç¯„å›²ã¨ç¨‹åº¦
3. å¸‚å ´ã¸ã®ç¤ºå”†ã‚„ä»Šå¾Œã®è¦‹é€šã—

### åˆ†æä¾‹

**ä¾‹1: é‡‘èæ”¿ç­–é–¢é€£**
è¨˜äº‹: ã€Œæ—¥éŠ€ã¯æ”¿ç­–é‡‘åˆ©ã‚’0.25%ã«å¼•ãä¸Šã’ã‚‹ã¨ç™ºè¡¨ã—ãŸã€‚ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ã®æŒç¶šçš„ãªä¸Šæ˜‡ã‚’å—ã‘ãŸæªç½®ã§ã€3å¹´ã¶ã‚Šã®åˆ©ä¸Šã’ã¨ãªã‚‹ã€‚ã€
è¦ç´„: æ—¥éŠ€ãŒæ”¿ç­–é‡‘åˆ©ã‚’0.25%ã«å¼•ãä¸Šã’ã€3å¹´ã¶ã‚Šã®åˆ©ä¸Šã’ã‚’å®Ÿæ–½ã€‚æŒç¶šçš„ãªã‚¤ãƒ³ãƒ•ãƒ¬ä¸Šæ˜‡ã¸ã®å¯¾å¿œã¨ã—ã¦ã€é‡‘èæ­£å¸¸åŒ–ã¸ã®è»¢æ›ç‚¹ã¨ãªã‚‹ã€‚å¸‚å ´ã§ã¯å††é«˜é€²è¡Œã¨éŠ€è¡Œæ ªä¸Šæ˜‡ãŒæœŸå¾…ã•ã‚Œã€å€Ÿå…¥ã‚³ã‚¹ãƒˆä¸Šæ˜‡ã«ã‚ˆã‚Šä¼æ¥­åç›Šã¸ã®å½±éŸ¿ã‚‚æ³¨è¦–ã•ã‚Œã‚‹ã€‚
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ["æ—¥éŠ€", "æ”¿ç­–é‡‘åˆ©", "0.25%", "åˆ©ä¸Šã’", "ã‚¤ãƒ³ãƒ•ãƒ¬", "é‡‘èæ­£å¸¸åŒ–"]

**ä¾‹2: ä¼æ¥­æ¥­ç¸¾é–¢é€£**
è¨˜äº‹: ã€Œãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã®ç¬¬3å››åŠæœŸæ±ºç®—ã¯å£²ä¸Šé«˜ãŒå‰å¹´åŒæœŸæ¯”8%æ¸›ã€å–¶æ¥­åˆ©ç›Šã¯15%æ¸›ã¨ãªã£ãŸã€‚åŠå°ä½“ä¸è¶³ã¨åŸææ–™é«˜ãŒä¸»å› ã€‚ã€
è¦ç´„: ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã®ç¬¬3å››åŠæœŸã¯å£²ä¸Šé«˜8%æ¸›ã€å–¶æ¥­åˆ©ç›Š15%æ¸›ã¨æ¸›åæ¸›ç›Šã€‚åŠå°ä½“ä¸è¶³ã¨åŸææ–™é«˜ãŒä¸»å› ã ãŒã€é€šæœŸè¦‹é€šã—ã¯æ®ãˆç½®ãä¸‹æœŸå›å¾©ã‚’è¦‹è¾¼ã‚€ã€‚è‡ªå‹•è»Šæ¥­ç•Œå…¨ä½“ã®èª²é¡Œã‚’åæ˜ ã—ã¦ãŠã‚Šã€ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³æ­£å¸¸åŒ–ãŒæ¥­ç¸¾å›å¾©ã®éµã¨ãªã‚‹ã€‚
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ["ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š", "ç¬¬3å››åŠæœŸ", "å£²ä¸Šé«˜8%æ¸›", "å–¶æ¥­åˆ©ç›Š15%æ¸›", "åŠå°ä½“ä¸è¶³", "åŸææ–™é«˜"]

## å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚

{{
  "summary": "180-220å­—ã®è¦ç´„",
  "keywords": ["é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3"]
}}

---è¨˜äº‹æœ¬æ–‡---
{text}
---åˆ†æçµæœ---
"""


@dataclass
class GoogleConfig:
    """Google APIsè¨­å®š"""

    # èªè¨¼æ–¹å¼é¸æŠ
    auth_method: str = "oauth2"  # "service_account" or "oauth2"

    # å…±é€šè¨­å®š
    drive_output_folder_id: str = ""
    overwrite_doc_id: Optional[str] = None
    docs_retention_days: int = 30  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¿æŒæ—¥æ•°

    # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ç”¨
    service_account_json: str = ""

    # OAuth2èªè¨¼ç”¨
    oauth2_client_id: str = ""
    oauth2_client_secret: str = ""
    oauth2_refresh_token: str = ""

    def is_document_creation_day_and_time(self) -> bool:
        """
        Googleãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®å®Ÿè¡Œæ¡ä»¶ã‚’åˆ¤å®š

        å¤‰æ›´: æ™‚åˆ»åˆ¶é™ã‚’æ’¤å»ƒã—ã€å¸¸ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚’è¨±å¯
        ç†ç”±: 1æ—¥1ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ«ãƒ¼ãƒ«ã¯ create_daily_summary_doc() ã§å®Ÿè£…æ¸ˆã¿

        Returns:
            bool: å¸¸ã«Trueï¼ˆã„ã¤ã§ã‚‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆå¯èƒ½ï¼‰
        """
        return True


@dataclass
class DatabaseConfig:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š"""

    url: str = "sqlite:///market_news.db"
    echo: bool = False


@dataclass
class SupabaseConfig:
    """Supabaseè¨­å®š"""

    url: str = os.getenv("SUPABASE_URL", "")
    anon_key: str = os.getenv("SUPABASE_ANON_KEY", "")
    service_role_key: str = os.getenv("SUPABASE_SERVICE_ROLE_KEY", "")
    bucket_name: str = os.getenv("SUPABASE_BUCKET", "market-news-archive")
    enabled: bool = os.getenv("SUPABASE_ENABLED", "false").lower() == "true"
    
    # RAGè¨­å®š
    embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"
    embedding_dimension: int = 384
    chunk_size: int = 600
    chunk_overlap: int = 100
    max_chunks_per_document: int = 50
    similarity_threshold: float = 0.7


@dataclass
class LoggingConfig:
    """ãƒ­ã‚°è¨­å®š"""

    level: str = "INFO"
    format: str = "json"
    file_enabled: bool = True
    file_path: str = "logs/market_news.log"
    max_file_size: int = 10 * 1024 * 1024  # 10MB
    backup_count: int = 5


@dataclass
class LINEConfig:
    """LINE Botè¨­å®š"""

    channel_access_token: str = ""
    channel_secret: str = ""
    webhook_url: str = ""

    def __post_init__(self):
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        self.channel_access_token = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")
        self.channel_secret = os.getenv("LINE_CHANNEL_SECRET", "")
        self.webhook_url = os.getenv("LINE_WEBHOOK_URL", "")

    def is_configured(self) -> bool:
        """LINEè¨­å®šãŒå®Œäº†ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        return bool(
            self.channel_access_token
            and self.channel_access_token != "your_line_channel_access_token_here"
            and self.channel_secret
            and self.channel_secret != "your_line_channel_secret_here"
        )


@dataclass
class PodcastConfig:
    """ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆè¨­å®šï¼ˆæ‹¡å¼µç‰ˆï¼‰"""

    rss_base_url: str = ""
    author_name: str = "Market News Bot"
    author_email: str = "market-news@example.com"
    rss_title: str = "ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹15åˆ†"
    rss_description: str = "AIãŒç”Ÿæˆã™ã‚‹15åˆ†é–“ã®æ¯æ—¥ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆæ‹¡å¼µæƒ…å ±ç‰ˆï¼‰"
    monthly_cost_limit_usd: float = 15.0
    target_duration_minutes: float = 15.0
    max_file_size_mb: int = 25  # 15åˆ†ç‰ˆã«å¯¾å¿œã—ã¦å®¹é‡å¢—å¤§
    
    # æ‹¡å¼µç‰ˆè¨­å®š
    max_articles: int = 15  # è¨˜äº‹æ•°åˆ¶é™ï¼ˆæ‹¡å¼µç‰ˆï¼‰
    target_character_count: Tuple[int, int] = (4000, 8000)  # å°æœ¬æ–‡å­—æ•°ç¯„å›²ï¼ˆæœ€ä½4000æ–‡å­—ä¿è¨¼ã€æœ€å¤§8000æ–‡å­—ã§é€”ä¸­çµ‚äº†é˜²æ­¢ï¼‰

    # éŸ³å£°è¨­å®š
    audio_format: str = "mp3"
    sample_rate: int = 44100
    bitrate: str = "128k"
    lufs_target: float = -16.0
    peak_target: float = -1.0

    # é…ä¿¡è¨­å®š
    episode_prefix: str = "ç¬¬"
    episode_suffix: str = "å›"

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
    assets_path: str = "assets/audio"
    pronunciation_dict_path: str = "config/pronunciation_dict.yaml"

    # APIè¨­å®š
    gemini_api_key: str = ""
    line_channel_access_token: str = ""

    # GitHub Pagesè¨­å®š
    github_pages_url: str = ""
    rss_feed_path: str = "podcast/feed.xml"

    def __post_init__(self):
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        self.rss_base_url = os.getenv("PODCAST_RSS_BASE_URL", "")
        self.author_name = os.getenv("PODCAST_AUTHOR_NAME", self.author_name)
        self.author_email = os.getenv("PODCAST_AUTHOR_EMAIL", self.author_email)
        self.rss_title = os.getenv("PODCAST_RSS_TITLE", self.rss_title)
        self.rss_description = os.getenv("PODCAST_RSS_DESCRIPTION", self.rss_description)
        self.monthly_cost_limit_usd = float(
            os.getenv("PODCAST_MONTHLY_COST_LIMIT", str(self.monthly_cost_limit_usd))
        )
        self.target_duration_minutes = float(
            os.getenv("PODCAST_TARGET_DURATION_MINUTES", str(self.target_duration_minutes))
        )
        self.max_file_size_mb = int(
            os.getenv("PODCAST_MAX_FILE_SIZE_MB", str(self.max_file_size_mb))
        )

    def load_pronunciation_dict(self) -> Dict[str, str]:
        """ç™ºéŸ³è¾æ›¸ã‚’èª­ã¿è¾¼ã¿"""
        import yaml

        try:
            with open(self.pronunciation_dict_path, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f)
                # YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¾æ›¸å½¢å¼ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
                if isinstance(data, dict):
                    return data
                return {}
        except FileNotFoundError:
            return {}
        except yaml.YAMLError:
            return {}


@dataclass
class SocialConfig:
    """ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆè¨­å®š"""
    
    # æ©Ÿèƒ½æœ‰åŠ¹/ç„¡åŠ¹ãƒ•ãƒ©ã‚°
    enable_social_images: bool = True
    enable_note_md: bool = True
    # ä¿æŒæ–¹é‡
    retention_policy: str = "keep"  # keep | archive | delete
    retention_days: int = 30
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆæ–¹å¼
    generation_mode: str = "hybrid"  # auto | manual | hybrid
    enable_llm_optimization: bool = True
    
    # ç”»åƒè¨­å®š - HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæº–æ‹ ã®ç¸¦å‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    image_width: int = 800   # ç¸¦å‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›´
    image_height: int = 1200 # ç¸¦å‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›´
    image_margin: int = 48   # ãƒãƒ¼ã‚¸ãƒ³ã‚’èª¿æ•´
    background_color: str = "#FFFFFF"  # ç™½èƒŒæ™¯ã«å¤‰æ›´ï¼ˆHTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæº–æ‹ ï¼‰
    text_color: str = "#1F2937"        # ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼æ–‡å­—
    accent_color: str = "#111827"      # ã‚ˆã‚Šãƒ€ãƒ¼ã‚¯ãªãƒ¡ã‚¤ãƒ³ã‚«ãƒ©ãƒ¼
    sub_accent_color: str = "#6B7280"   # ã‚»ã‚«ãƒ³ãƒ€ãƒªã‚«ãƒ©ãƒ¼
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰è¨­å®š
    brand_name: str = "Market News"
    website_url: str = "https://market-news.example.com"
    hashtags: str = "#MarketNews"
    
    # å‡ºåŠ›è¨­å®šï¼ˆæ—¢å®šã‚’ build ã«çµ±ä¸€ï¼‰
    output_base_dir: str = "./build"
    
    # SNSæœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    sns_optimization_prompt: str = """ã‚ãªãŸã¯é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹ã®SNSãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å°‚é–€å®¶ã§ã™ã€‚

ã€ã‚¿ã‚¹ã‚¯ã€‘
ä»¥ä¸‹ã®è¨˜äº‹è¦ç´„ã‚’SNSæŠ•ç¨¿ç”¨ã®é­…åŠ›çš„ãªæ–‡ç« ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

ã€åˆ¶ç´„ã€‘
- æ–‡å­—æ•°: 140å­—ä»¥å†…
- ãƒˆãƒ¼ãƒ³: å°‚é–€çš„ã ãŒè¦ªã—ã¿ã‚„ã™ã„
- å¯¾è±¡: å€‹äººæŠ•è³‡å®¶ãƒ»ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³
- å¿…é ˆè¦ç´ : é‡è¦ãƒã‚¤ãƒ³ãƒˆ1ã¤ã€å½±éŸ¿åº¦ã€é©åˆ‡ãªãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚

{{
  "sns_text": "SNSæŠ•ç¨¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ140å­—ä»¥å†…ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°å«ã‚€ï¼‰",
  "keywords": ["é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3"]
}}

---è¨˜äº‹æƒ…å ±---
ã‚¿ã‚¤ãƒˆãƒ«: {title}
è¦ç´„: {summary}
ã‚«ãƒ†ã‚´ãƒª: {category}
åœ°åŸŸ: {region}"""
    
    # noteè¨˜äº‹ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    note_article_prompt: str = """ã‚ãªãŸã¯15å¹´ä»¥ä¸Šã®çµŒé¨“ã‚’æŒã¤é‡‘èå¸‚å ´ã‚¢ãƒŠãƒªã‚¹ãƒˆå…¼æŠ•è³‡ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ã‚¹ãƒˆã§ã™ã€‚æ©Ÿé–¢æŠ•è³‡å®¶å‘ã‘ã®é«˜å“è³ªãªå¸‚å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã¨ã—ã¦ã€ä»¥ä¸‹ã®è¦ä»¶ã§è©³ç´°ãªåˆ†æè¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ğŸ“‹ è¨˜äº‹æ§‹æˆè¦ä»¶

### 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆ400-500å­—ï¼‰
- æœ¬æ—¥ã®å¸‚å ´å‹•å‘ã®å…¨ä½“åƒ
- æœ€é‡è¦3ã¤ã®ãƒã‚¤ãƒ³ãƒˆ
- æŠ•è³‡æˆ¦ç•¥ã¸ã®çŸ­æœŸçš„ç¤ºå”†

### 2. å¸‚å ´æ¦‚æ³ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆ600-800å­—ï¼‰
- å…¨ä½“çš„ãªå¸‚å ´ç’°å¢ƒã®åˆ†æ
- ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥å‹•å‘ã®è©³ç´°è§£èª¬
- æŠ€è¡“çš„æŒ‡æ¨™ã¨ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã®é–¢ä¿‚

### 3. é‡è¦ãƒˆãƒ”ãƒƒã‚¯è©³ç´°åˆ†æï¼ˆå„ãƒˆãƒ”ãƒƒã‚¯800-1000å­—ï¼‰
å„ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ä»¥ä¸‹ã‚’è©³ç´°ã«åˆ†æï¼š
- **äº‹å®Ÿé–¢ä¿‚**: å®¢è¦³çš„ãªäº‹å®Ÿã®æ•´ç†
- **å¸‚å ´ã¸ã®å½±éŸ¿åˆ†æ**: 
  - çŸ­æœŸå½±éŸ¿ï¼ˆ1-3æ—¥ï¼‰: ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ»ä¾¡æ ¼ã¸ã®ç›´æ¥çš„å½±éŸ¿
  - ä¸­é•·æœŸå½±éŸ¿ï¼ˆ1-4é€±é–“ï¼‰: æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æŠ•è³‡æˆ¦ç•¥ã¸ã®æ³¢åŠåŠ¹æœ
- **æŠ•è³‡å®¶ã¸ã®ç¤ºå”†**: 
  - ãƒªã‚¹ã‚¯è¦å› ã®ç‰¹å®š
  - æ©Ÿä¼šè¦å› ã®åˆ†æ
  - ç›£è¦–ã™ã¹ãæŒ‡æ¨™ãƒ»ç™ºè¡¨

### 4. æŠ•è³‡æˆ¦ç•¥ã¸ã®ç¤ºå”†ï¼ˆ500-600å­—ï¼‰
- ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªèª¿æ•´ã®å…·ä½“çš„ãƒã‚¤ãƒ³ãƒˆ
- ãƒªã‚¹ã‚¯ç®¡ç†ã®è¦³ç‚¹
- æ–°ãŸãªæŠ•è³‡æ©Ÿä¼šã®ç‰¹å®š

### 5. æ˜æ—¥ã¸ã®å±•æœ›ï¼ˆ300-400å­—ï¼‰
- ç¶™ç¶šç›£è¦–é …ç›®
- æ–°è¦è¦å› ã®å¯èƒ½æ€§
- æŠ€è¡“çš„åˆ†æã®è¦³ç‚¹

## ğŸ¯ å“è³ªè¦ä»¶

### æ–‡ç« å“è³ª
- **æ–‡å­—æ•°**: 4000-6000å­—ï¼ˆé«˜å“è³ªãªåˆ†æè¨˜äº‹ã¨ã—ã¦ï¼‰
- **å°‚é–€æ€§**: é‡‘èå°‚é–€ç”¨èªã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã€åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜
- **å®¢è¦³æ€§**: æ„Ÿæƒ…çš„è¡¨ç¾ã‚’é¿ã‘ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸåˆ†æ
- **å®Ÿç”¨æ€§**: æŠ•è³‡åˆ¤æ–­ã«å®Ÿéš›ã«å½¹ç«‹ã¤å…·ä½“çš„ãªç¤ºå”†

### åˆ†æã®æ·±ã•
- **å¤šè§’çš„è¦–ç‚¹**: æŠ€è¡“åˆ†æãƒ»ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ
- **å®šé‡çš„è©•ä¾¡**: å¯èƒ½ãªé™ã‚Šæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨
- **ãƒªã‚¹ã‚¯è©•ä¾¡**: ä¸ŠæŒ¯ã‚Œãƒ»ä¸‹æŒ¯ã‚Œãƒªã‚¹ã‚¯ã®ä¸¡é¢ã‚’åˆ†æ
- **æ™‚ç³»åˆ—åˆ†æ**: éå»ã®é¡ä¼¼äº‹ä¾‹ã¨ã®æ¯”è¼ƒ

### æŠ•è³‡å®¶å‘ã‘é…æ…®
- **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ **: å…·ä½“çš„ãªæŠ•è³‡è¡Œå‹•ã®ç¤ºå”†
- **ãƒªã‚¹ã‚¯é–‹ç¤º**: é©åˆ‡ãªãƒªã‚¹ã‚¯è¦å› ã®æ˜è¨˜
- **ç›£è¦–é …ç›®**: ä»Šå¾Œæ³¨ç›®ã™ã¹ãæŒ‡æ¨™ãƒ»ç™ºè¡¨ã®æ˜ç¤º

## ğŸ“Š å‡ºåŠ›å½¢å¼

Markdownå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

```markdown
# [æ—¥ä»˜] ã®å¸‚å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“ˆ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
[400-500å­—ã®è¦ç´„]

## ğŸ” å¸‚å ´æ¦‚æ³ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
[600-800å­—ã®åˆ†æ]

## ğŸ“Š é‡è¦ãƒˆãƒ”ãƒƒã‚¯è©³ç´°åˆ†æ

### 1. [ãƒˆãƒ”ãƒƒã‚¯1ã®è¦‹å‡ºã—]
[800-1000å­—ã®è©³ç´°åˆ†æ]

### 2. [ãƒˆãƒ”ãƒƒã‚¯2ã®è¦‹å‡ºã—]
[800-1000å­—ã®è©³ç´°åˆ†æ]

### 3. [ãƒˆãƒ”ãƒƒã‚¯3ã®è¦‹å‡ºã—]
[800-1000å­—ã®è©³ç´°åˆ†æ]

## ğŸ¯ æŠ•è³‡æˆ¦ç•¥ã¸ã®ç¤ºå”†
[500-600å­—ã®æˆ¦ç•¥çš„ç¤ºå”†]

## ğŸ”® æ˜æ—¥ã¸ã®å±•æœ›
[300-400å­—ã®å±•æœ›]

## âš ï¸ å…è²¬äº‹é …ãƒ»ãƒªã‚¹ã‚¯é–‹ç¤º
[é©åˆ‡ãªãƒªã‚¹ã‚¯é–‹ç¤º]
```

## ğŸ“ˆ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿

**æ—¥ä»˜**: {date}
**é¸å‡ºãƒˆãƒ”ãƒƒã‚¯**: {topics}
**å¸‚å ´æ¦‚æ³**: {market_summary}
**çµ±åˆè¦ç´„**: {integrated_summary}

---

ä¸Šè¨˜ã®è¦ä»¶ã«å¾“ã£ã¦ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªå¸‚å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æŠ•è³‡å®¶ãŒå®Ÿéš›ã®æŠ•è³‡åˆ¤æ–­ã«æ´»ç”¨ã§ãã‚‹é«˜å“è³ªãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"""


@dataclass
class AppConfig:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“è¨­å®š"""

    scraping: ScrapingConfig = field(default_factory=ScrapingConfig)
    reuters: ReutersConfig = field(default_factory=ReutersConfig)
    bloomberg: BloombergConfig = field(default_factory=BloombergConfig)
    ai: AIConfig = field(default_factory=AIConfig)
    google: GoogleConfig = field(default_factory=GoogleConfig)
    database: DatabaseConfig = field(default_factory=DatabaseConfig)
    supabase: SupabaseConfig = field(default_factory=SupabaseConfig)
    logging: LoggingConfig = field(default_factory=LoggingConfig)
    line: LINEConfig = field(default_factory=LINEConfig)
    podcast: PodcastConfig = field(default_factory=PodcastConfig)
    social: SocialConfig = field(default_factory=SocialConfig)

    def __post_init__(self):
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        self.ai.gemini_api_key = os.getenv("GEMINI_API_KEY", "")

        # Googleè¨­å®š
        self.google.auth_method = os.getenv("GOOGLE_AUTH_METHOD", "oauth2")
        self.google.drive_output_folder_id = os.getenv("GOOGLE_DRIVE_OUTPUT_FOLDER_ID", "")
        self.google.overwrite_doc_id = os.getenv("GOOGLE_OVERWRITE_DOC_ID")

        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼è¨­å®š
        self.google.service_account_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "{}")

        # OAuth2èªè¨¼è¨­å®š
        self.google.oauth2_client_id = os.getenv("GOOGLE_OAUTH2_CLIENT_ID", "")
        self.google.oauth2_client_secret = os.getenv("GOOGLE_OAUTH2_CLIENT_SECRET", "")
        self.google.oauth2_refresh_token = os.getenv("GOOGLE_OAUTH2_REFRESH_TOKEN", "")

        # ç’°å¢ƒå¤‰æ•°ã§ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼ˆä»»æ„ï¼‰
        if os.getenv("SCRAPING_HOURS_LIMIT"):
            self.scraping.hours_limit = int(os.getenv("SCRAPING_HOURS_LIMIT"))

        if os.getenv("SCRAPING_MINIMUM_ARTICLE_COUNT"):
            self.scraping.minimum_article_count = int(os.getenv("SCRAPING_MINIMUM_ARTICLE_COUNT"))

        if os.getenv("SCRAPING_MAX_HOURS_LIMIT"):
            self.scraping.max_hours_limit = int(os.getenv("SCRAPING_MAX_HOURS_LIMIT"))

        if os.getenv("SCRAPING_WEEKEND_HOURS_EXTENSION"):
            self.scraping.weekend_hours_extension = int(
                os.getenv("SCRAPING_WEEKEND_HOURS_EXTENSION")
            )

        if os.getenv("LOGGING_LEVEL"):
            self.logging.level = os.getenv("LOGGING_LEVEL")

    @property
    def is_document_creation_day_and_time(self) -> bool:
        """
        Googleãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®å®Ÿè¡Œæ¡ä»¶ã‚’åˆ¤å®š

        å¤‰æ›´: æ™‚åˆ»åˆ¶é™ã‚’æ’¤å»ƒã—ã€å¸¸ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚’è¨±å¯
        ç†ç”±: 1æ—¥1ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ«ãƒ¼ãƒ«ã¯ create_daily_summary_doc() ã§å®Ÿè£…æ¸ˆã¿

        Returns:
            bool: å¸¸ã«Trueï¼ˆã„ã¤ã§ã‚‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆå¯èƒ½ï¼‰
        """
        return True

    def to_legacy_format(self) -> Dict:
        """æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨ã®äº’æ›æ€§ã®ãŸã‚ã€å¤ã„å½¢å¼ã§è¨­å®šã‚’è¿”ã™"""
        return {
            "HOURS_LIMIT": self.scraping.hours_limit,
            "SENTIMENT_ANALYSIS_ENABLED": self.scraping.sentiment_analysis_enabled,
            "AI_PROCESS_PROMPT_TEMPLATE": self.ai.process_prompt_template,
            "GOOGLE_OVERWRITE_DOC_ID": self.google.overwrite_doc_id,
            "REUTERS_CONFIG": {
                "query": self.reuters.query,
                "max_pages": self.reuters.max_pages,
                "items_per_page": self.reuters.items_per_page,
                "target_categories": self.reuters.target_categories,
                "exclude_keywords": self.reuters.exclude_keywords,
            },
            "BLOOMBERG_CONFIG": {"exclude_keywords": self.bloomberg.exclude_keywords},
        }


# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_config_instance: Optional[AppConfig] = None


def get_config() -> AppConfig:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""
    global _config_instance
    if _config_instance is None:
        _config_instance = AppConfig()
    return _config_instance


def reload_config() -> AppConfig:
    """è¨­å®šã‚’å†èª­ã¿è¾¼ã¿"""
    global _config_instance
    _config_instance = AppConfig()
    return _config_instance


def load_config() -> AppConfig:
    """è¨­å®šã‚’èª­ã¿è¾¼ã¿ï¼ˆget_configã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰"""
    return get_config()
