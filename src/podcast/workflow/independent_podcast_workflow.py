# -*- coding: utf-8 -*-

"""
ç‹¬ç«‹ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆé…ä¿¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼šå„ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç‹¬ç«‹ã—ãŸã‚¯ãƒ©ã‚¹ã«åˆ†å‰²ã—ã€
ã“ã®ã‚¯ãƒ©ã‚¹ã¯ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã€Œçµ„ã¿ç«‹ã¦å½¹ã€ã«å¾¹ã™ã‚‹ã€‚
"""

import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path
from dataclasses import dataclass, field
import json

# ä¾å­˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
from ..standalone.gdrive_document_reader import GoogleDriveDocumentReader, DocumentReaderWithRetry
from ..script_generation.professional_dialogue_script_generator import ProfessionalDialogueScriptGenerator
from ..tts.gemini_tts_engine import GeminiTTSEngine
from ..audio.audio_processor import AudioProcessor
from ..publisher.independent_github_pages_publisher import IndependentGitHubPagesPublisher
from ..integration.message_templates import MessageTemplates
from ..integration.distribution_error_handler import DistributionErrorHandler

# æ–°ã—ã„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
from .workflow_runner import WorkflowRunner
from .steps import (
    IWorkflowStep,
    StepContext,
    InitializeStep,
    ReadArticlesStep,
    AnalyzeArticlesStep,
    GenerateScriptStep,
    SynthesizeAudioStep,
    ProcessAudioStep,
    PublishToGitHubStep,
    SendNotificationStep,
    CleanupStep,
)
from ..analysis import ScriptAnalyzer

# --- ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹å®šç¾© ---

@dataclass
class WorkflowConfig:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®è¨­å®šï¼ˆå¤‰æ›´ãªã—ï¼‰"""
    google_document_id: str
    gemini_api_key: str
    github_repo_url: str
    github_pages_base_url: str
    gemini_model: str = "gemini-2.0-flash-lite-001"
    podcast_title: str = "ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹15åˆ†"
    podcast_description: str = "AIãŒç”Ÿæˆã™ã‚‹15åˆ†é–“ã®æ¯æ—¥ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆæ‹¡å¼µæƒ…å ±ç‰ˆï¼‰"
    podcast_author: str = "Market News Team"
    podcast_email: str = "podcast@example.com"
    max_articles: int = 12
    target_script_length: int = 4200
    audio_bitrate: str = "128k"
    enable_line_notification: bool = True
    max_retries: int = 3
    retry_delay: float = 60.0
    output_dir: str = "output/podcast"
    assets_dir: str = "src/podcast/assets"
    debug_mode: bool = False
    save_intermediates: bool = True

@dataclass
class WorkflowResult:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæœï¼ˆå¤‰æ›´ãªã—ï¼‰"""
    success: bool
    episode_id: str
    audio_url: Optional[str] = None
    rss_url: Optional[str] = None
    processing_time: float = 0.0
    articles_processed: int = 0
    file_size_mb: float = 0.0
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    script_info: Optional[Dict[str, Any]] = None
    message: Optional[str] = None

@dataclass
class WorkflowProgress:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€²è¡ŒçŠ¶æ³ï¼ˆå¤‰æ›´ãªã—ï¼‰"""
    current_step: str
    total_steps: int
    completed_steps: int
    step_start_time: datetime
    overall_start_time: datetime
    estimated_remaining_time: Optional[float] = None

    @property
    def progress_percentage(self) -> float:
        return (self.completed_steps / self.total_steps) * 100 if self.total_steps > 0 else 0.0

    @property
    def elapsed_time(self) -> float:
        return (datetime.now() - self.overall_start_time).total_seconds()

@dataclass
class PodcastServiceComponents:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå¿…è¦ã¨ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚³ãƒ³ãƒ†ãƒŠ"""
    gdrive_reader: GoogleDriveDocumentReader
    script_generator: ProfessionalDialogueScriptGenerator
    tts_engine: GeminiTTSEngine
    audio_processor: AudioProcessor
    publisher: IndependentGitHubPagesPublisher
    message_templates: MessageTemplates
    error_handler: DistributionErrorHandler

# --- ãƒ¡ã‚¤ãƒ³ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¯ãƒ©ã‚¹ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰ ---

class IndependentPodcastWorkflow:
    """
    ç‹¬ç«‹ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆé…ä¿¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çµ„ã¿ç«‹ã¦å½¹ã€‚
    è²¬å‹™ï¼š
    1. å¿…è¦ãªã‚µãƒ¼ãƒ“ã‚¹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚
    2. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    3. WorkflowRunnerã«ã‚¹ãƒ†ãƒƒãƒ—ãƒªã‚¹ãƒˆã‚’æ¸¡ã—ã¦å®Ÿè¡Œã™ã‚‹ã€‚
    """

    def __init__(self, config: WorkflowConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.logger.info("IndependentPodcastWorkflow (Refactored) aåˆæœŸåŒ–å®Œäº†")

    def _initialize_services(self) -> PodcastServiceComponents:
        """å¿…è¦ãªå…¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ã—ã€ã‚³ãƒ³ãƒ†ãƒŠã¨ã—ã¦è¿”ã™ã€‚"""
        self.logger.debug("ã‚µãƒ¼ãƒ“ã‚¹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")

        gdrive_reader = DocumentReaderWithRetry(
            max_retries=self.config.max_retries, retry_delay=self.config.retry_delay
        ) if self.config.max_retries > 1 else GoogleDriveDocumentReader()

        script_generator = ProfessionalDialogueScriptGenerator(
            api_key=self.config.gemini_api_key, model_name=self.config.gemini_model
        )

        tts_engine = GeminiTTSEngine(api_key=self.config.gemini_api_key)

        audio_processor = AudioProcessor(assets_dir=self.config.assets_dir)
        audio_processor.update_settings({"bitrate": self.config.audio_bitrate})

        podcast_info = {
            "title": self.config.podcast_title,
            "description": self.config.podcast_description,
            "author": self.config.podcast_author,
            "email": self.config.podcast_email,
        }
        publisher = IndependentGitHubPagesPublisher(
            github_repo_url=self.config.github_repo_url,
            base_url=self.config.github_pages_base_url,
            podcast_info=podcast_info,
        )

        message_templates = MessageTemplates(base_url=self.config.github_pages_base_url)

        error_handler = DistributionErrorHandler(base_url=self.config.github_pages_base_url)

        self.logger.debug("å…¨ã‚µãƒ¼ãƒ“ã‚¹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–å®Œäº†ã€‚")
        return PodcastServiceComponents(
            gdrive_reader=gdrive_reader,
            script_generator=script_generator,
            tts_engine=tts_engine,
            audio_processor=audio_processor,
            publisher=publisher,
            message_templates=message_templates,
            error_handler=error_handler,
        )

    def _build_steps(self, services: PodcastServiceComponents) -> List[IWorkflowStep]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰ã—ã¦è¿”ã™ã€‚"""
        self.logger.debug("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™...")
        return [
            InitializeStep(services.gdrive_reader),
            ReadArticlesStep(services.gdrive_reader),
            AnalyzeArticlesStep(),
            GenerateScriptStep(services.script_generator),
            SynthesizeAudioStep(services.tts_engine),
            ProcessAudioStep(services.audio_processor),
            PublishToGitHubStep(services.publisher),
            SendNotificationStep(services.message_templates),
            CleanupStep(),
        ]

    async def execute_workflow(self) -> WorkflowResult:
        """
        ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’çµ„ã¿ç«‹ã¦ã¦å®Ÿè¡Œã™ã‚‹ã€‚
        """
        self.logger.info("ğŸš€ ç‹¬ç«‹ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–‹å§‹ (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆ)")

        # 1. ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
        services = self._initialize_services()

        # 2. ã‚¹ãƒ†ãƒƒãƒ—ã®æ§‹ç¯‰
        steps = self._build_steps(services)

        # 3. å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ã®æº–å‚™
        runner = WorkflowRunner(steps)

        # 4. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æº–å‚™
        episode_id = f"market_news_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        result = WorkflowResult(success=False, episode_id=episode_id)
        context = StepContext(config=self.config, result=result)

        # 5. å®Ÿè¡Œ
        final_result = await runner.run(context)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ãªã©ã®æœ€çµ‚å‡¦ç†
        await self._record_metrics(final_result)

        return final_result

    async def execute_script_test_mode(self) -> WorkflowResult:
        """
        éƒ¨åˆ†çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¦å°æœ¬ã‚’ç”Ÿæˆã—ã€åˆ†æã—ã¾ã™ã€‚
        """
        self.logger.info("ğŸ“„ å°æœ¬åˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–‹å§‹")
        services = self._initialize_services()
        
        # å°æœ¬ç”Ÿæˆã«å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã®ã¿ã‚’æ§‹ç¯‰
        script_steps = [
            InitializeStep(services.gdrive_reader),
            ReadArticlesStep(services.gdrive_reader),
            AnalyzeArticlesStep(),
            GenerateScriptStep(services.script_generator),
        ]
        
        runner = WorkflowRunner(script_steps)
        
        episode_id = f"script_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        result = WorkflowResult(success=False, episode_id=episode_id)
        context = StepContext(config=self.config, result=result)
        
        # éƒ¨åˆ†çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
        partial_result = await runner.run(context)
        
        if not partial_result.success:
            return partial_result

        script = context.data.get('script')
        if not script:
            partial_result.success = False
            partial_result.errors.append("å°æœ¬ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return partial_result

        # ç”Ÿæˆã•ã‚ŒãŸå°æœ¬ã‚’åˆ†æ
        self.logger.info("å°æœ¬ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™...")
        analyzer = ScriptAnalyzer()
        analysis_data = analyzer.analyze(script)
        analyzer.display_analysis(analysis_data, script)
        
        partial_result.script_info = analysis_data
        partial_result.message = "å°æœ¬ç”Ÿæˆã¨åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚"
        return partial_result

    async def _record_metrics(self, result: WorkflowResult) -> None:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²ã™ã‚‹ã€‚"""
        try:
            output_dir = Path(self.config.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)

            metrics_data = {
                "execution_id": result.episode_id,
                "timestamp": datetime.now().isoformat(),
                "success": result.success,
                "processing_time": result.processing_time,
                "articles_processed": result.articles_processed,
                "file_size_mb": result.file_size_mb,
                "step_times": result.metadata.get("step_times", {}),
                "errors": result.errors,
                "warnings": result.warnings,
                "config": {
                    "max_articles": self.config.max_articles,
                    "target_script_length": self.config.target_script_length,
                    "audio_bitrate": self.config.audio_bitrate,
                },
            }
            metrics_file = output_dir / "workflow_metrics.jsonl"
            with open(metrics_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(metrics_data, ensure_ascii=False) + "\n")
            self.logger.info("ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²å®Œäº†")

        except Exception as e:
            self.logger.warning(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
