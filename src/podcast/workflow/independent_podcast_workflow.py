# -*- coding: utf-8 -*-

"""
ç‹¬ç«‹ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆé…ä¿¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
6ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„ãªã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹
"""

import os
import asyncio
import logging
import re
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, field
import json

# 6ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..standalone.gdrive_document_reader import GoogleDriveDocumentReader, DocumentReaderWithRetry
from ..script_generation.dialogue_script_generator import DialogueScriptGenerator
from ..tts.gemini_tts_engine import GeminiTTSEngine
from ..audio.audio_processor import AudioProcessor
from ..publisher.independent_github_pages_publisher import IndependentGitHubPagesPublisher
from ..integration.message_templates import MessageTemplates
from ..integration.distribution_error_handler import (
    DistributionErrorHandler,
    ErrorType,
    ErrorSeverity,
)


@dataclass
class WorkflowConfig:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®è¨­å®š"""

    # Google Driveè¨­å®š
    google_document_id: str

    # Gemini APIè¨­å®š
    gemini_api_key: str
    gemini_model: str = "gemini-2.0-flash-lite-001"

    # GitHub Pagesè¨­å®š
    github_repo_url: str
    github_pages_base_url: str

    # ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆè¨­å®š
    podcast_title: str = "ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹15åˆ†"
    podcast_description: str = "AIãŒç”Ÿæˆã™ã‚‹15åˆ†é–“ã®æ¯æ—¥ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆæ‹¡å¼µæƒ…å ±ç‰ˆï¼‰"
    podcast_author: str = "Market News Team"
    podcast_email: str = "podcast@example.com"

    # å‡¦ç†è¨­å®šï¼ˆæ‹¡å¼µç‰ˆï¼‰
    max_articles: int = 12
    target_script_length: int = 4200
    audio_bitrate: str = "128k"
    enable_line_notification: bool = True

    # ãƒªãƒˆãƒ©ã‚¤è¨­å®š
    max_retries: int = 3
    retry_delay: float = 60.0

    # å‡ºåŠ›è¨­å®š
    output_dir: str = "output/podcast"
    assets_dir: str = "src/podcast/assets"

    # ãƒ‡ãƒãƒƒã‚°è¨­å®š
    debug_mode: bool = False
    save_intermediates: bool = True


@dataclass
class WorkflowResult:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæœ"""

    success: bool
    episode_id: str
    audio_url: Optional[str] = None
    rss_url: Optional[str] = None
    processing_time: float = 0.0
    articles_processed: int = 0
    file_size_mb: float = 0.0
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    script_info: Optional[Dict[str, Any]] = None  # å°æœ¬æƒ…å ±ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰
    message: Optional[str] = None  # è¿½åŠ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸


@dataclass
class WorkflowProgress:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€²è¡ŒçŠ¶æ³"""

    current_step: str
    total_steps: int
    completed_steps: int
    step_start_time: datetime
    overall_start_time: datetime
    estimated_remaining_time: Optional[float] = None

    @property
    def progress_percentage(self) -> float:
        """é€²è¡Œç‡ï¼ˆ%ï¼‰"""
        return (self.completed_steps / self.total_steps) * 100 if self.total_steps > 0 else 0.0

    @property
    def elapsed_time(self) -> float:
        """çµŒéæ™‚é–“ï¼ˆç§’ï¼‰"""
        return (datetime.now() - self.overall_start_time).total_seconds()


class IndependentPodcastWorkflow:
    """
    ç‹¬ç«‹ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆé…ä¿¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

    6ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’çµ±åˆã—ãŸã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹:
    1. GoogleDriveDocumentReader - è¨˜äº‹ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
    2. DialogueScriptGenerator - å°æœ¬ç”Ÿæˆ
    3. GeminiTTSEngine - éŸ³å£°åˆæˆ
    4. AudioProcessor - éŸ³å£°å‡¦ç†
    5. IndependentGitHubPagesPublisher - é…ä¿¡
    6. MessageTemplates + DistributionErrorHandler - é€šçŸ¥ãƒ»ã‚¨ãƒ©ãƒ¼å‡¦ç†

    Features:
    - åŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    - é€²è¡ŒçŠ¶æ³ç®¡ç†
    - ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–
    - è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½
    - å“è³ªç®¡ç†
    - è©³ç´°ãªãƒ­ã‚°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    """

    WORKFLOW_STEPS = [
        "åˆæœŸåŒ–",
        "Google Driveæ–‡æ›¸èª­ã¿å–ã‚Š",
        "è¨˜äº‹ãƒ‡ãƒ¼ã‚¿è§£æ",
        "å°æœ¬ç”Ÿæˆ",
        "éŸ³å£°åˆæˆ",
        "éŸ³å£°å‡¦ç†",
        "GitHub Pagesé…ä¿¡",
        "é€šçŸ¥é€ä¿¡",
        "ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—",
    ]

    def __init__(self, config: WorkflowConfig):
        """
        åˆæœŸåŒ–

        Args:
            config: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®š
        """
        self.config = config
        self.logger = logging.getLogger(__name__)

        # é€²è¡ŒçŠ¶æ³ç®¡ç†
        self.progress = WorkflowProgress(
            current_step="",
            total_steps=len(self.WORKFLOW_STEPS),
            completed_steps=0,
            step_start_time=datetime.now(),
            overall_start_time=datetime.now(),
        )

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.output_dir = Path(config.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰
        self._gdrive_reader: Optional[GoogleDriveDocumentReader] = None
        self._script_generator: Optional[DialogueScriptGenerator] = None
        self._tts_engine: Optional[GeminiTTSEngine] = None
        self._audio_processor: Optional[AudioProcessor] = None
        self._publisher: Optional[IndependentGitHubPagesPublisher] = None
        self._message_templates: Optional[MessageTemplates] = None
        self._error_handler: Optional[DistributionErrorHandler] = None

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
        self._temp_files: List[Path] = []

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.metrics = {
            "start_time": None,
            "end_time": None,
            "processing_times": {},
            "component_stats": {},
            "errors": [],
            "warnings": [],
        }

        self.logger.info(f"IndependentPodcastWorkflowåˆæœŸåŒ–å®Œäº† - å‡ºåŠ›: {self.output_dir}")

    @property
    def gdrive_reader(self) -> GoogleDriveDocumentReader:
        """Google Driveæ–‡æ›¸ãƒªãƒ¼ãƒ€ãƒ¼ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._gdrive_reader is None:
            if self.config.max_retries > 1:
                self._gdrive_reader = DocumentReaderWithRetry(
                    max_retries=self.config.max_retries, retry_delay=self.config.retry_delay
                )
            else:
                self._gdrive_reader = GoogleDriveDocumentReader()
            self.logger.debug("Google Drive ReaderåˆæœŸåŒ–å®Œäº†")
        return self._gdrive_reader

    @property
    def script_generator(self) -> DialogueScriptGenerator:
        """å°æœ¬ç”Ÿæˆå™¨ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._script_generator is None:
            self._script_generator = DialogueScriptGenerator(
                api_key=self.config.gemini_api_key, model_name=self.config.gemini_model
            )
            self.logger.debug("Script GeneratoråˆæœŸåŒ–å®Œäº†")
        return self._script_generator

    @property
    def tts_engine(self) -> GeminiTTSEngine:
        """éŸ³å£°åˆæˆã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._tts_engine is None:
            self._tts_engine = GeminiTTSEngine(api_key=self.config.gemini_api_key)
            self.logger.debug("TTS EngineåˆæœŸåŒ–å®Œäº†")
        return self._tts_engine

    @property
    def audio_processor(self) -> AudioProcessor:
        """éŸ³å£°å‡¦ç†å™¨ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._audio_processor is None:
            self._audio_processor = AudioProcessor(assets_dir=self.config.assets_dir)
            # ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆè¨­å®šæ›´æ–°
            self._audio_processor.update_settings({"bitrate": self.config.audio_bitrate})
            self.logger.debug("Audio ProcessoråˆæœŸåŒ–å®Œäº†")
        return self._audio_processor

    @property
    def publisher(self) -> IndependentGitHubPagesPublisher:
        """é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._publisher is None:
            podcast_info = {
                "title": self.config.podcast_title,
                "description": self.config.podcast_description,
                "author": self.config.podcast_author,
                "email": self.config.podcast_email,
            }

            self._publisher = IndependentGitHubPagesPublisher(
                github_repo_url=self.config.github_repo_url,
                base_url=self.config.github_pages_base_url,
                podcast_info=podcast_info,
            )
            self.logger.debug("PublisheråˆæœŸåŒ–å®Œäº†")
        return self._publisher

    @property
    def message_templates(self) -> MessageTemplates:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._message_templates is None:
            self._message_templates = MessageTemplates(base_url=self.config.github_pages_base_url)
            self.logger.debug("Message TemplatesåˆæœŸåŒ–å®Œäº†")
        return self._message_templates

    @property
    def error_handler(self) -> DistributionErrorHandler:
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._error_handler is None:
            self._error_handler = DistributionErrorHandler(
                base_url=self.config.github_pages_base_url
            )
            self.logger.debug("Error HandleråˆæœŸåŒ–å®Œäº†")
        return self._error_handler

    async def execute_workflow(self) -> WorkflowResult:
        """
        ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’å®Ÿè¡Œ

        Returns:
            WorkflowResult: å®Ÿè¡Œçµæœ
        """
        self.logger.info("ğŸš€ ç‹¬ç«‹ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–‹å§‹")
        self.metrics["start_time"] = datetime.now()

        result = WorkflowResult(
            success=False, episode_id=self._generate_episode_id(), processing_time=0.0
        )

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: åˆæœŸåŒ–
            await self._execute_step("åˆæœŸåŒ–", self._step_initialization, result)

            # ã‚¹ãƒ†ãƒƒãƒ—2: Google Driveæ–‡æ›¸èª­ã¿å–ã‚Š
            articles_data = await self._execute_step(
                "Google Driveæ–‡æ›¸èª­ã¿å–ã‚Š", self._step_read_articles, result
            )

            # ã‚¹ãƒ†ãƒƒãƒ—3: è¨˜äº‹ãƒ‡ãƒ¼ã‚¿è§£æãƒ»å³é¸
            selected_articles = await self._execute_step(
                "è¨˜äº‹ãƒ‡ãƒ¼ã‚¿è§£æ", lambda: self._step_analyze_articles(articles_data), result
            )
            result.articles_processed = len(selected_articles)

            # ã‚¹ãƒ†ãƒƒãƒ—4: å°æœ¬ç”Ÿæˆ
            script = await self._execute_step(
                "å°æœ¬ç”Ÿæˆ", lambda: self._step_generate_script(selected_articles), result
            )

            # ã‚¹ãƒ†ãƒƒãƒ—5: éŸ³å£°åˆæˆ
            audio_data = await self._execute_step(
                "éŸ³å£°åˆæˆ", lambda: self._step_synthesize_audio(script, result.episode_id), result
            )

            # ã‚¹ãƒ†ãƒƒãƒ—6: éŸ³å£°å‡¦ç†
            processed_audio_path = await self._execute_step(
                "éŸ³å£°å‡¦ç†",
                lambda: self._step_process_audio(audio_data, result.episode_id, selected_articles),
                result,
            )

            # ã‚¹ãƒ†ãƒƒãƒ—7: GitHub Pagesé…ä¿¡
            audio_url = await self._execute_step(
                "GitHub Pagesé…ä¿¡",
                lambda: self._step_publish_to_github(
                    processed_audio_path, result.episode_id, selected_articles
                ),
                result,
            )
            result.audio_url = audio_url
            result.rss_url = self.publisher.get_rss_url()

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¨˜éŒ²
            if Path(processed_audio_path).exists():
                result.file_size_mb = Path(processed_audio_path).stat().st_size / (1024 * 1024)

            # ã‚¹ãƒ†ãƒƒãƒ—8: é€šçŸ¥é€ä¿¡
            if self.config.enable_line_notification:
                await self._execute_step(
                    "é€šçŸ¥é€ä¿¡",
                    lambda: self._step_send_notifications(result, selected_articles),
                    result,
                )

            # ã‚¹ãƒ†ãƒƒãƒ—9: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            await self._execute_step("ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—", self._step_cleanup, result)

            # æˆåŠŸå®Œäº†
            result.success = True
            self.logger.info("âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå®Œäº†")

        except Exception as e:
            self.logger.error(f"âŒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

            # ã‚¨ãƒ©ãƒ¼å‡¦ç†
            error_info = self.error_handler.handle_error(
                ErrorType.UNKNOWN_ERROR,
                str(e),
                context={"episode_id": result.episode_id, "step": self.progress.current_step},
            )

            result.errors.append(str(e))
            result.success = False

            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¯å¸¸ã«å®Ÿè¡Œ
            try:
                await self._step_cleanup()
            except Exception as cleanup_error:
                self.logger.warning(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {cleanup_error}")

        finally:
            # æœ€çµ‚å‡¦ç†
            self.metrics["end_time"] = datetime.now()
            result.processing_time = self.progress.elapsed_time

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
            await self._record_metrics(result)

        return result

    async def execute_script_test_mode(self) -> WorkflowResult:
        """
        å°æœ¬ç¢ºèªå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ - å°æœ¬ç”Ÿæˆã¾ã§å®Ÿè¡Œã—ã¦è©³ç´°åˆ†æã‚’è¡Œã†
        
        Returns:
            WorkflowResult: å°æœ¬ãƒ†ã‚¹ãƒˆçµæœ
        """
        self.logger.info("ğŸ“„ å°æœ¬ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
        
        episode_id = self._generate_episode_id()
        
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: åˆæœŸåŒ–
            await self._step_initialization()
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: è¨˜äº‹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            articles = await self._step_read_articles()
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: è¨˜äº‹åˆ†æ
            analyzed_articles = await self._step_analyze_articles(articles)
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: å°æœ¬ç”Ÿæˆ
            script = await self._step_generate_script(analyzed_articles)
            
            # å°æœ¬ã®è©³ç´°åˆ†æ
            script_info = self._analyze_script_content(script, episode_id)
            
            # å°æœ¬è¡¨ç¤º
            self._display_script_analysis(script, script_info)
            
            # æˆåŠŸçµæœã‚’ä½œæˆ
            result = WorkflowResult(
                success=True,
                episode_id=episode_id,
                script_info=script_info,
                message="å°æœ¬ç”Ÿæˆãƒ†ã‚¹ãƒˆå®Œäº†"
            )
            
            self.logger.info("âœ… å°æœ¬ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Œäº†")
            return result
            
        except Exception as e:
            error_message = f"å°æœ¬ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.logger.error(f"âŒ {error_message}")
            
            return WorkflowResult(
                success=False,
                episode_id=episode_id,
                errors=[error_message]
            )

    def _analyze_script_content(self, script: str, episode_id: str) -> Dict[str, Any]:
        """
        å°æœ¬ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œï¼ˆå¼·åŒ–ç‰ˆï¼‰
        
        Args:
            script: å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆ
            episode_id: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ID
            
        Returns:
            Dict[str, Any]: åˆ†æçµæœ
        """
        lines = script.split('\n')
        total_lines = len(lines)
        char_count = len(script)
        
        # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åˆ¥ã®è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        speaker_a_lines = 0
        speaker_b_lines = 0
        other_lines = 0
        
        # ã€æ”¹å–„ã€‘ã‚ˆã‚Šè©³ç´°ãªç™ºè©±åˆ†æ
        speaker_a_chars = 0
        speaker_b_chars = 0
        long_lines = 0
        empty_lines = 0
        
        for line in lines:
            line = line.strip()
            if not line:
                empty_lines += 1
                continue
                
            if line.startswith('A:'):
                speaker_a_lines += 1
                speaker_a_chars += len(line[2:].strip())  # "A:"ã‚’é™¤ã„ãŸæ–‡å­—æ•°
            elif line.startswith('B:'):
                speaker_b_lines += 1
                speaker_b_chars += len(line[2:].strip())  # "B:"ã‚’é™¤ã„ãŸæ–‡å­—æ•°
            elif line:  # ç©ºè¡Œã§ãªã„å ´åˆ
                other_lines += 1
            
            # é•·ã™ãã‚‹è¡Œã®æ¤œå‡ºï¼ˆTTSå‘ã‘ï¼‰
            if len(line) > 120:  # 1è¡Œ120æ–‡å­—è¶…ã¯èª­ã¿ã«ãã„
                long_lines += 1
        
        # æ¨å®šèª­ã¿ä¸Šã’æ™‚é–“ï¼ˆæ—¥æœ¬èª: ç´„400æ–‡å­—/åˆ†ï¼‰
        estimated_minutes = char_count / 400
        estimated_duration = f"{int(estimated_minutes)}åˆ†{int((estimated_minutes % 1) * 60)}ç§’"
        
        # å°æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        script_file = self.output_dir / f"{episode_id}_script.txt"
        
        # ã€æ”¹å–„ã€‘å•é¡Œæ¤œå‡ºã®æ‹¡å¼µ
        issues = []
        warnings = []
        
        # åŸºæœ¬çš„ãªé•·ã•ãƒã‚§ãƒƒã‚¯
        if char_count < 1000:
            issues.append("å°æœ¬ãŒçŸ­ã™ãã¾ã™ï¼ˆ1000æ–‡å­—æœªæº€ï¼‰")
        if char_count > 8000:
            issues.append("å°æœ¬ãŒé•·ã™ãã¾ã™ï¼ˆ8000æ–‡å­—è¶…éï¼‰")
        
        # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒãƒ©ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯
        if speaker_a_lines == 0:
            issues.append("ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼Aã®å°è©ãŒã‚ã‚Šã¾ã›ã‚“")
        if speaker_b_lines == 0:
            issues.append("ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼Bã®å°è©ãŒã‚ã‚Šã¾ã›ã‚“")
        
        total_speaker_lines = speaker_a_lines + speaker_b_lines
        if total_speaker_lines > 0:
            if abs(speaker_a_lines - speaker_b_lines) > max(speaker_a_lines, speaker_b_lines) * 0.3:
                warnings.append("ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼é–“ã®å°è©æ•°ãƒãƒ©ãƒ³ã‚¹ãŒæ‚ªã„")
        
        # ã€æ”¹å–„ã€‘æ–°ã—ã„å“è³ªãƒã‚§ãƒƒã‚¯
        if long_lines > 0:
            warnings.append(f"é•·ã™ãã‚‹è¡ŒãŒ{long_lines}è¡Œã‚ã‚Šã¾ã™ï¼ˆTTSèª­ã¿ä¸Šã’ã«ä¸é©åˆ‡ï¼‰")
        
        if other_lines > total_speaker_lines * 0.3:
            warnings.append("ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¡ŒãŒå¤šã™ãã¾ã™ï¼ˆå¯¾è©±å½¢å¼å°æœ¬ã¨ã—ã¦ä¸é©åˆ‡ï¼‰")
        
        # æ–‡å­—æ•°ãƒãƒ©ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯
        if speaker_a_chars > 0 and speaker_b_chars > 0:
            char_ratio = max(speaker_a_chars, speaker_b_chars) / min(speaker_a_chars, speaker_b_chars)
            if char_ratio > 2.0:
                warnings.append("ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼é–“ã®ç™ºè©±é‡ã«å¤§ããªåã‚ŠãŒã‚ã‚Šã¾ã™")
        
        # ã€æ”¹å–„ã€‘å°æœ¬æ§‹é€ ãƒã‚§ãƒƒã‚¯
        structure_score = 100
        if not script.strip():
            structure_score = 0
        elif char_count < 2000:
            structure_score -= 20
        elif char_count > 6000:
            structure_score -= 10
        
        if long_lines > 0:
            structure_score -= min(20, long_lines * 2)
        
        if len(issues) > 0:
            structure_score -= len(issues) * 15
        if len(warnings) > 0:
            structure_score -= len(warnings) * 5
        
        structure_score = max(0, structure_score)
        
        # ã€æ”¹å–„ã€‘é–‹å§‹ãƒ»çµ‚äº†ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        proper_start = False
        proper_end = False
        
        # é©åˆ‡ãªé–‹å§‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œç´¢
        start_patterns = [
            r'(ã¿ãªã•ã‚“|çš†ã•ã‚“|çš†æ§˜).*?(ãŠã¯ã‚ˆã†|ã“ã‚“ã«ã¡ã¯)',
            r'\d{4}å¹´\d+æœˆ\d+æ—¥',
            r'(ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ|ç•ªçµ„).*?(æ™‚é–“|é–‹å§‹)',
        ]
        
        script_start = script[:200]
        for pattern in start_patterns:
            if re.search(pattern, script_start, re.IGNORECASE):
                proper_start = True
                break
        
        # é©åˆ‡ãªçµ‚äº†ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œç´¢  
        end_patterns = [
            r'æ˜æ—¥.*?ã‚ˆã‚ã—ã.*?ãŠé¡˜ã„.*?ã—ã¾ã™',
            r'ä»¥ä¸Š.*?ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ.*?ã§ã—ãŸ',
            r'ã¾ãŸ.*?(æ˜æ—¥|æ¬¡å›).*?ãŠä¼šã„',
        ]
        
        script_end = script[-300:]
        for pattern in end_patterns:
            if re.search(pattern, script_end, re.IGNORECASE):
                proper_end = True
                break
        
        if not proper_start:
            warnings.append("é©åˆ‡ãªé–‹å§‹æŒ¨æ‹¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        if not proper_end:
            warnings.append("é©åˆ‡ãªçµ‚äº†æŒ¨æ‹¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return {
            'char_count': char_count,
            'line_count': total_lines,
            'empty_lines': empty_lines,
            'speaker_a_lines': speaker_a_lines,
            'speaker_b_lines': speaker_b_lines,
            'speaker_a_chars': speaker_a_chars,
            'speaker_b_chars': speaker_b_chars,
            'other_lines': other_lines,
            'long_lines': long_lines,
            'estimated_duration': estimated_duration,
            'estimated_minutes': estimated_minutes,
            'script_file': str(script_file),
            'issues': issues,
            'warnings': warnings,
            'structure_score': structure_score,
            'proper_start': proper_start,
            'proper_end': proper_end,
            'speaker_balance_ratio': speaker_a_chars / speaker_b_chars if speaker_b_chars > 0 else 0,
        }

    def _display_script_analysis(self, script: str, script_info: Dict[str, Any]) -> None:
        """
        å°æœ¬åˆ†æçµæœã‚’è©³ç´°è¡¨ç¤ºï¼ˆå¼·åŒ–ç‰ˆï¼‰
        
        Args:
            script: å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆ
            script_info: åˆ†æçµæœ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“„ å°æœ¬åˆ†æçµæœï¼ˆè©³ç´°ç‰ˆï¼‰")
        self.logger.info("=" * 60)
        
        # åŸºæœ¬çµ±è¨ˆ
        self.logger.info(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        self.logger.info(f"  æ–‡å­—æ•°: {script_info['char_count']:,}æ–‡å­—")
        self.logger.info(f"  ç·è¡Œæ•°: {script_info['line_count']}è¡Œ")
        self.logger.info(f"  ç©ºè¡Œæ•°: {script_info.get('empty_lines', 0)}è¡Œ")
        self.logger.info(f"  æ¨å®šæ™‚é–“: {script_info['estimated_duration']}")
        self.logger.info(f"  æ¨å®šæ™‚é–“ï¼ˆåˆ†ï¼‰: {script_info['estimated_minutes']:.1f}åˆ†")
        
        # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åˆ†æï¼ˆæ‹¡å¼µï¼‰
        self.logger.info(f"\nğŸ­ ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åˆ†æ:")
        self.logger.info(f"  ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼A: {script_info['speaker_a_lines']}è¡Œ ({script_info.get('speaker_a_chars', 0)}æ–‡å­—)")
        self.logger.info(f"  ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼B: {script_info['speaker_b_lines']}è¡Œ ({script_info.get('speaker_b_chars', 0)}æ–‡å­—)")
        self.logger.info(f"  ãã®ä»–: {script_info['other_lines']}è¡Œ")
        
        total_speaker_lines = script_info['speaker_a_lines'] + script_info['speaker_b_lines']
        if total_speaker_lines > 0:
            a_ratio = script_info['speaker_a_lines'] / total_speaker_lines * 100
            b_ratio = script_info['speaker_b_lines'] / total_speaker_lines * 100
            self.logger.info(f"  A:Bè¡Œæ•°æ¯”ç‡ = {a_ratio:.1f}% : {b_ratio:.1f}%")
            
            # ã€æ”¹å–„ã€‘æ–‡å­—æ•°æ¯”ç‡ã‚‚è¡¨ç¤º
            if script_info.get('speaker_balance_ratio', 0) > 0:
                char_ratio = script_info['speaker_balance_ratio']
                self.logger.info(f"  A:Bæ–‡å­—æ•°æ¯”ç‡ = {char_ratio:.2f} : 1")
        
        # ã€æ”¹å–„ã€‘å“è³ªã‚¹ã‚³ã‚¢è¡¨ç¤º
        structure_score = script_info.get('structure_score', 0)
        score_emoji = "ğŸŸ¢" if structure_score >= 80 else "ğŸŸ¡" if structure_score >= 60 else "ğŸ”´"
        self.logger.info(f"\n{score_emoji} å“è³ªã‚¹ã‚³ã‚¢: {structure_score}/100")
        
        # ã€æ”¹å–„ã€‘æ§‹é€ ãƒã‚§ãƒƒã‚¯çµæœ
        self.logger.info(f"\nğŸ—ï¸ æ§‹é€ ãƒã‚§ãƒƒã‚¯:")
        proper_start = script_info.get('proper_start', False)
        proper_end = script_info.get('proper_end', False)
        self.logger.info(f"  é©åˆ‡ãªé–‹å§‹: {'âœ…' if proper_start else 'âŒ'}")
        self.logger.info(f"  é©åˆ‡ãªçµ‚äº†: {'âœ…' if proper_end else 'âŒ'}")
        
        long_lines = script_info.get('long_lines', 0)
        if long_lines > 0:
            self.logger.info(f"  é•·ã™ãã‚‹è¡Œ: {long_lines}è¡Œ âš ï¸")
        else:
            self.logger.info(f"  é•·ã™ãã‚‹è¡Œ: ãªã— âœ…")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        self.logger.info(f"\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:")
        self.logger.info(f"  ä¿å­˜å…ˆ: {script_info['script_file']}")
        
        # ã€æ”¹å–„ã€‘å•é¡Œæ¤œå‡ºçµæœï¼ˆè©³ç´°è¡¨ç¤ºï¼‰
        issues = script_info.get('issues', [])
        warnings = script_info.get('warnings', [])
        
        if issues:
            self.logger.info(f"\nğŸš¨ é‡å¤§ãªå•é¡Œ ({len(issues)}ä»¶):")
            for i, issue in enumerate(issues, 1):
                self.logger.error(f"  {i}. {issue}")
        
        if warnings:
            self.logger.info(f"\nâš ï¸  è­¦å‘Š ({len(warnings)}ä»¶):")
            for i, warning in enumerate(warnings, 1):
                self.logger.warning(f"  {i}. {warning}")
        
        if not issues and not warnings:
            self.logger.info(f"\nâœ… å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        # ã€æ”¹å–„ã€‘æ¨å¥¨äº‹é …
        recommendations = []
        
        if script_info['char_count'] < 2000:
            recommendations.append("å°æœ¬ã‚’ã‚‚ã†å°‘ã—é•·ãã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
        elif script_info['char_count'] > 6000:
            recommendations.append("å°æœ¬ãŒé•·ã‚ã§ã™ã€‚é‡è¦ãªå†…å®¹ã«çµã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if long_lines > 0:
            recommendations.append("é•·ã„è¡Œã‚’çŸ­ãåˆ†å‰²ã—ã¦TTSèª­ã¿ä¸Šã’ã‚’æ”¹å–„ã—ã¦ãã ã•ã„")
        
        balance_ratio = script_info.get('speaker_balance_ratio', 1)
        if balance_ratio > 2.0 or (balance_ratio > 0 and balance_ratio < 0.5):
            recommendations.append("ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼é–“ã®ç™ºè©±ãƒãƒ©ãƒ³ã‚¹ã‚’èª¿æ•´ã—ã¦ãã ã•ã„")
        
        if not proper_start:
            recommendations.append("é©åˆ‡ãªé–‹å§‹æŒ¨æ‹¶ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
        if not proper_end:
            recommendations.append("é©åˆ‡ãªçµ‚äº†æŒ¨æ‹¶ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
        
        if recommendations:
            self.logger.info(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for i, rec in enumerate(recommendations, 1):
                self.logger.info(f"  {i}. {rec}")
        
        # å°æœ¬ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰
        self.logger.info(f"\nğŸ“– å°æœ¬ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
        self.logger.info("-" * 40)
        preview = script[:500] + "..." if len(script) > 500 else script
        self.logger.info(preview)
        self.logger.info("-" * 40)
        
        # ã€æ”¹å–„ã€‘æœ€å¾Œã®100æ–‡å­—ã‚‚ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        if len(script) > 500:
            self.logger.info(f"\nğŸ“– å°æœ¬çµ‚äº†éƒ¨åˆ†ï¼ˆæœ€å¾Œã®200æ–‡å­—ï¼‰:")
            self.logger.info("-" * 40)
            ending_preview = script[-200:]
            self.logger.info(ending_preview)
            self.logger.info("-" * 40)
        
        self.logger.info("=" * 60)

    async def _execute_step(self, step_name: str, step_func, result: WorkflowResult):
        """
        å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œ

        Args:
            step_name: ã‚¹ãƒ†ãƒƒãƒ—å
            step_func: ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œé–¢æ•°
            result: çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

        Returns:
            Any: ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œçµæœ
        """
        self.progress.current_step = step_name
        self.progress.step_start_time = datetime.now()

        self.logger.info(
            f"ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹: {step_name} ({self.progress.completed_steps + 1}/{self.progress.total_steps})"
        )

        step_start = datetime.now()

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
            if asyncio.iscoroutinefunction(step_func):
                step_result = await step_func()
            else:
                step_result = step_func()

            # æˆåŠŸå‡¦ç†
            self.progress.completed_steps += 1
            processing_time = (datetime.now() - step_start).total_seconds()
            self.metrics["processing_times"][step_name] = processing_time

            self.logger.info(f"âœ… ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†: {step_name} ({processing_time:.2f}ç§’)")

            return step_result

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼å‡¦ç†
            processing_time = (datetime.now() - step_start).total_seconds()
            self.metrics["processing_times"][step_name] = processing_time

            self.logger.error(f"âŒ ã‚¹ãƒ†ãƒƒãƒ—å¤±æ•—: {step_name} - {e}")

            # ã‚¨ãƒ©ãƒ¼è¨˜éŒ²
            result.errors.append(f"{step_name}: {str(e)}")

            raise

    def _generate_episode_id(self) -> str:
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰IDã‚’ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        return f"market_news_{timestamp}"

    async def _step_initialization(self) -> None:
        """ã‚¹ãƒ†ãƒƒãƒ—1: åˆæœŸåŒ–"""
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®äº‹å‰ãƒã‚§ãƒƒã‚¯
        try:
            # Google Drive ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
            is_accessible = self.gdrive_reader.validate_document_access(
                self.config.google_document_id
            )
            if not is_accessible:
                raise Exception("Google Driveãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")

            self.logger.info("âœ… åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯å®Œäº†")

        except Exception as e:
            raise Exception(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    async def _step_read_articles(self) -> List[Dict[str, Any]]:
        """ã‚¹ãƒ†ãƒƒãƒ—2: Google Driveæ–‡æ›¸èª­ã¿å–ã‚Š"""
        try:
            metadata, articles = self.gdrive_reader.read_and_parse_document(
                self.config.google_document_id, use_cache=True
            )

            if not articles:
                raise Exception("è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            self.logger.info(f"âœ… {len(articles)}ä»¶ã®è¨˜äº‹ã‚’èª­ã¿å–ã‚Š")

            # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’Dictå½¢å¼ã«å¤‰æ›
            articles_dict = []
            for article in articles:
                articles_dict.append(
                    {
                        "title": article.title,
                        "url": article.url,
                        "summary": article.summary,
                        "sentiment_label": article.sentiment_label,
                        "sentiment_score": article.sentiment_score,
                        "source": article.source,
                        "published_date": article.published_jst.isoformat(),
                    }
                )

            return articles_dict

        except Exception as e:
            raise Exception(f"è¨˜äº‹èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")

    async def _step_analyze_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ã‚¹ãƒ†ãƒƒãƒ—3: è¨˜äº‹ãƒ‡ãƒ¼ã‚¿è§£æãƒ»å³é¸"""
        if not articles:
            raise Exception("è§£æã™ã‚‹è¨˜äº‹ãŒã‚ã‚Šã¾ã›ã‚“")

        # è¨˜äº‹ã®é‡è¦åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        scored_articles = []
        for article in articles:
            score = self._calculate_article_importance(article)
            article_with_score = article.copy()
            article_with_score["importance_score"] = score
            scored_articles.append(article_with_score)

        # é‡è¦åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        scored_articles.sort(key=lambda x: x["importance_score"], reverse=True)

        # æœ€å¤§è¨˜äº‹æ•°ã¾ã§å³é¸
        selected_articles = scored_articles[: self.config.max_articles]

        self.logger.info(f"âœ… {len(articles)}ä»¶ã‹ã‚‰{len(selected_articles)}ä»¶ã‚’å³é¸")

        return selected_articles

    def _calculate_article_importance(self, article: Dict[str, Any]) -> float:
        """è¨˜äº‹ã®é‡è¦åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        score = 0.0

        # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢ã®çµ¶å¯¾å€¤ï¼ˆè©±é¡Œæ€§ï¼‰
        sentiment_score = abs(article.get("sentiment_score", 0.0))
        score += sentiment_score * 0.35  # 0.4 â†’ 0.35 ã«èª¿æ•´

        # è¦ç´„ã®é•·ã•ï¼ˆè©³ç´°åº¦ï¼‰
        summary_length = len(article.get("summary", ""))
        score += min(summary_length / 500.0, 1.0) * 0.25  # 0.3 â†’ 0.25 ã«èª¿æ•´

        # ã‚¿ã‚¤ãƒˆãƒ«ã®é•·ã•ï¼ˆè©³ç´°åº¦ï¼‰
        title_length = len(article.get("title", ""))
        score += min(title_length / 100.0, 1.0) * 0.15  # 0.2 â†’ 0.15 ã«èª¿æ•´

        # ã€æ”¹å–„ã€‘è¨˜äº‹ã®æ–°é®®åº¦è©•ä¾¡ã‚’è¿½åŠ 
        try:
            from datetime import datetime
            published_date_str = article.get("published_date", "")
            if published_date_str:
                published_date = datetime.fromisoformat(published_date_str.replace('Z', '+00:00'))
                hours_old = (datetime.now().replace(tzinfo=published_date.tzinfo) - published_date).total_seconds() / 3600
                # 24æ™‚é–“ä»¥å†…ã¯æœ€å¤§0.15ãƒã‚¤ãƒ³ãƒˆã€ãã‚Œä»¥é™ã¯æ¸›è¡°
                freshness_score = max(0, min(0.15, 0.15 * (1 - hours_old / 24)))
                score += freshness_score
        except Exception:
            pass  # æ—¥ä»˜è§£æã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–

        # ã‚½ãƒ¼ã‚¹ã®ä¿¡é ¼åº¦ï¼ˆæ‹¡å¼µï¼‰
        source = article.get("source", "").lower()
        if "reuters" in source:
            score += 0.12  # 0.1 â†’ 0.12 ã«å¢—åŠ 
        elif "bloomberg" in source:
            score += 0.12  # 0.1 â†’ 0.12 ã«å¢—åŠ 
        elif "nikkei" in source or "æ—¥çµŒ" in source:
            score += 0.10  # æ—¥çµŒè¿½åŠ 
        elif "wsj" in source or "wall street journal" in source:
            score += 0.10  # WSJè¿½åŠ 
        elif "ft.com" in source or "financial times" in source:
            score += 0.10  # FTè¿½åŠ 

        # ã€æ”¹å–„ã€‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®é‡è¦åº¦è©•ä¾¡
        title_and_summary = (article.get("title", "") + " " + article.get("summary", "")).lower()
        
        # é«˜é‡è¦åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¸‚å ´ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹äº‹è±¡ï¼‰
        high_impact_keywords = ["fed", "central bank", "interest rate", "gdp", "inflation", "recession", 
                               "market crash", "stimulus", "bailout", "merger", "acquisition",
                               "ä¸­å¤®éŠ€è¡Œ", "é‡‘åˆ©", "ã‚¤ãƒ³ãƒ•ãƒ¬", "æ™¯æ°—å¾Œé€€", "åˆºæ¿€ç­–"]
        for keyword in high_impact_keywords:
            if keyword in title_and_summary:
                score += 0.08
                break  # è¤‡æ•°è©²å½“ã§ã‚‚1å›ã®ã¿åŠ ç®—

        # ä¸­é‡è¦åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæŠ•è³‡å®¶ãŒæ³¨ç›®ã™ã‚‹äº‹è±¡ï¼‰
        medium_impact_keywords = ["earnings", "revenue", "profit", "dividend", "stock split", "ipo",
                                 "æ±ºç®—", "å£²ä¸Š", "åˆ©ç›Š", "é…å½“", "æ ªå¼åˆ†å‰²", "æ–°è¦ä¸Šå ´"]
        for keyword in medium_impact_keywords:
            if keyword in title_and_summary:
                score += 0.05
                break

        return min(score, 2.0)  # æœ€å¤§ã‚¹ã‚³ã‚¢åˆ¶é™ã‚’è¿½åŠ 

    async def _step_generate_script(self, articles: List[Dict[str, Any]]) -> str:
        """ã‚¹ãƒ†ãƒƒãƒ—4: å°æœ¬ç”Ÿæˆ"""
        try:
            script = self.script_generator.generate_script(articles)

            if not script or len(script) < 1000:
                raise Exception("å°æœ¬ãŒçŸ­ã™ãã¾ã™")

            # ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            if self.config.save_intermediates:
                script_path = self.output_dir / f"{self._generate_episode_id()}_script.txt"
                with open(script_path, "w", encoding="utf-8") as f:
                    f.write(script)
                self._temp_files.append(script_path)

            self.logger.info(f"âœ… å°æœ¬ç”Ÿæˆå®Œäº† - {len(script)}æ–‡å­—")

            return script

        except Exception as e:
            raise Exception(f"å°æœ¬ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    async def _step_synthesize_audio(self, script: str, episode_id: str) -> bytes:
        """ã‚¹ãƒ†ãƒƒãƒ—5: éŸ³å£°åˆæˆ"""
        try:
            audio_data = self.tts_engine.synthesize_dialogue(script)

            if not audio_data:
                raise Exception("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

            # ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            if self.config.save_intermediates:
                raw_audio_path = self.output_dir / f"{episode_id}_raw.mp3"
                with open(raw_audio_path, "wb") as f:
                    f.write(audio_data)
                self._temp_files.append(raw_audio_path)

            self.logger.info(f"âœ… éŸ³å£°åˆæˆå®Œäº† - {len(audio_data)}ãƒã‚¤ãƒˆ")

            return audio_data

        except Exception as e:
            raise Exception(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")

    async def _step_process_audio(
        self, audio_data: bytes, episode_id: str, articles: List[Dict[str, Any]]
    ) -> str:
        """ã‚¹ãƒ†ãƒƒãƒ—6: éŸ³å£°å‡¦ç†"""
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            metadata = {
                "title": f"{self.config.podcast_title} - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}",
                "artist": self.config.podcast_author,
                "album": self.config.podcast_title,
                "date": datetime.now().strftime("%Y"),
                "genre": "News",
                "comment": f"è¨˜äº‹æ•°: {len(articles)}ä»¶",
            }

            processed_path = self.audio_processor.process_audio(
                audio_data=audio_data, episode_id=episode_id, metadata=metadata
            )

            self.logger.info(f"âœ… éŸ³å£°å‡¦ç†å®Œäº† - å‡ºåŠ›: {processed_path}")

            return processed_path

        except Exception as e:
            raise Exception(f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

    async def _step_publish_to_github(
        self, audio_file_path: str, episode_id: str, articles: List[Dict[str, Any]]
    ) -> Optional[str]:
        """ã‚¹ãƒ†ãƒƒãƒ—7: GitHub Pagesé…ä¿¡"""
        try:
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            episode_metadata = {
                "title": f"{self.config.podcast_title} - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}",
                "description": f"æœ¬æ—¥ã®å¸‚å ´å‹•å‘ã‚’{len(articles)}ä»¶ã®è¨˜äº‹ã‹ã‚‰è§£èª¬",
                "published_date": datetime.now(),
                "duration": "00:10:00",  # å›ºå®šå€¤ï¼ˆå®Ÿéš›ã®å†ç”Ÿæ™‚é–“ã¯éŸ³å£°å‡¦ç†å¾Œã«å–å¾—å¯èƒ½ï¼‰
                "keywords": ["market", "news", "finance", "japan", "ai"],
                "episode_number": self._get_next_episode_number(),
            }

            audio_url = self.publisher.publish_episode(
                audio_file=Path(audio_file_path), episode_metadata=episode_metadata
            )

            if not audio_url:
                raise Exception("é…ä¿¡URLãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            self.logger.info(f"âœ… é…ä¿¡å®Œäº† - URL: {audio_url}")

            return audio_url

        except Exception as e:
            raise Exception(f"é…ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

    def _get_next_episode_number(self) -> int:
        """æ¬¡ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·ã‚’å–å¾—"""
        try:
            episodes = self.publisher.get_episode_list()
            if episodes:
                max_episode = max([ep.get("episode_number", 0) for ep in episodes])
                return max_episode + 1
            return 1
        except:
            return 1

    async def _step_send_notifications(
        self, result: WorkflowResult, articles: List[Dict[str, Any]]
    ) -> None:
        """ã‚¹ãƒ†ãƒƒãƒ—8: é€šçŸ¥é€ä¿¡"""
        try:
            # é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
            episode_data = {
                "title": f"{self.config.podcast_title} - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}",
                "duration": "ç´„10åˆ†",
                "date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥"),
                "summary": self._create_articles_summary(articles),
                "filename": Path(result.audio_url).name if result.audio_url else "",
                "file_size_mb": result.file_size_mb,
                "episode_number": self._get_next_episode_number() - 1,  # æ—¢ã«é…ä¿¡æ¸ˆã¿ãªã®ã§-1
            }

            notification_message = self.message_templates.create_podcast_notification(episode_data)

            # å®Ÿéš›ã®é€šçŸ¥é€ä¿¡ã¯å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ãƒ­ã‚°å‡ºåŠ›
            self.logger.info("ğŸ“¢ é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆå®Œäº†")
            if self.config.debug_mode:
                self.logger.debug(f"é€šçŸ¥å†…å®¹:\n{notification_message}")

        except Exception as e:
            # é€šçŸ¥ã‚¨ãƒ©ãƒ¼ã¯è‡´å‘½çš„ã§ã¯ãªã„ãŸã‚ã€è­¦å‘Šãƒ¬ãƒ™ãƒ«
            self.logger.warning(f"é€šçŸ¥é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

    def _create_articles_summary(self, articles: List[Dict[str, Any]]) -> str:
        """è¨˜äº‹ã‹ã‚‰è¦ç´„ã‚’ä½œæˆ"""
        if not articles:
            return "æœ¬æ—¥ã®é‡è¦ãªå¸‚å ´å‹•å‘ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚"

        summaries = []
        for i, article in enumerate(articles[:3], 1):
            title = article.get("title", "").strip()
            if title and len(title) > 10:
                if len(title) > 40:
                    title = title[:37] + "..."
                summaries.append(f"{i}. {title}")

        return "\n".join(summaries) if summaries else "æœ¬æ—¥ã®é‡è¦ãªå¸‚å ´å‹•å‘ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚"

    async def _step_cleanup(self) -> None:
        """ã‚¹ãƒ†ãƒƒãƒ—9: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
            deleted_count = 0
            for temp_file in self._temp_files:
                try:
                    if temp_file.exists():
                        temp_file.unlink()
                        deleted_count += 1
                except Exception as e:
                    self.logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {temp_file} - {e}")

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self._gdrive_reader:
                cache_cleaned = self.gdrive_reader.cleanup_cache()

            # å¤ã„ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self._error_handler:
                self.error_handler.cleanup_old_errors()

            self.logger.info(f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº† - ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«{deleted_count}ä»¶å‰Šé™¤")

        except Exception as e:
            self.logger.warning(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    async def _record_metrics(self, result: WorkflowResult) -> None:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        try:
            metrics_data = {
                "execution_id": result.episode_id,
                "timestamp": datetime.now().isoformat(),
                "success": result.success,
                "processing_time": result.processing_time,
                "articles_processed": result.articles_processed,
                "file_size_mb": result.file_size_mb,
                "step_times": self.metrics["processing_times"],
                "errors": result.errors,
                "warnings": result.warnings,
                "config": {
                    "max_articles": self.config.max_articles,
                    "target_script_length": self.config.target_script_length,
                    "audio_bitrate": self.config.audio_bitrate,
                },
            }

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²
            metrics_file = self.output_dir / "workflow_metrics.jsonl"
            with open(metrics_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(metrics_data, ensure_ascii=False) + "\n")

            self.logger.info("ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²å®Œäº†")

        except Exception as e:
            self.logger.warning(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

    def get_progress_info(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®é€²è¡ŒçŠ¶æ³ã‚’å–å¾—"""
        return {
            "current_step": self.progress.current_step,
            "progress_percentage": self.progress.progress_percentage,
            "completed_steps": self.progress.completed_steps,
            "total_steps": self.progress.total_steps,
            "elapsed_time": self.progress.elapsed_time,
            "estimated_remaining_time": self.progress.estimated_remaining_time,
            "processing_times": self.metrics["processing_times"],
        }

    def get_component_status(self) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çŠ¶æ…‹ã‚’å–å¾—"""
        return {
            "gdrive_reader": {
                "initialized": self._gdrive_reader is not None,
                "info": self._gdrive_reader.get_processing_info() if self._gdrive_reader else None,
            },
            "script_generator": {
                "initialized": self._script_generator is not None,
                "model": self.config.gemini_model,
            },
            "tts_engine": {
                "initialized": self._tts_engine is not None,
                "config": self._tts_engine.get_voice_config() if self._tts_engine else None,
            },
            "audio_processor": {
                "initialized": self._audio_processor is not None,
                "info": (
                    self._audio_processor.get_processing_info() if self._audio_processor else None
                ),
            },
            "publisher": {
                "initialized": self._publisher is not None,
                "stats": self._publisher.get_stats() if self._publisher else None,
            },
            "error_handler": {
                "initialized": self._error_handler is not None,
                "stats": (
                    self._error_handler.get_error_statistics() if self._error_handler else None
                ),
            },
        }


# ãƒ†ã‚¹ãƒˆã¨ãƒ‡ãƒ¢ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
async def demo_workflow_execution():
    """ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
    # è¨­å®šä¾‹
    config = WorkflowConfig(
        google_document_id="your_document_id_here",
        gemini_api_key="your_gemini_api_key",
        github_repo_url="https://github.com/username/repo.git",
        github_pages_base_url="https://username.github.io/repo",
        debug_mode=True,
    )

    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
    workflow = IndependentPodcastWorkflow(config)

    try:
        result = await workflow.execute_workflow()

        print(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæœ:")
        print(f"  æˆåŠŸ: {result.success}")
        print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ID: {result.episode_id}")
        print(f"  å‡¦ç†æ™‚é–“: {result.processing_time:.2f}ç§’")
        print(f"  éŸ³å£°URL: {result.audio_url}")
        print(f"  è¨˜äº‹å‡¦ç†æ•°: {result.articles_processed}")
        print(f"  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {result.file_size_mb:.1f}MB")

        if result.errors:
            print(f"  ã‚¨ãƒ©ãƒ¼: {result.errors}")

        return result

    except Exception as e:
        print(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return None


if __name__ == "__main__":
    import asyncio

    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    asyncio.run(demo_workflow_execution())
