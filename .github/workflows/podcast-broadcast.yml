name: Daily Podcast Broadcast

on:
  push:
    branches:
      - master  # Êú¨Áï™„É¢„Éº„Éâ„ÉÜ„Çπ„ÉàÁî®„Å´ÂÜçÊúâÂäπÂåñ
  schedule:
    - cron: '30 22 * * *' # JST 7:30 (UTC 22:30) - ÈÄöÂã§ÊôÇÈñìÂ∏Ø
  workflow_dispatch: # ÊâãÂãïÂÆüË°å„ÇíÂèØËÉΩ„Å´„Åô„Çã
    inputs:
      use_db_artifact:
        description: 'Use database artifact from main workflow'
        required: false
        default: 'false'
        type: choice
        options:
        - 'true'
        - 'false'
      force_run:
        description: 'Force run even if conditions are not met'
        required: false
        default: 'true'
        type: choice
        options:
        - 'true'
        - 'false'
      test_mode:
        description: 'Run in test mode (no actual broadcast)'
        required: false
        default: 'false'
        type: choice
        options:
        - 'true'
        - 'false'
      weekdays_only:
        description: 'Run only on weekdays'
        required: false
        default: 'false'
        type: choice
        options:
        - 'true'
        - 'false'
      prompt_pattern:
        description: '„Éó„É≠„É≥„Éó„Éà„Éë„Çø„Éº„É≥ÈÅ∏Êäû'
        required: false
        default: 'current_professional'
        type: choice
        options:
        - 'current_professional'
        - 'cot_enhanced'
        - 'enhanced_persona'
        - 'few_shot_learning'
        - 'constraint_optimization'
        - 'context_aware'
        - 'minimalist'
      comparison_mode:
        description: '„Éó„É≠„É≥„Éó„ÉàÊØîËºÉ„É¢„Éº„Éâ'
        required: false
        default: 'single'
        type: choice
        options:
        - 'single'           # Âçò‰∏Ä„Éë„Çø„Éº„É≥„ÉÜ„Çπ„Éà
        - 'ab_test'          # 2„Éë„Çø„Éº„É≥ÊØîËºÉ
        - 'multi_compare'    # Ë§áÊï∞„Éë„Çø„Éº„É≥ÊØîËºÉ

jobs:
  podcast-broadcast:
    runs-on: ubuntu-latest
    permissions:
      contents: write # GitHub Pages „Éá„Éó„É≠„Ç§Áî®
      issues: write   # Â§±ÊïóÊôÇIssue‰ΩúÊàêÁî®

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        echo "Python dependencies installed successfully"
        pip list | grep -E "(google|pydub|feedgen|yaml)" || echo "Some podcast dependencies may be missing"

    - name: Download database artifact
      id: download-artifact
      if: |
        github.event_name == 'schedule' || 
        (github.event_name == 'workflow_dispatch' && github.event.inputs.use_db_artifact == 'true')
      uses: dawidd6/action-download-artifact@v2
      continue-on-error: true
      with:
        workflow: main.yml
        name: market-news-db
        path: .
        search_artifacts: true
        
    - name: Check artifact download result
      id: artifact-status
      run: |
        if [ -f "market_news.db" ]; then
          echo "artifact_available=true" >> $GITHUB_OUTPUT
          echo "data_source=database" >> $GITHUB_OUTPUT
          ls -la market_news.db
        else
          echo "artifact_available=false" >> $GITHUB_OUTPUT
          echo "data_source=google_document" >> $GITHUB_OUTPUT
        fi

    - name: Validate database file
      id: validate-db
      if: steps.artifact-status.outputs.artifact_available == 'true'
      run: |
        if sqlite3 market_news.db ".tables" > /dev/null 2>&1; then
          echo "db_valid=true" >> $GITHUB_OUTPUT
        else
          echo "db_valid=false" >> $GITHUB_OUTPUT
          echo "Database file is corrupted, falling back to Google Document"
          rm -f market_news.db
        fi

    - name: Final data source decision
      id: final-source
      run: |
        if [[ -f "market_news.db" && "${{ steps.validate-db.outputs.db_valid }}" == "true" ]]; then
          echo "PODCAST_DATA_SOURCE=database" >> $GITHUB_ENV
          echo "final_source=database" >> $GITHUB_OUTPUT
        else
          echo "PODCAST_DATA_SOURCE=google_document" >> $GITHUB_ENV
          echo "GOOGLE_DOCUMENT_ID=${{ secrets.GOOGLE_DOCUMENT_ID || secrets.GOOGLE_OVERWRITE_DOC_ID }}" >> $GITHUB_ENV
          echo "final_source=google_document" >> $GITHUB_OUTPUT
        fi

    - name: Log data source decision
      run: |
        echo "=== Podcast Data Source Decision ==="
        echo "Trigger: ${{ github.event_name }}"
        echo "Use artifact requested: ${{ github.event.inputs.use_db_artifact || 'N/A (scheduled)' }}"
        echo "Artifact available: ${{ steps.artifact-status.outputs.artifact_available }}"
        echo "Database valid: ${{ steps.validate-db.outputs.db_valid }}"
        echo "Final data source: ${{ steps.final-source.outputs.final_source }}"
        echo "================================="

    - name: Verify dependencies and environment
      run: |
        echo "üîç ÂøÖÈ†à‰æùÂ≠òÈñ¢‰øÇÁ¢∫Ë™ç"
        python --version
        
        # Critical dependencies check
        python -c "
        import sys
        failed = []
        
        critical_modules = [
            'google.cloud.texttospeech',
            'pydub', 
            'feedgen',
            'yaml',
            'requests'
        ]
        
        for module in critical_modules:
            try:
                __import__(module)
                print(f'‚úÖ {module}: OK')
            except ImportError as e:
                print(f'‚ùå {module}: FAILED - {e}')
                failed.append(module)
        
        if failed:
            print(f'\\nCRITICAL: Missing modules: {failed}')
            sys.exit(1)
        else:
            print('\\n‚úÖ All critical dependencies verified')
        "
        
        # Google Cloud auth check
        if [ -n "$GOOGLE_APPLICATION_CREDENTIALS_JSON" ]; then
          echo "‚úÖ Google Cloud auth configured"
        else
          echo "‚ùå Google Cloud auth not configured"
        fi

    - name: Run standalone podcast workflow
      env:
        # Core control settings
        ENABLE_PODCAST_GENERATION: 'true'
        PODCAST_FORCE_RUN: ${{ github.event.inputs.force_run || 'true' }}
        PODCAST_TEST_MODE: ${{ github.event.inputs.test_mode || 'false' }}
        
        # Google Authentication
        GOOGLE_OAUTH2_CLIENT_ID: ${{ secrets.GOOGLE_OAUTH2_CLIENT_ID }}
        GOOGLE_OAUTH2_CLIENT_SECRET: ${{ secrets.GOOGLE_OAUTH2_CLIENT_SECRET }}
        GOOGLE_OAUTH2_REFRESH_TOKEN: ${{ secrets.GOOGLE_OAUTH2_REFRESH_TOKEN }}
        GOOGLE_OVERWRITE_DOC_ID: ${{ secrets.GOOGLE_OVERWRITE_DOC_ID }}
        
        # Google Cloud TTS
        GOOGLE_APPLICATION_CREDENTIALS_JSON: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS_JSON }}
        GOOGLE_SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
        
        # AI Configuration
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        GEMINI_PODCAST_MODEL: ${{ secrets.GEMINI_PODCAST_MODEL || 'gemini-2.5-pro' }}
        
        # LINE Bot Configuration
        LINE_CHANNEL_ACCESS_TOKEN: ${{ secrets.LINE_CHANNEL_ACCESS_TOKEN }}
        LINE_CHANNEL_SECRET: ${{ secrets.LINE_CHANNEL_SECRET }}
        
        # Podcast Configuration
        PODCAST_RSS_BASE_URL: ${{ secrets.PODCAST_RSS_BASE_URL }}
        PODCAST_AUTHOR_NAME: ${{ secrets.PODCAST_AUTHOR_NAME }}
        PODCAST_AUTHOR_EMAIL: ${{ secrets.PODCAST_AUTHOR_EMAIL }}
        PODCAST_TARGET_DURATION_MINUTES: '10.0'
      timeout-minutes: 20
      run: |
        echo "üéôÔ∏è Starting podcast generation..."
        python scripts/core/standalone_podcast_main.py
        
        if [ $? -eq 0 ]; then
          echo "‚úÖ Podcast generation completed successfully"
        else
          echo "‚ùå Podcast generation failed"
          exit 1
        fi

    - name: Prepare podcast files for deployment
      if: success()
      run: |
        # ÂÖ¨ÈñãÁî®„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê
        mkdir -p public/podcast
        
        # „Éù„ÉÉ„Éâ„Ç≠„É£„Çπ„Éà„Éï„Ç°„Ç§„É´„Åå„ÅÇ„Çå„Å∞„Ç≥„Éî„ÉºÔºàGitHubPagesPublisher„Åå‰ΩúÊàê„Åó„Åüpodcast„Éá„Ç£„É¨„ÇØ„Éà„É™„ÇíÂÑ™ÂÖàÔºâ
        if [ -d "podcast" ]; then
          cp -r podcast/* public/podcast/
          echo "Podcast files copied from podcast/ directory (GitHubPagesPublisher output)"
          ls -la public/podcast/
        elif [ -d "output/podcast" ]; then
          cp -r output/podcast/* public/podcast/
          echo "Podcast files copied from output/podcast/ directory (fallback)"
          ls -la public/podcast/
        else
          echo "No podcast files found to deploy"
          ls -la output/ || echo "No output directory"
          ls -la . | grep -E "(podcast|output)" || echo "No podcast directories found"
        fi

    - name: Deploy podcast to GitHub Pages
      if: success()
      uses: peaceiris/actions-gh-pages@v4.0.0
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./public
        publish_branch: gh-pages
        keep_files: true # Êó¢Â≠ò„Éï„Ç°„Ç§„É´„Çí‰øùÊåÅÔºà„É°„Ç§„É≥„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÅÆ„Éï„Ç°„Ç§„É´„Çí‰øùË≠∑Ôºâ
        destination_dir: . # „É´„Éº„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„Å´„Éá„Éó„É≠„Ç§
        user_name: 'github-actions[bot]'
        user_email: 'github-actions[bot]@users.noreply.github.com'
        commit_message: 'Deploy daily podcast: ${{ github.run_id }}'

    - name: Cleanup temporary files
      if: always()
      run: |
        # ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„Çí„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
        rm -rf output/podcast/episode_*.mp3
        rm -rf public/
        echo "Temporary files cleaned up"

    - name: Workflow summary
      if: always()
      run: |
        echo "## üìä Podcast Broadcast Workflow Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Execution Time**: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Use DB Artifact**: ${{ github.event.inputs.use_db_artifact || 'N/A (scheduled)' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Final Data Source**: ${{ steps.final-source.outputs.final_source }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Artifact Available**: ${{ steps.artifact-status.outputs.artifact_available }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Database Valid**: ${{ steps.validate-db.outputs.db_valid }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Force Run**: ${{ github.event.inputs.force_run || 'false' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Test Mode**: ${{ github.event.inputs.test_mode || 'false' }}" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "podcast/market_news_$(date +%Y%m%d).mp3" ]; then
          echo "- **Podcast Generated**: ‚úÖ Yes" >> $GITHUB_STEP_SUMMARY
          echo "- **File Size**: $(du -h podcast/market_news_$(date +%Y%m%d).mp3 | cut -f1)" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Podcast Generated**: ‚ùå No" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Collect error details
      if: failure()
      run: |
        echo "Error occurred at: $(date -u)"
        echo "Python version: $(python --version)"
        pip list | grep -E "(google|pydub|feedgen|yaml)" || echo "Missing critical packages"

    - name: Create Issue on Failure
      if: failure() && github.event.pull_request == null
      uses: jayqi/failed-build-issue-action@v1
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        title-template: "üéôÔ∏è Podcast Broadcast Failed #${{ github.run_number }}"
        body-template: |
          ## Podcast Broadcast Failure
          
          **Run ID**: ${{ github.run_id }}
          **Branch**: ${{ github.ref_name }}
          **Triggered by**: ${{ github.actor }}
          **Time**: ${{ github.event.head_commit.timestamp }}
          
          ### Quick Debug Links
          - [View Failed Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          - [View Commit](https://github.com/${{ github.repository }}/commit/${{ github.sha }})
          
          ### Common Solutions
          1. Check GitHub Secrets are configured
          2. Verify `GOOGLE_APPLICATION_CREDENTIALS_JSON` is set
          3. Ensure Google Cloud TTS API is enabled
          4. Re-run workflow after checking dependencies
          
          This issue will auto-close when the workflow succeeds.
        label-name: "podcast"
        always-create-new-issue: false