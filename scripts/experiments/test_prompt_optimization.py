#!/usr/bin/env python3
"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã¨A/Bãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import asyncio
import logging
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.podcast.prompts import PromptManager, ABTestManager
from src.podcast.script_generation.professional_dialogue_script_generator import ProfessionalDialogueScriptGenerator

# æ¨¡æ“¬è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
MOCK_ARTICLES = [
    {
        "index": 1,
        "title": "FRBã€æ”¿ç­–é‡‘åˆ©ã‚’æ®ãˆç½®ãæ±ºå®š",
        "summary": "ç±³é€£é‚¦æº–å‚™åˆ¶åº¦ç†äº‹ä¼šï¼ˆFRBï¼‰ã¯æœ¬æ—¥é–‹å‚¬ã—ãŸFOMCã§æ”¿ç­–é‡‘åˆ©ã‚’5.25-5.5%ã§æ®ãˆç½®ãã“ã¨ã‚’æ±ºå®šã—ãŸã€‚ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ã®å‹•å‘ã‚’æ³¨è¦–ã—ãªãŒã‚‰æ…é‡ã«æ”¿ç­–ã‚’æ¤œè¨ã™ã‚‹å§¿å‹¢ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚",
        "category": "é‡‘èæ”¿ç­–",
        "region": "US",
        "importance_score": 0.95,
        "published_at": "2024å¹´12æœˆ20æ—¥",
        "source": "Bloomberg"
    },
    {
        "index": 2,
        "title": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã€å››åŠæœŸæ±ºç®—ã§å¢—ç›Š",
        "summary": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»ŠãŒç™ºè¡¨ã—ãŸ2024å¹´ç¬¬3å››åŠæœŸæ±ºç®—ã¯ã€å£²ä¸Šé«˜ãŒå‰å¹´åŒæœŸæ¯”8%å¢—ã®9å…†2000å„„å††ã€ç´”åˆ©ç›Šã¯12%å¢—ã®1å…†2000å„„å††ã¨ãªã£ãŸã€‚é›»å‹•åŒ–æˆ¦ç•¥ã®é€²å±•ãŒå¯„ä¸ã—ã¦ã„ã‚‹ã€‚",
        "category": "ä¼æ¥­æ¥­ç¸¾",
        "region": "Japan",
        "importance_score": 0.82,
        "published_at": "2024å¹´12æœˆ19æ—¥",
        "source": "æ—¥çµŒæ–°è"
    },
    {
        "index": 3,
        "title": "ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã€10ä¸‡ãƒ‰ãƒ«çªç ´",
        "summary": "æš—å·è³‡ç”£ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã®ä¾¡æ ¼ãŒå²ä¸Šåˆã‚ã¦10ä¸‡ãƒ‰ãƒ«ã‚’çªç ´ã—ãŸã€‚æ©Ÿé–¢æŠ•è³‡å®¶ã®å‚å…¥æ‹¡å¤§ã¨è¦åˆ¶ç’°å¢ƒã®æ”¹å–„ãŒèƒŒæ™¯ã«ã‚ã‚‹ã¨ã®è¦‹æ–¹ãŒå¼·ã„ã€‚",
        "category": "æš—å·è³‡ç”£",
        "region": "Global",
        "importance_score": 0.78,
        "published_at": "2024å¹´12æœˆ18æ—¥",
        "source": "Reuters"
    }
]

def setup_logging():
    """ãƒ­ã‚°è¨­å®š"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('prompt_optimization_test.log')
        ]
    )
    return logging.getLogger(__name__)

def test_prompt_manager():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    logger = logging.getLogger(__name__)
    logger.info("=== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # PromptManageråˆæœŸåŒ–
        prompt_manager = PromptManager()
        
        # åˆ©ç”¨å¯èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºèª
        patterns = prompt_manager.get_available_patterns()
        logger.info(f"åˆ©ç”¨å¯èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³: {patterns}")
        
        # ç’°å¢ƒæ¤œè¨¼
        validation = prompt_manager.validate_environment()
        logger.info(f"ç’°å¢ƒæ¤œè¨¼çµæœ: {validation}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
        for pattern in patterns[:3]:  # æœ€åˆã®3ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ
            try:
                logger.info(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ {pattern} ãƒ†ã‚¹ãƒˆä¸­...")
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                template_vars = {
                    "target_duration": 10.0,
                    "target_chars": 2700,
                    "target_chars_min": 2600,
                    "target_chars_max": 2800,
                    "main_content_chars": 2300,
                    "articles_data": "\n".join([f"ã€è¨˜äº‹{i+1}ã€‘{article['title']}" for i, article in enumerate(MOCK_ARTICLES)]),
                    "generation_date": "2024å¹´12æœˆ20æ—¥ãƒ»é‡‘æ›œæ—¥",
                    "episode_number": 354
                }
                
                prompt = prompt_manager.load_prompt_template(pattern, **template_vars)
                logger.info(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ {pattern}: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”ŸæˆæˆåŠŸ ({len(prompt)}æ–‡å­—)")
                
            except Exception as e:
                logger.error(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ {pattern} ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        
        logger.info("=== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº† ===")
        return True
        
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def test_ab_test_system():
    """A/Bãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    logger = logging.getLogger(__name__)
    logger.info("=== A/Bãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # å¿…è¦ãªç’°å¢ƒå¤‰æ•°è¨­å®š
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if not gemini_api_key:
            logger.error("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        # A/Bãƒ†ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        ab_test_manager = ABTestManager()
        
        # å°æœ¬ç”Ÿæˆå™¨åˆæœŸåŒ–
        script_generator = ProfessionalDialogueScriptGenerator(gemini_api_key)
        
        # æ¨¡æ“¬è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        from src.podcast.data_fetcher.enhanced_database_article_fetcher import ArticleScore
        from dataclasses import dataclass
        
        # ç°¡æ˜“çš„ãªArticleScoreã‚¯ãƒ©ã‚¹ä½œæˆ
        @dataclass
        class MockAnalysis:
            summary: str
            sentiment_score: float
            category: str = "é‡‘è"
            region: str = "global"
        
        @dataclass
        class MockArticle:
            title: str
            published_at: str
            source: str
        
        mock_article_scores = []
        for article in MOCK_ARTICLES:
            mock_article = MockArticle(
                title=article["title"],
                published_at=article["published_at"],
                source=article["source"]
            )
            mock_analysis = MockAnalysis(
                summary=article["summary"],
                sentiment_score=0.5,
                category=article["category"],
                region=article["region"]
            )
            mock_article_scores.append(ArticleScore(
                article=mock_article,
                analysis=mock_analysis,
                score=article["importance_score"]
            ))
        
        # å˜ä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ
        logger.info("å˜ä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        os.environ["PODCAST_PROMPT_PATTERN"] = "cot_enhanced"
        
        single_result = await ab_test_manager.run_comparison_test(
            script_generator, mock_article_scores, comparison_mode="single"
        )
        logger.info(f"å˜ä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†: {single_result['test_id']}")
        
        # A/Bãƒ†ã‚¹ãƒˆï¼ˆ2ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒï¼‰
        logger.info("A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        ab_result = await ab_test_manager.run_comparison_test(
            script_generator, mock_article_scores, comparison_mode="ab_test"
        )
        logger.info(f"A/Bãƒ†ã‚¹ãƒˆå®Œäº†: {ab_result['test_id']}")
        
        # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = ab_test_manager.create_comparison_report(ab_result['test_id'])
        logger.info("æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        report_file = Path("prompt_comparison_report.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        
        logger.info("=== A/Bãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº† ===")
        return True
        
    except Exception as e:
        logger.error(f"A/Bãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_github_actions_integration():
    """GitHub Actionsçµ±åˆãƒ†ã‚¹ãƒˆ"""
    logger = logging.getLogger(__name__)
    logger.info("=== GitHub Actionsçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # ç’°å¢ƒå¤‰æ•°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        test_env_vars = {
            "PODCAST_PROMPT_PATTERN": "few_shot_learning",
            "PODCAST_COMPARISON_MODE": "ab_test",
            "PODCAST_AB_TEST_MODE": "true"
        }
        
        # ç’°å¢ƒå¤‰æ•°è¨­å®š
        for key, value in test_env_vars.items():
            os.environ[key] = value
            logger.info(f"ç’°å¢ƒå¤‰æ•°è¨­å®š: {key}={value}")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒç’°å¢ƒå¤‰æ•°ã‚’æ­£ã—ãèª­ã¿å–ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
        prompt_manager = PromptManager()
        
        selected_pattern = prompt_manager.get_environment_prompt_pattern()
        logger.info(f"ç’°å¢ƒå¤‰æ•°ã‹ã‚‰é¸æŠã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³: {selected_pattern}")
        
        # æ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
        ab_test_manager = ABTestManager(prompt_manager)
        comparison_patterns = ab_test_manager.setup_comparison_test("ab_test")
        logger.info(f"A/Bãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ‘ã‚¿ãƒ¼ãƒ³: {comparison_patterns}")
        
        logger.info("=== GitHub Actionsçµ±åˆãƒ†ã‚¹ãƒˆå®Œäº† ===")
        return True
        
    except Exception as e:
        logger.error(f"GitHub Actionsçµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    logger = setup_logging()
    logger.info("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tests = [
        ("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", test_prompt_manager),
        ("GitHub Actionsçµ±åˆ", test_github_actions_integration),
        ("A/Bãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ", test_ab_test_system),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        logger.info(f"\n{'='*50}")
        logger.info(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: {test_name}")
        logger.info(f"{'='*50}")
        
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            results[test_name] = result
            logger.info(f"ãƒ†ã‚¹ãƒˆ {test_name}: {'âœ… æˆåŠŸ' if result else 'âŒ å¤±æ•—'}")
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆ {test_name} ã§ä¾‹å¤–ç™ºç”Ÿ: {e}")
            results[test_name] = False
    
    # çµæœã‚µãƒãƒªãƒ¼
    logger.info(f"\n{'='*50}")
    logger.info("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    logger.info(f"{'='*50}")
    
    for test_name, result in results.items():
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±æ•—"
        logger.info(f"{test_name}: {status}")
    
    total_tests = len(results)
    successful_tests = sum(results.values())
    logger.info(f"\nç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}, æˆåŠŸ: {successful_tests}, å¤±æ•—: {total_tests - successful_tests}")
    
    if successful_tests == total_tests:
        logger.info("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        return 0
    else:
        logger.error("âš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)