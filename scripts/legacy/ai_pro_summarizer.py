# -*- coding: utf-8 -*-

import os
import json
import re
import time
from typing import Optional, Dict, Any, List, Union
import logging
from dataclasses import dataclass
from datetime import datetime
import random

from src.llm import (
    BaseLLMClient,
    GeminiClient,
    LLMResult,
    OpenRouterClient,
)

@dataclass
class ProSummaryConfig:
    """Proçµ±åˆè¦ç´„ã®è¨­å®šã‚¯ãƒ©ã‚¹"""
    enabled: bool = True
    min_articles_threshold: int = 10
    max_daily_executions: int = 3
    execution_hours: List[int] = None  # [9, 15, 21] # JST
    cost_limit_monthly: float = 50.0  # USD
    timeout_seconds: int = 180
    model_name: str = "gemini-2.5-pro"
    provider: str = "gemini"
    system_prompt: Optional[str] = None
    temperature: float = 0.3

    def __post_init__(self):
        if self.execution_hours is None:
            self.execution_hours = list(range(24))  # 24æ™‚é–“ã„ã¤ã§ã‚‚å®Ÿè¡Œå¯èƒ½


class ProSummarizer:
    """LLMã‚’ç”¨ã„ãŸçµ±åˆè¦ç´„æ©Ÿèƒ½"""

    def __init__(
        self,
        client_or_api_key: Union[BaseLLMClient, str],
        config: Optional[ProSummaryConfig] = None,
    ) -> None:
        self.logger = logging.getLogger(__name__)
        self.config = config or ProSummaryConfig()

        if isinstance(client_or_api_key, BaseLLMClient):
            self.client = client_or_api_key
        else:
            api_key = client_or_api_key
            if not api_key:
                raise ValueError("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            if self.config.provider and self.config.provider != "gemini":
                self.logger.warning(
                    "APIã‚­ãƒ¼æ–‡å­—åˆ—ãŒæ¸¡ã•ã‚Œã¾ã—ãŸãŒã€ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒ %s ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚Geminiã¨ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚",
                    self.config.provider,
                )
            self.config.provider = "gemini"
            self.client = GeminiClient(
                api_key=api_key,
                model_name=self.config.model_name,
                default_timeout=self.config.timeout_seconds,
            )

        if not self.config.provider:
            self.config.provider = self.client.provider
        elif self.config.provider != self.client.provider:
            self.logger.debug(
                "ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«åˆã‚ã›ã¦æ›´æ–°: %s -> %s",
                self.config.provider,
                self.client.provider,
            )
            self.config.provider = self.client.provider

        self.config.model_name = self.client.model_name
        if not self.config.system_prompt:
            self.config.system_prompt = self._default_system_prompt()

        self.logger.info(
            "LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ (provider=%s, model=%s)",
            self.client.provider,
            self.client.model_name,
        )

    def _default_system_prompt(self) -> str:
        return (
            "ã‚ãªãŸã¯é‡‘èå¸‚å ´ã®ã‚·ãƒ‹ã‚¢ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚æä¾›ã•ã‚ŒãŸHTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ§‹é€ ã«å³å¯†ã«å¾“ã„ã€"
            "æ—¥æœ¬èªã§æŠ•è³‡å®¶å‘ã‘ã®é«˜åº¦ãªåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚æ•°å€¤æ ¹æ‹ ã¨ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’æ˜ç¤ºã—ã€"
            "éåº¦ãªèª‡å¼µã‚„æŠ•æ©Ÿçš„è¡¨ç¾ã¯é¿ã‘ã¾ã™ã€‚"
        )

    def _fallback_system_prompt(self) -> str:
        return (
            "ã‚ãªãŸã¯é‡‘èå¸‚å ´ãƒ¬ãƒãƒ¼ãƒˆã®ã‚µãƒãƒ¼ãƒˆã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚å„åœ°åŸŸã®è¨˜äº‹ã‹ã‚‰100-200å­—ã®"
            "ç°¡æ½”ãªæ—¥æœ¬èªè¦ç´„ã‚’ä½œæˆã—ã€æŠ•è³‡å®¶ãŒã™ãã«ç†è§£ã§ãã‚‹å½¢ã§æä¾›ã—ã¦ãã ã•ã„ã€‚"
        )

    def _api_call_with_retry(
        self,
        prompt: str,
        *,
        max_output_tokens: int,
        system_prompt: Optional[str] = None,
        temperature: Optional[float] = None,
        timeout: Optional[int] = None,
        max_retries: int = 3,
    ) -> LLMResult:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã®ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãAPIå‘¼ã³å‡ºã—"""

        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    wait_time = (2 ** attempt) + random.uniform(0, 1)
                    self.logger.info(
                        "APIå‘¼ã³å‡ºã—ãƒªãƒˆãƒ©ã‚¤ %s/%s - %.2fç§’å¾…æ©Ÿä¸­",
                        attempt,
                        max_retries,
                        wait_time,
                    )
                    time.sleep(wait_time)

                result = self.client.generate(
                    prompt,
                    system_prompt=system_prompt or self.config.system_prompt,
                    temperature=temperature if temperature is not None else self.config.temperature,
                    max_output_tokens=max_output_tokens,
                    timeout=timeout or self.config.timeout_seconds,
                )
                return result

            except Exception as e:  # pragma: no cover - network failures depend on runtime env
                error_msg = str(e).lower()
                if ("rate limit" in error_msg or "quota" in error_msg or "429" in error_msg) and attempt < max_retries - 1:
                    wait_time = (2 ** (attempt + 1)) + random.uniform(1, 3)
                    self.logger.warning(
                        "ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ - %.2fç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ (è©¦è¡Œ %s/%s)",
                        wait_time,
                        attempt + 1,
                        max_retries,
                    )
                    time.sleep(wait_time)
                    continue
                if "timeout" in error_msg and attempt < max_retries - 1:
                    self.logger.warning(
                        "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ - ãƒªãƒˆãƒ©ã‚¤ %s/%s",
                        attempt + 1,
                        max_retries,
                    )
                    continue
                raise

        raise RuntimeError("äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: ãƒªãƒˆãƒ©ã‚¤ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æŠœã‘ã¾ã—ãŸ")
    
    
    def generate_unified_summary(self, grouped_articles: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """
        ä¸€æ‹¬çµ±åˆè¦ç´„ã‚’ç”Ÿæˆï¼ˆåœ°åŸŸé–¢é€£æ€§ã‚’è€ƒæ…®ï¼‰
        
        Args:
            grouped_articles (Dict[str, List[Dict]]): åœ°åŸŸåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸè¨˜äº‹ç¾¤
                ä¾‹: {"japan": [{"summary": "...", "title": "...", "category": "..."}], ...}
        
        Returns:
            Dict[str, Any]: çµ±åˆè¦ç´„çµæœï¼ˆåœ°åŸŸåˆ¥+å…¨ä½“+é–¢é€£æ€§åˆ†æï¼‰
        """
        start_time = time.time()
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        self.logger.info(f"ä¸€æ‹¬çµ±åˆè¦ç´„ç”Ÿæˆé–‹å§‹ (ç·è¨˜äº‹æ•°: {total_articles}, åœ°åŸŸæ•°: {len(grouped_articles)})")
        
        # è¨˜äº‹æ•°åˆ¶é™ãªã—ï¼ˆå…¨è¨˜äº‹ã‚’çµ±åˆè¦ç´„ã«ä½¿ç”¨ï¼‰
        try:
            prompt = self._build_unified_prompt(grouped_articles)
            self.logger.info(f"çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(prompt)}æ–‡å­—")

            result = self._api_call_with_retry(
                prompt,
                max_output_tokens=8192,
                temperature=self.config.temperature,
            )

            if not result or not result.text:
                raise Exception("LLMã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

            finish_reason = str(result.metadata.get("finish_reason", "")).lower()
            if finish_reason in {"safety", "safetyblock"}:
                self.logger.error("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ã«ã‚ˆã£ã¦ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸ")
                raise Exception("å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ã«ã‚ˆã‚Šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸ")

            response_text = result.text
            self.logger.info(f"çµ±åˆè¦ç´„APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {len(response_text)}æ–‡å­—")

            processing_time_ms = int((time.time() - start_time) * 1000)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            parsed_result = self._parse_unified_response(response_text)
            
            if parsed_result:
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å®Œå…¨æ€§ã‚’æ¤œè¨¼
                validation_result = self._validate_response_completeness(parsed_result)
                
                result = {
                    "unified_summary": parsed_result,
                    "total_articles": total_articles,
                    "processing_time_ms": processing_time_ms,
                    "model_version": result.metadata.get("model", self.config.model_name),
                    "validation": validation_result  # æ¤œè¨¼çµæœã‚’è¿½åŠ 
                }
                
                if validation_result['is_complete']:
                    self.logger.info(f"ä¸€æ‹¬çµ±åˆè¦ç´„å®Œäº† ({processing_time_ms}ms) - å®Œå…¨")
                else:
                    self.logger.warning(f"ä¸€æ‹¬çµ±åˆè¦ç´„å®Œäº† ({processing_time_ms}ms) - ä¸å®Œå…¨: {validation_result['issues']}")
                
                return result
            else:
                self.logger.error("çµ±åˆè¦ç´„ã®è§£æã«å¤±æ•—")
                return None
                
        except Exception as e:
            self.logger.error(f"ğŸš¨ ä¸€æ‹¬çµ±åˆè¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ğŸš¨ UNIFIED SUMMARY FAILED: {e}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ï¼šåˆ†å‰²å‡¦ç†ã«è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ
            if "å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿" in str(e) or "finish_reason=STOP" in str(e) or "ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©º" in str(e):
                self.logger.info("ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ç™ºå‹•ï¼šåˆ†å‰²å‡¦ç†ã«è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ")
                try:
                    return self._generate_fallback_summary(grouped_articles)
                except Exception as fallback_e:
                    self.logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚‚å¤±æ•—: {fallback_e}")
            
            return None
    
    
    
    
    def _build_unified_prompt(self, grouped_articles: Dict[str, List[Dict[str, Any]]]) -> str:
        """çµ±åˆè¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆåœ°åŸŸé–“é–¢é€£æ€§åˆ†æã‚’é‡è¦–ï¼‰"""
        
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        
        prompt = f"""ã€é‡è¦ï¼šã“ã‚Œã¯å­¦è¡“çš„ãƒ»æ•™è‚²çš„ãªé‡‘èå¸‚å ´åˆ†æã§ã™ã€‘

ã‚ãªãŸã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡‘èå¸‚å ´ã®å°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®å†…å®¹ã¯é‡‘èæ•™è‚²ãƒ»æŠ•è³‡åˆ¤æ–­æ”¯æ´ã‚’ç›®çš„ã¨ã—ãŸæ­£å½“ãªãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æã§ã‚ã‚Šã€æœ‰å®³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

ã€åˆ†æç›®çš„ã€‘
- æŠ•è³‡å®¶ã¸ã®æƒ…å ±æä¾›
- å¸‚å ´å‹•å‘ã®å­¦è¡“çš„åˆ†æ
- çµŒæ¸ˆæ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä½œæˆ

ä»¥ä¸‹ã®{total_articles}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åˆ†æã—ã€åœ°åŸŸé–“ã®ç›¸äº’é–¢é€£æ€§ã¨å½±éŸ¿ã‚’æ·±ãè€ƒæ…®ã—ãŸåŒ…æ‹¬çš„ãªå¸‚å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚è¨˜äº‹ä¸­ã®ã€Œæš´è½ã€ã€Œç ´ç¶»ã€ã€Œå±æ©Ÿã€ç­‰ã¯é‡‘èå¸‚å ´ã®å°‚é–€ç”¨èªã¨ã—ã¦æ­£å½“ãªåˆ†æå¯¾è±¡ã§ã™ã€‚

ã€åˆ†æå¯¾è±¡ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘"""
        
        # åœ°åŸŸåˆ¥è¨˜äº‹ã‚’æ•´ç†ï¼ˆè¡¨ç¤ºé †åºã‚’èª¿æ•´ï¼šç±³å›½â†’æ¬§å·â†’æ—¥æœ¬â†’ä¸­å›½ãƒ»æ–°èˆˆå›½ï¼‰
        region_order = ["usa", "europe", "japan", "china", "asia", "global", "other"]
        sorted_regions = sorted(grouped_articles.keys(), key=lambda x: region_order.index(x) if x in region_order else 999)
        
        for region in sorted_regions:
            articles = grouped_articles[region]
            region_names = {
                "japan": "æ—¥æœ¬", "usa": "ç±³å›½", "china": "ä¸­å›½ãƒ»ãã®ä»–æ–°èˆˆå›½", 
                "europe": "æ¬§å·", "asia": "ã‚¢ã‚¸ã‚¢", "global": "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "other": "ãã®ä»–"
            }
            region_ja = region_names.get(region, region)
            
            prompt += f"\n\nâ– â–  {region_ja}å¸‚å ´ ({len(articles)}ä»¶)\n"
            
            for i, article in enumerate(articles, 1):
                title = article.get("title", "").strip()
                summary = article.get("summary", "").strip()
                category = article.get("category", "ãã®ä»–")
                
                prompt += f"{i}. ã€{category}ã€‘{title}\n   è¦ç´„: {summary}\n"
        
        prompt += f"""

ã€é‡è¦ï¼šHTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‘
ä»¥ä¸‹ã®HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ§‹é€ ã«å¾“ã£ã¦ã€åœ°åŸŸé–“ã®ç›¸äº’ä½œç”¨ã¨æ³¢åŠåŠ¹æœã‚’é‡è¦–ã—ãŸç·åˆåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š

## åœ°åŸŸåˆ¥å¸‚å ´æ¦‚æ³
ä»¥ä¸‹ã®HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å¾“ã£ã¦å‡ºåŠ›ï¼š
<div class="regional-summaries">
<div class="region-item">
<h4>ç±³å›½å¸‚å ´</h4>
<p>[ç±³å›½å¸‚å ´ã®åˆ†æå†…å®¹]</p>
</div>
<div class="region-item">
<h4>æ¬§å·å¸‚å ´</h4>
<p>[æ¬§å·å¸‚å ´ã®åˆ†æå†…å®¹]</p>
</div>
<div class="region-item">
<h4>æ—¥æœ¬å¸‚å ´</h4>
<p>[æ—¥æœ¬å¸‚å ´ã®åˆ†æå†…å®¹]</p>
</div>
<div class="region-item">
<h4>ä¸­å›½ãƒ»ãã®ä»–æ–°èˆˆå›½å¸‚å ´</h4>
<p>[ä¸­å›½ãƒ»æ–°èˆˆå›½å¸‚å ´ã®åˆ†æå†…å®¹]</p>
</div>
</div>

## ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ç·æ‹¬
<div class="global-overview">
<p>[ä¸–ç•Œå…¨ä½“ã®å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã€ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥å‹•å‘ã‚’400å­—ç¨‹åº¦ã§ç·åˆåˆ†æ]</p>
</div>

## åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ
<div class="cross-regional-analysis">
<div class="influence-item">
<h5>ç±³å›½é‡‘èæ”¿ç­–ã®å½±éŸ¿</h5>
<p>[ç±³å›½ã®æ”¿ç­–ãŒä»–åœ°åŸŸã«ä¸ãˆã‚‹å½±éŸ¿]</p>
</div>
<div class="influence-item">
<h5>ä¸­å›½çµŒæ¸ˆã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æ³¢åŠ</h5>
<p>[ä¸­å›½çµŒæ¸ˆå‹•å‘ã®ä¸–ç•Œã¸ã®å½±éŸ¿]</p>
</div>
<div class="influence-item">
<h5>æ¬§å·ãƒ»æ—¥æœ¬ã®å¸‚å ´å‹•å‘</h5>
<p>[æ¬§å·ãƒ»æ—¥æœ¬ã®å‹•å‘ã¨åœ°åŸŸé–“ç›¸äº’ä½œç”¨]</p>
</div>
</div>

## æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å°†æ¥å±•æœ›
<div class="key-trends">
<p>[é‡è¦ãªå¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã€æŠ€è¡“é€²æ­©ã€æ”¿ç­–æ–¹å‘æ€§ã‚’300å­—ç¨‹åº¦]</p>
</div>

## ãƒªã‚¹ã‚¯è¦å› ãƒ»æŠ•è³‡æ©Ÿä¼š
<div class="risk-factors">
<div class="risk-item">
<h5>çŸ­æœŸãƒªã‚¹ã‚¯è¦å› </h5>
<p>[çŸ­æœŸçš„ãªãƒªã‚¹ã‚¯è¦å› ã®åˆ†æ]</p>
</div>
<div class="risk-item">
<h5>æŠ•è³‡æ©Ÿä¼š</h5>
<p>[æŠ•è³‡æ©Ÿä¼šã®ç‰¹å®š]</p>
</div>
</div>

ã€å‡ºåŠ›æŒ‡å®šã€‘
- å¿…ãšä¸Šè¨˜HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ§‹é€ ã«å¾“ã£ã¦å‡ºåŠ›ã™ã‚‹
- èª¬æ˜æ–‡ã‚„æŒ‡ç¤ºæ–‡ã¯ä¸€åˆ‡å«ã‚ãªã„ï¼ˆ[å†…å®¹]éƒ¨åˆ†ã®ã¿å®Ÿéš›ã®åˆ†æå†…å®¹ã«ç½®æ›ï¼‰
- æŠ•è³‡å®¶ãƒ»å¸‚å ´é–¢ä¿‚è€…ã«ã¨ã£ã¦å®Ÿç”¨çš„ãªæƒ…å ±ã‚’æä¾›
- æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚„å…·ä½“ä¾‹ã‚’ç©æ¥µçš„ã«å«ã‚ã‚‹
- ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã§è¨˜è¿°ã™ã‚‹"""

        return prompt
    
    def _parse_unified_response(self, response_text: str) -> Optional[Dict[str, str]]:
        """HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ§‹é€ ã§ã®çµ±åˆè¦ç´„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ"""
        if not response_text:
            return None
        
        import re
        
        # HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ§‹é€ ã‹ã‚‰å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
        sections = {}
        
        # åœ°åŸŸåˆ¥å¸‚å ´æ¦‚æ³
        regional_match = re.search(r'<div class="regional-summaries">(.*?)</div>(?=\s*##|\s*<div class="global-overview"|$)', response_text, re.DOTALL)
        if regional_match:
            sections['regional_summaries'] = regional_match.group(1).strip()
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ç·æ‹¬
        global_match = re.search(r'<div class="global-overview">(.*?)</div>(?=\s*##|\s*<div class="cross-regional-analysis"|$)', response_text, re.DOTALL)
        if global_match:
            sections['global_overview'] = global_match.group(1).strip()
        
        # åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ
        cross_regional_match = re.search(r'<div class="cross-regional-analysis">(.*?)</div>(?=\s*##|\s*<div class="key-trends"|$)', response_text, re.DOTALL)
        if cross_regional_match:
            sections['cross_regional_analysis'] = cross_regional_match.group(1).strip()
        
        # æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å°†æ¥å±•æœ›
        trends_match = re.search(r'<div class="key-trends">(.*?)</div>(?=\s*##|\s*<div class="risk-factors"|$)', response_text, re.DOTALL)
        if trends_match:
            sections['key_trends'] = trends_match.group(1).strip()
        
        # ãƒªã‚¹ã‚¯è¦å› ãƒ»æŠ•è³‡æ©Ÿä¼š
        risk_match = re.search(r'<div class="risk-factors">(.*?)</div>(?=\s*##|$)', response_text, re.DOTALL)
        if risk_match:
            sections['risk_factors'] = risk_match.group(1).strip()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²ã‚‚è©¦è¡Œ
        if not sections:
            return self._parse_traditional_response(response_text)
        
        return sections if sections else None
    
    def _parse_traditional_response(self, response_text: str) -> Optional[Dict[str, str]]:
        """å¾“æ¥å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
        sections = {}
        current_section = None
        current_content = []
        
        lines = response_text.split('\n')
        
        section_headers = {
            'åœ°åŸŸåˆ¥å¸‚å ´æ¦‚æ³': 'regional_summaries',
            'ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ç·æ‹¬': 'global_overview', 
            'åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ': 'cross_regional_analysis',
            'æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰': 'key_trends',
            'ãƒªã‚¹ã‚¯è¦å› ': 'risk_factors',
        }
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œå‡º
            header_found = False
            for header, key in section_headers.items():
                if header in line and ('##' in line or 'â– ' in line or 'â—' in line):
                    # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                    if current_section and current_content:
                        sections[current_section] = '\n'.join(current_content).strip()
                    
                    current_section = key
                    current_content = []
                    header_found = True
                    break
            
            if not header_found and current_section:
                current_content.append(line)
        
        # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content).strip()
        
        return sections if sections else None
    
    def _validate_response_completeness(self, parsed_sections: Dict[str, str]) -> Dict[str, Any]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®Œå…¨æ€§ã‚’æ¤œè¨¼
        
        Args:
            parsed_sections: è§£æã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³è¾æ›¸
            
        Returns:
            æ¤œè¨¼çµæœè¾æ›¸
        """
        issues = []
        is_complete = True
        
        # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        required_sections = [
            'regional_summaries',
            'global_overview', 
            'cross_regional_analysis'
        ]
        
        for section in required_sections:
            if section not in parsed_sections:
                issues.append(f"å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ '{section}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                is_complete = False
                continue
                
            content = parsed_sections[section].strip()
            
            # æœ€ä½æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
            min_lengths = {
                'regional_summaries': 100,
                'global_overview': 100,
                'cross_regional_analysis': 50  # åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æã®æœ€ä½æ–‡å­—æ•°
            }
            
            min_length = min_lengths.get(section, 50)
            if len(content) < min_length:
                issues.append(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ '{section}' ã®æ–‡å­—æ•°ãŒä¸è¶³ ({len(content)}å­— < {min_length}å­—)")
                is_complete = False
            
            # åˆ‡ã‚Šè©°ã‚ã‚‰ã‚ŒãŸå¯èƒ½æ€§ã®ãƒã‚§ãƒƒã‚¯ï¼ˆä¸å®Œå…¨ãªæ–‡ã§çµ‚ã‚ã£ã¦ã„ã‚‹ã‹ï¼‰
            if section == 'cross_regional_analysis':
                # åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æã®ç‰¹åˆ¥ãƒã‚§ãƒƒã‚¯
                if content.endswith('**') or content.endswith('- ') or content.endswith('**ç±³å›½ã®é€š'):
                    issues.append("åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æãŒé€”ä¸­ã§åˆ‡ã‚Šè©°ã‚ã‚‰ã‚Œã¦ã„ã¾ã™")
                    is_complete = False
                elif len(content) < 200:  # åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æã¯ç‰¹ã«é‡è¦ãªã®ã§200å­—ä»¥ä¸Šå¿…è¦
                    issues.append(f"åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æã®å†…å®¹ãŒçŸ­ã™ãã¾ã™ ({len(content)}å­—)")
                    is_complete = False
        
        return {
            'is_complete': is_complete,
            'issues': issues,
            'section_lengths': {section: len(content) for section, content in parsed_sections.items()}
        }
    
    def _extract_summary_text(self, response_text: str) -> Optional[str]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¦ç´„éƒ¨åˆ†ã‚’æŠ½å‡º"""
        if not response_text:
            return None
        
        # ä¸è¦ãªå‰å¾Œã®è£…é£¾ã‚’é™¤å»
        text = response_text.strip()
        
        # ```markdown ãªã©ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯é™¤å»
        text = re.sub(r"```[a-zA-Z]*\n(.*?)\n```", r"\1", text, flags=re.DOTALL)
        
        # æœ€çµ‚çš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
        return text.strip() if text.strip() else None

    def _generate_fallback_summary(self, grouped_articles: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼šåˆ†å‰²å‡¦ç†ã«ã‚ˆã‚‹è¦ç´„ç”Ÿæˆ"""
        start_time = time.time()
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        
        self.logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†é–‹å§‹ - åˆ†å‰²å‡¦ç†ã«ã‚ˆã‚‹çµ±åˆè¦ç´„ (ç·è¨˜äº‹æ•°: {total_articles})")
        
        regional_summaries = {}
        successful_regions = 0
        
        # åœ°åŸŸåˆ¥ã«åˆ†å‰²å‡¦ç†
        for region, articles in grouped_articles.items():
            if not articles:
                continue
                
            try:
                # çŸ­ç¸®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§åœ°åŸŸåˆ¥è¦ç´„
                region_prompt = f"""ã€é‡‘èæ•™è‚²ç›®çš„ã®å¸‚å ´åˆ†æã€‘

åœ°åŸŸ: {region}
è¨˜äº‹æ•°: {len(articles)}ä»¶

ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰ç°¡æ½”ãªå¸‚å ´æ¦‚æ³ã‚’100-200å­—ã§ã¾ã¨ã‚ã¦ãã ã•ã„ï¼š

"""
                for i, article in enumerate(articles[:5], 1):  # æœ€å¤§5è¨˜äº‹ã«åˆ¶é™
                    title = article.get("title", "").strip()
                    summary = article.get("summary", "").strip()
                    region_prompt += f"{i}. {title}\n{summary[:100]}...\n\n"
                
                result = self._api_call_with_retry(
                    region_prompt,
                    system_prompt=self._fallback_system_prompt(),
                    max_output_tokens=1024,
                    temperature=0.3,
                    max_retries=2,
                )

                if result and result.text:
                    regional_summaries[region] = result.text.strip()
                    successful_regions += 1
                    self.logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {region}åœ°åŸŸã®è¦ç´„å®Œäº†")
                else:
                    regional_summaries[region] = f"{region}åœ°åŸŸã®è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
                    self.logger.warning(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {region}åœ°åŸŸã®è¦ç´„å¤±æ•—")
                    
            except Exception as e:
                regional_summaries[region] = f"{region}åœ°åŸŸã®è¦ç´„ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)[:50]}"
                self.logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {region}åœ°åŸŸã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœã‚’ã¾ã¨ã‚ã‚‹
        processing_time_ms = int((time.time() - start_time) * 1000)
        
        result = {
            "unified_summary": {
                "regional_summaries": "\n".join([f"â–  {region}: {summary}" for region, summary in regional_summaries.items()]),
                "global_overview": f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã«ã‚ˆã‚Š{successful_regions}/{len(grouped_articles)}åœ°åŸŸã®è¦ç´„ã‚’ç”Ÿæˆã—ã¾ã—ãŸ",
                "cross_regional_analysis": "åˆ†å‰²å‡¦ç†ã®ãŸã‚åœ°åŸŸé–“åˆ†æã¯çœç•¥ã•ã‚Œã¾ã—ãŸ",
                "key_trends": "è©³ç´°åˆ†æã¯ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®ä¿®æ­£å¾Œã«å®Ÿè¡Œã—ã¦ãã ã•ã„",
                "risk_factors": "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã®ãŸã‚ç°¡æ˜“ç‰ˆã§ã™"
            },
            "total_articles": total_articles,
            "processing_time_ms": processing_time_ms,
            "model_version": f"{self.client.model_name} (fallback)",
            "validation": {
                "is_complete": False,
                "issues": ["ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã«ã‚ˆã‚‹ç°¡æ˜“ç‰ˆ"],
                "completeness_score": 0.3
            }
        }
        
        self.logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†: {successful_regions}/{len(grouped_articles)}åœ°åŸŸæˆåŠŸ ({processing_time_ms}ms)")
        return result


def create_integrated_summaries(
    client_or_api_key: Union[BaseLLMClient, str],
    grouped_articles: Dict[str, List[Dict[str, Any]]],
    config: Optional[ProSummaryConfig] = None,
) -> Optional[Dict[str, Any]]:
    """
    1å›ã®APIå‘¼ã³å‡ºã—ã§çµ±åˆè¦ç´„ã‚’ä½œæˆã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆåœ°åŸŸé–“é–¢é€£æ€§åˆ†æé‡è¦–ï¼‰

    Args:
        client_or_api_key: æ—¢å­˜ã®LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€ã¾ãŸã¯APIã‚­ãƒ¼
        grouped_articles (Dict): åœ°åŸŸåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸè¨˜äº‹
        config (ProSummaryConfig): è¨­å®š
    
    Returns:
        Optional[Dict[str, Any]]: çµ±åˆè¦ç´„çµæœï¼ˆåœ°åŸŸåˆ¥+ã‚°ãƒ­ãƒ¼ãƒãƒ«+é–¢é€£æ€§åˆ†æï¼‰ã€å¤±æ•—æ™‚ã¯None
    """
    logger = logging.getLogger(__name__)
    
    try:
        config = config or ProSummaryConfig()

        # è¨˜äº‹æ•°ãƒã‚§ãƒƒã‚¯
        total_articles = sum(len(articles) for articles in grouped_articles.values())
        if total_articles < config.min_articles_threshold:
            logger.warning(f"è¨˜äº‹æ•°ãŒé–¾å€¤æœªæº€ã§ã™ ({total_articles} < {config.min_articles_threshold})")
            return None

        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æº–å‚™
        if isinstance(client_or_api_key, BaseLLMClient):
            client = client_or_api_key
        else:
            api_key = client_or_api_key
            if not api_key:
                logger.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return None

            provider = (config.provider or "gemini").lower()
            if provider == "openrouter":
                client = OpenRouterClient(
                    api_key=api_key,
                    model_name=config.model_name,
                    default_timeout=config.timeout_seconds,
                )
            else:
                client = GeminiClient(
                    api_key=api_key,
                    model_name=config.model_name,
                    default_timeout=config.timeout_seconds,
                )

        # Pro Summarizerã‚’åˆæœŸåŒ–
        summarizer = ProSummarizer(client, config)
        
        # 1å›APIå‘¼ã³å‡ºã—ã§çµ±åˆè¦ç´„ç”Ÿæˆ
        unified_result = summarizer.generate_unified_summary(grouped_articles)
        
        if not unified_result:
            logger.error("çµ±åˆè¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
        
        # çµæœã‚’æ•´ç†
        articles_by_region = {region: len(articles) for region, articles in grouped_articles.items()}
        
        result = {
            "unified_summary": unified_result["unified_summary"],
            "metadata": {
                "total_articles": total_articles,
                "articles_by_region": articles_by_region,
                "processing_timestamp": datetime.utcnow().isoformat(),
                "processing_time_ms": unified_result.get("processing_time_ms", 0),
                "model_version": unified_result.get("model_version", "gemini-2.5-pro")
            }
        }
        
        logger.info(f"1å›APIå‘¼ã³å‡ºã—çµ±åˆè¦ç´„ç”Ÿæˆå®Œäº†: {total_articles}ä»¶ã®è¨˜äº‹ã‚’å‡¦ç†")
        return result
        
    except Exception as e:
        logger.error(f"çµ±åˆè¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return None


if __name__ == '__main__':
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    from dotenv import load_dotenv
    load_dotenv()
    
    test_api_key = os.getenv("GEMINI_API_KEY")
    if not test_api_key:
        raise ValueError("ç’°å¢ƒå¤‰æ•° 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
    test_grouped_articles = {
        "japan": [
            {
                "title": "æ—¥éŠ€ã€æ”¿ç­–é‡‘åˆ©æ®ãˆç½®ãæ±ºå®š",
                "summary": "æ—¥æœ¬éŠ€è¡Œã¯é‡‘èæ”¿ç­–æ±ºå®šä¼šåˆã§æ”¿ç­–é‡‘åˆ©ã‚’æ®ãˆç½®ãã€ç·©å’Œçš„ãªé‡‘èæ”¿ç­–ã‚’ç¶™ç¶šã™ã‚‹ã“ã¨ã‚’æ±ºå®šã—ãŸã€‚",
                "category": "é‡‘èæ”¿ç­–"
            },
            {
                "title": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã€å¢—ç›Šã‚’ç™ºè¡¨",
                "summary": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã¯å››åŠæœŸæ±ºç®—ã§å‰å¹´åŒæœŸæ¯”å¢—ç›Šã‚’ç™ºè¡¨ã€æµ·å¤–è²©å£²ãŒå¥½èª¿ã ã£ãŸã€‚",
                "category": "ä¼æ¥­æ¥­ç¸¾"
            }
        ],
        "usa": [
            {
                "title": "FRBã€åˆ©ä¸Šã’ã‚’æ¤œè¨",
                "summary": "ç±³é€£é‚¦æº–å‚™åˆ¶åº¦ç†äº‹ä¼šã¯æ¬¡å›ä¼šåˆã§ã®åˆ©ä¸Šã’å®Ÿæ–½ã‚’ç¤ºå”†ã€ã‚¤ãƒ³ãƒ•ãƒ¬æŠ‘åˆ¶ã‚’å„ªå…ˆã™ã‚‹å§¿å‹¢ã€‚",
                "category": "é‡‘èæ”¿ç­–"
            }
        ]
    }
    
    print("--- Proçµ±åˆè¦ç´„ãƒ†ã‚¹ãƒˆ ---")
    config = ProSummaryConfig(min_articles_threshold=2)
    result = create_integrated_summaries(test_api_key, test_grouped_articles, config)
    
    if result:
        print(f"\n=== çµ±åˆè¦ç´„çµæœ ===")
        unified_summary = result['unified_summary']
        
        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º
        for section_name, content in unified_summary.items():
            section_names = {
                'regional_summaries': 'åœ°åŸŸåˆ¥å¸‚å ´æ¦‚æ³',
                'global_overview': 'ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ç·æ‹¬',
                'cross_regional_analysis': 'åœ°åŸŸé–“ç›¸äº’å½±éŸ¿åˆ†æ',
                'key_trends': 'æ³¨ç›®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å°†æ¥å±•æœ›',
                'risk_factors': 'ãƒªã‚¹ã‚¯è¦å› ãƒ»æŠ•è³‡æ©Ÿä¼š'
            }
            display_name = section_names.get(section_name, section_name)
            print(f"\n--- {display_name} ---")
            print(f"æ–‡å­—æ•°: {len(content)}å­—")
            print(f"å†…å®¹: {content[:100]}...")
        
        print(f"\n=== ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ ===")
        print(f"ç·è¨˜äº‹æ•°: {result['metadata']['total_articles']}")
        print(f"åœ°åŸŸåˆ¥: {result['metadata']['articles_by_region']}")
        print(f"å‡¦ç†æ™‚é–“: {result['metadata']['processing_time_ms']}ms")
        print(f"ãƒ¢ãƒ‡ãƒ«: {result['metadata']['model_version']}")
    else:
        print("ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
